{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bulk The bulk-synchronous parallel (BSP) programming model gives a powerful method for implementing and describing parallel programs. Bulk is a novel interface for writing BSP programs in the C++ programming language that leverages modern C++ features to allow for the implementation of safe and generic parallel algorithms for shared-memory, distributed-memory, and hybrid systems. This interface targets the next generation of BSP programmers who want to write fast, safe, clear and portable parallel programs. About BSP The bulk synchronous parallel (BSP) programming model, is a way of writing parallel and distributed programs. BSP is the underlying model for Bulk. Instead of communicating between processors (or nodes, or cores) asynchronously, all communication is staged and resolved at fixed synchronization points . These synchronizations delimit so-called supersteps . This way of structuring parallel programs has a number of advantages: The resulting programs are structured , easy to understand and maintain, and their performance and correctness can be reasoned about. Data races are eliminated almost by construction, because of simple rules which can be enforced at runtime. Scalability is straightforward to obtain. Programs are written in a SPMD fashion. There are only two types of communication mechanisms , message passing and named communication (through distributed variables) . This makes BSP based libraries very economic: you can accomplish a lot with very little. It has a gentle learning curve . It is easy to write correct BSP programs, while it is notoriously hard to write correct asynchronous parallel programs. Examples Hello world! bulk :: thread :: environment env ; env . spawn ( env . available_processors (), []( auto & world ) { auto s = world . rank (); auto p = world . active_processors (); world . log ( \"Hello world from processor %d / %d!\" , s , p ); }); Distributed variables are the bread and butter of communication in Bulk. auto a = bulk :: var < int > ( world ); a ( world . next_rank ()) = s ; world . sync (); // ... a is now updated auto b = a ( world . next_rank ()). get (); world . sync (); // ... b.value() is now available Coarrays are convenient distributed arrays. auto xs = bulk :: coarray < int > ( world , 10 ); xs ( world . next_rank ())[ 3 ] = s ; Message passing can be used for more flexible communication. auto q = bulk :: queue < int , float > ( world ); for ( int t = 0 ; t < p ; ++ t ) { q ( t ). send ( s , 3.1415f ); // send (s, pi) to processor t } world . sync (); // messages are now available in q for ( auto [ tag , content ] : q ) { world . log ( \"%d got sent %d, %f \\n \" , s , tag , content ); } Building Bulk requires an up-to-date compiler, that supports C++17, e.g. GCC >= 7.0, or Clang >= 4.0. Bulk supports a number of different backends , allowing the programs to run in parallel using: thread for multi-core systems using standard C++ <thread> threading support mpi for distributed environments using MPI The examples in the examples directory work for every backend. To build them, do the following. The backends (e.g. thread , mpi ) are built optionally, just remove or add the option if you do not require them. mkdir build cd build cmake .. make thread mpi The examples will be compiled in the bin/{backend} directory, prepended with the backend name, i.e. to run the hello example with the thread backend: ./bin/thread/thread_hello There is also a special backend available for the Epiphany coprocessor , which can be found in the epiphany branch. It also has a modified version of Bulk to support portability between MPI, <thread> and the Epiphany coprocessor. See backends/epiphany/README.md for more details. Authors Bulk is developed at Centrum Wiskunde & Informatica (CWI) in Amsterdam by: Jan-Willem Buurlage (@jwbuurlage) Tom Bannink (@tombana) License Bulk is released under the MIT license, see LICENSE.md. Please Cite Us If you have used Bulk for a scientific publication, we would appreciate citations to the following paper: Buurlage JW., Bannink T., Bisseling R.H. (2018) Bulk: A Modern C++ Interface for Bulk-Synchronous Parallel Programs. In: Aldinucci M., Padovani L., Torquati M. (eds) Euro-Par 2018: Parallel Processing. Euro-Par 2018. Lecture Notes in Computer Science, vol 11014. Springer, Cham Contributing We welcome contributions. Please submit pull requests against the develop branch. If you have any issues, questions, or remarks, then please open an issue on GitHub.","title":"Home"},{"location":"#bulk","text":"The bulk-synchronous parallel (BSP) programming model gives a powerful method for implementing and describing parallel programs. Bulk is a novel interface for writing BSP programs in the C++ programming language that leverages modern C++ features to allow for the implementation of safe and generic parallel algorithms for shared-memory, distributed-memory, and hybrid systems. This interface targets the next generation of BSP programmers who want to write fast, safe, clear and portable parallel programs.","title":"Bulk"},{"location":"#about-bsp","text":"The bulk synchronous parallel (BSP) programming model, is a way of writing parallel and distributed programs. BSP is the underlying model for Bulk. Instead of communicating between processors (or nodes, or cores) asynchronously, all communication is staged and resolved at fixed synchronization points . These synchronizations delimit so-called supersteps . This way of structuring parallel programs has a number of advantages: The resulting programs are structured , easy to understand and maintain, and their performance and correctness can be reasoned about. Data races are eliminated almost by construction, because of simple rules which can be enforced at runtime. Scalability is straightforward to obtain. Programs are written in a SPMD fashion. There are only two types of communication mechanisms , message passing and named communication (through distributed variables) . This makes BSP based libraries very economic: you can accomplish a lot with very little. It has a gentle learning curve . It is easy to write correct BSP programs, while it is notoriously hard to write correct asynchronous parallel programs.","title":"About BSP"},{"location":"#examples","text":"Hello world! bulk :: thread :: environment env ; env . spawn ( env . available_processors (), []( auto & world ) { auto s = world . rank (); auto p = world . active_processors (); world . log ( \"Hello world from processor %d / %d!\" , s , p ); }); Distributed variables are the bread and butter of communication in Bulk. auto a = bulk :: var < int > ( world ); a ( world . next_rank ()) = s ; world . sync (); // ... a is now updated auto b = a ( world . next_rank ()). get (); world . sync (); // ... b.value() is now available Coarrays are convenient distributed arrays. auto xs = bulk :: coarray < int > ( world , 10 ); xs ( world . next_rank ())[ 3 ] = s ; Message passing can be used for more flexible communication. auto q = bulk :: queue < int , float > ( world ); for ( int t = 0 ; t < p ; ++ t ) { q ( t ). send ( s , 3.1415f ); // send (s, pi) to processor t } world . sync (); // messages are now available in q for ( auto [ tag , content ] : q ) { world . log ( \"%d got sent %d, %f \\n \" , s , tag , content ); }","title":"Examples"},{"location":"#building","text":"Bulk requires an up-to-date compiler, that supports C++17, e.g. GCC >= 7.0, or Clang >= 4.0. Bulk supports a number of different backends , allowing the programs to run in parallel using: thread for multi-core systems using standard C++ <thread> threading support mpi for distributed environments using MPI The examples in the examples directory work for every backend. To build them, do the following. The backends (e.g. thread , mpi ) are built optionally, just remove or add the option if you do not require them. mkdir build cd build cmake .. make thread mpi The examples will be compiled in the bin/{backend} directory, prepended with the backend name, i.e. to run the hello example with the thread backend: ./bin/thread/thread_hello There is also a special backend available for the Epiphany coprocessor , which can be found in the epiphany branch. It also has a modified version of Bulk to support portability between MPI, <thread> and the Epiphany coprocessor. See backends/epiphany/README.md for more details.","title":"Building"},{"location":"#authors","text":"Bulk is developed at Centrum Wiskunde & Informatica (CWI) in Amsterdam by: Jan-Willem Buurlage (@jwbuurlage) Tom Bannink (@tombana)","title":"Authors"},{"location":"#license","text":"Bulk is released under the MIT license, see LICENSE.md.","title":"License"},{"location":"#please-cite-us","text":"If you have used Bulk for a scientific publication, we would appreciate citations to the following paper: Buurlage JW., Bannink T., Bisseling R.H. (2018) Bulk: A Modern C++ Interface for Bulk-Synchronous Parallel Programs. In: Aldinucci M., Padovani L., Torquati M. (eds) Euro-Par 2018: Parallel Processing. Euro-Par 2018. Lecture Notes in Computer Science, vol 11014. Springer, Cham","title":"Please Cite Us"},{"location":"#contributing","text":"We welcome contributions. Please submit pull requests against the develop branch. If you have any issues, questions, or remarks, then please open an issue on GitHub.","title":"Contributing"},{"location":"CHANGELOG/","text":"Changelog 1.1.0 2018-10-10 Added Add a spinlock barrier bulk::thread::spinning_barrier to the thread backend, which is now used by default. Add citation instruction to README 1.0.0 2018-02-27 Added Backend for the Epiphany coprocessor Fixed Let coarray::image::put take values by const reference Allow non-uniform local array sizes in coarray Require T to satisfy is_trivially_copyable for coarray<T> Add more type safety checks to (de-)serialization (De-)serialization in var and future now avoids redundant memory allocation and copying, by making the memory buffer objects non-owning 0.2.0 2017-08-09 Added Add support for std::string variables and queues Add support for array components in messages, i.e. queue<T[], U, V, ...> Deprecate processor_id in favor of rank , renamed {next,prev}_processor to {next, prev}_rank Fixed Fixed bug in MPI backend where messages could get truncated 0.1.0 2017-06-01 Initial release. A complete modern replacement for BSPlib.","title":"Release Notes"},{"location":"CHANGELOG/#changelog","text":"","title":"Changelog"},{"location":"CHANGELOG/#110","text":"2018-10-10","title":"1.1.0"},{"location":"CHANGELOG/#added","text":"Add a spinlock barrier bulk::thread::spinning_barrier to the thread backend, which is now used by default. Add citation instruction to README","title":"Added"},{"location":"CHANGELOG/#100","text":"2018-02-27","title":"1.0.0"},{"location":"CHANGELOG/#added_1","text":"Backend for the Epiphany coprocessor","title":"Added"},{"location":"CHANGELOG/#fixed","text":"Let coarray::image::put take values by const reference Allow non-uniform local array sizes in coarray Require T to satisfy is_trivially_copyable for coarray<T> Add more type safety checks to (de-)serialization (De-)serialization in var and future now avoids redundant memory allocation and copying, by making the memory buffer objects non-owning","title":"Fixed"},{"location":"CHANGELOG/#020","text":"2017-08-09","title":"0.2.0"},{"location":"CHANGELOG/#added_2","text":"Add support for std::string variables and queues Add support for array components in messages, i.e. queue<T[], U, V, ...> Deprecate processor_id in favor of rank , renamed {next,prev}_processor to {next, prev}_rank","title":"Added"},{"location":"CHANGELOG/#fixed_1","text":"Fixed bug in MPI backend where messages could get truncated","title":"Fixed"},{"location":"CHANGELOG/#010","text":"2017-06-01 Initial release. A complete modern replacement for BSPlib.","title":"0.1.0"},{"location":"bsp/","text":"BSP Model The bulk synchronous parallel (BSP) model was developed by Leslie Valiant in the 1980s. The BSP model is intended as a bridging model between parallel hardware and software. It is an elegant and simple model that has a small and easy to understand interface. The BSP model is defined on an abstract computer called a BSP computer. This computer has three important requirements. It has p p processors capable of computation and communication, i.e. it allows for local memory transactions. It has a network in place that allows the different processors to send and receive data. It has a mechanism that allows for the synchronisation of these processors, e.g. by means of a blocking barrier. A BSP program consists of a number of distinct blocks of computation and communication called supersteps . These steps are separated by a barrier synchronisation, and consist of a computation and a communication step. An important part of a BSP algorithm is the associated cost function. To this end we introduce two important concepts: namely an h h -relation, and a notion of the work done by a processor. Furthermore we introduce two parameters that define a BSP computer: g g and l l . An h h -relation is a superstep in which each processor sends or receives a maximum of h h words of data. We commonly denote with s s the id of a processor such that we can write for the h h -relation: h = \\max_s \\left\\{ \\max \\{ (h_s)_\\text{sent}, (h_s)_\\text{received} \\}~|~\\text{processors } s \\right\\} h = \\max_s \\left\\{ \\max \\{ (h_s)_\\text{sent}, (h_s)_\\text{received} \\}~|~\\text{processors } s \\right\\} Where h_s h_s denotes the number of words received or sent by processor s s . Similarly we define the work w w done in a superstep as the maximum number of flops, floating point operations, performed by all processors. Finally we define the latency l l of a superstep as the fixed constant overhead, used primarily to account for the barrier synchronisation. The values for g g and l l are platform-specific constants that are found emperically. The values for w w and h h are superstep specific and commonly obtained analytically. The total BSP cost associated to a BSP algorithm is: T = \\sum_{\\text{supersteps } i} (w_i + g \\cdot h_i + l) T = \\sum_{\\text{supersteps } i} (w_i + g \\cdot h_i + l) The BSP model has gained significant interest in the last couple of years. Most notably because Google has adopted the model and has developed some technologies based on BSP such as MapReduce and Pregel. The standard for BSP implementations is BSPlib . Modern implementations of the BSPlib include BSPonMPI, which simulates the BSP model on top of MPI, and MulticoreBSP, which provides a BSP implementation for shared-memory multi-core computers. For a more detailed introduction on the BSP model, as well as a large number of examples of BSP programs we refer to the introductory textbook on BSP and MPI by Rob Bisseling. A large number of algorithms have already been implemented using the BSP model. Some of them with their associated cost function are listed below: Problem BSP Complexity Matrix multiplication n^3/p + (n^2/p^{2/3}) \\cdot g + l n^3/p + (n^2/p^{2/3}) \\cdot g + l Sorting (n \\log n)/p + (n/p)\\cdot g + l (n \\log n)/p + (n/p)\\cdot g + l Fast Fourier Transform (n \\log n)/p + (n/p)\\cdot g + l (n \\log n)/p + (n/p)\\cdot g + l LU Decomposition n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l Cholesky Factorisation n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l Algebraic Path Problem (Shortest Paths) n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l Triangular Solver n^2/p + n\\cdot g + p\\cdot l n^2/p + n\\cdot g + p\\cdot l String Edit Problem n^2/p + n\\cdot g + p\\cdot l n^2/p + n\\cdot g + p\\cdot l Dense Matrix-Vector Multiplication n^2/p + (n/p^{1/2})\\cdot g+l n^2/p + (n/p^{1/2})\\cdot g+l Sparse Matrix-Vector Multiplication (2D grid) n/p + (n/p)^{1/2}\\cdot g+l n/p + (n/p)^{1/2}\\cdot g+l Sparse Matrix-Vector Multiplication (3D grid) n/p + (n/p)^{2/3}\\cdot g+l n/p + (n/p)^{2/3}\\cdot g+l Sparse Matrix-Vector Multiplication (random) n/p + (n/p)\\cdot g+l n/p + (n/p)\\cdot g+l List Ranking n/p + (n/p)\\cdot g+(\\log p)\\cdot l n/p + (n/p)\\cdot g+(\\log p)\\cdot l (From: McColl 1998 \u201cFoundations of Time-Critical Scalable Computing\u201d)","title":"BSP model"},{"location":"bsp/#bsp-model","text":"The bulk synchronous parallel (BSP) model was developed by Leslie Valiant in the 1980s. The BSP model is intended as a bridging model between parallel hardware and software. It is an elegant and simple model that has a small and easy to understand interface. The BSP model is defined on an abstract computer called a BSP computer. This computer has three important requirements. It has p p processors capable of computation and communication, i.e. it allows for local memory transactions. It has a network in place that allows the different processors to send and receive data. It has a mechanism that allows for the synchronisation of these processors, e.g. by means of a blocking barrier. A BSP program consists of a number of distinct blocks of computation and communication called supersteps . These steps are separated by a barrier synchronisation, and consist of a computation and a communication step. An important part of a BSP algorithm is the associated cost function. To this end we introduce two important concepts: namely an h h -relation, and a notion of the work done by a processor. Furthermore we introduce two parameters that define a BSP computer: g g and l l . An h h -relation is a superstep in which each processor sends or receives a maximum of h h words of data. We commonly denote with s s the id of a processor such that we can write for the h h -relation: h = \\max_s \\left\\{ \\max \\{ (h_s)_\\text{sent}, (h_s)_\\text{received} \\}~|~\\text{processors } s \\right\\} h = \\max_s \\left\\{ \\max \\{ (h_s)_\\text{sent}, (h_s)_\\text{received} \\}~|~\\text{processors } s \\right\\} Where h_s h_s denotes the number of words received or sent by processor s s . Similarly we define the work w w done in a superstep as the maximum number of flops, floating point operations, performed by all processors. Finally we define the latency l l of a superstep as the fixed constant overhead, used primarily to account for the barrier synchronisation. The values for g g and l l are platform-specific constants that are found emperically. The values for w w and h h are superstep specific and commonly obtained analytically. The total BSP cost associated to a BSP algorithm is: T = \\sum_{\\text{supersteps } i} (w_i + g \\cdot h_i + l) T = \\sum_{\\text{supersteps } i} (w_i + g \\cdot h_i + l) The BSP model has gained significant interest in the last couple of years. Most notably because Google has adopted the model and has developed some technologies based on BSP such as MapReduce and Pregel. The standard for BSP implementations is BSPlib . Modern implementations of the BSPlib include BSPonMPI, which simulates the BSP model on top of MPI, and MulticoreBSP, which provides a BSP implementation for shared-memory multi-core computers. For a more detailed introduction on the BSP model, as well as a large number of examples of BSP programs we refer to the introductory textbook on BSP and MPI by Rob Bisseling. A large number of algorithms have already been implemented using the BSP model. Some of them with their associated cost function are listed below: Problem BSP Complexity Matrix multiplication n^3/p + (n^2/p^{2/3}) \\cdot g + l n^3/p + (n^2/p^{2/3}) \\cdot g + l Sorting (n \\log n)/p + (n/p)\\cdot g + l (n \\log n)/p + (n/p)\\cdot g + l Fast Fourier Transform (n \\log n)/p + (n/p)\\cdot g + l (n \\log n)/p + (n/p)\\cdot g + l LU Decomposition n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l Cholesky Factorisation n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l Algebraic Path Problem (Shortest Paths) n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l Triangular Solver n^2/p + n\\cdot g + p\\cdot l n^2/p + n\\cdot g + p\\cdot l String Edit Problem n^2/p + n\\cdot g + p\\cdot l n^2/p + n\\cdot g + p\\cdot l Dense Matrix-Vector Multiplication n^2/p + (n/p^{1/2})\\cdot g+l n^2/p + (n/p^{1/2})\\cdot g+l Sparse Matrix-Vector Multiplication (2D grid) n/p + (n/p)^{1/2}\\cdot g+l n/p + (n/p)^{1/2}\\cdot g+l Sparse Matrix-Vector Multiplication (3D grid) n/p + (n/p)^{2/3}\\cdot g+l n/p + (n/p)^{2/3}\\cdot g+l Sparse Matrix-Vector Multiplication (random) n/p + (n/p)\\cdot g+l n/p + (n/p)\\cdot g+l List Ranking n/p + (n/p)\\cdot g+(\\log p)\\cdot l n/p + (n/p)\\cdot g+(\\log p)\\cdot l (From: McColl 1998 \u201cFoundations of Time-Critical Scalable Computing\u201d)","title":"BSP Model"},{"location":"bulk_vs_bsplib/","text":"Bulk vs BSPlib In this section we highlight some of the differences between Bulk and BSPlib. No global state In BSPlib, the SPMD section is delimited using bsp_begin() and bsp_end() calls. In Bulk, the SPMD section is passed as an argument to the environment::spawn function. // BSPlib #include <bsp.h> int main () { bsp_begin ( bsp_nprocs ()); int s = bsp_pid (); int p = bsp_nprocs (); printf ( \"Hello World from processor %d / %d\" , s , p ); bsp_end (); return 0 ; } // Bulk #include <bulk/bulk.hpp> #include <bulk/backends/mpi/mpi.hpp> int main () { bulk :: mpi :: environment env ; env . spawn ( env . available_processors (), []( auto & world ) { auto s = world . rank (); auto p = world . active_processors (); world . log ( \"Hello world from processor %d / %d!\" , s , p ); }); } When using BSPlib, all calls to the parallel system happen globally. In particular, calls such as bsp_sync() and bsp_push_reg(...) implicitly modify some global state. In Bulk, the state is captured in a world object. Besides the well-known reasons not to use global state, this allows for multi-layered parallelism. For example, one world could contain the nodes in an MPI cluster, while another world represents the multi-core system on such a node. Registration of variables Variables and message queues are registered and initialized upon creation, and deregistered when they go out of scope. This means that explicit registration calls are no longer necessary. Compare: // BSPlib int x = 0 ; bsp_push_reg ( & x , sizeof ( int )); bsp_sync (); ... bsp_pop_reg ( & x ); // Bulk auto x = bulk :: var < int > ( world ); Communication Communication using simple distributed variables is expressed more compactly in Bulk. Compare: // BSPlib int b = 3 ; bsp_put (( s + 1 ) % p , & b , & x , 0 , sizeof ( int )); int c = 0 ; bsp_get (( s + 1 ) % p , & x , 0 , & c , sizeof ( int )); bsp_sync (); // Bulk x ( world . next_rank ()) = 3 ; auto c = x ( world . next_rank ()). get (); world . sync (); Arrays Bulk treats distributed arrays differently from simple values. This is done using coarrays. Compare: // BSPlib int * xs = malloc ( 10 * sizeof ( int )); bsp_push_reg ( xs , 10 * sizeof ( int )); bsp_sync (); int ys [ 3 ] = { 1 , 2 , 3 }; bsp_put (( s + 1 ) % p , ys , xs , 2 , 3 * sizeof ( int )); int z = 5 ; bsp_put (( s + 1 ) % p , & z , xs , 0 , sizeof ( int )); bsp_sync (); ... bsp_pop_reg ( xs ); free ( xs ); // Bulk auto xs = bulk :: coarray < int > ( world , 10 ); xs ( world . next_rank ())[{ 2 , 5 }] = { 2 , 3 , 4 }; xs ( world . next_rank ())[ 0 ] = 5 ; world . sync (); Message passing In BSPlib, messages consist of a tag and a content . In Bulk, we don\u2019t force this message structure, but we do support it. Compare: // BSPlib int s = bsp_pid (); int p = bsp_nprocs (); int tagsize = sizeof ( int ); bsp_set_tagsize ( & tagsize ); bsp_sync (); int tag = 1 ; int payload = 42 + s ; bsp_send (( s + 1 ) % p , & tag , & payload , sizeof ( int )); bsp_sync (); int packets = 0 ; int accum_bytes = 0 ; bsp_qsize ( & packets , & accum_bytes ); int payload_in = 0 ; int payload_size = 0 ; int tag_in = 0 ; for ( int i = 0 ; i < packets ; ++ i ) { bsp_get_tag ( & payload_size , & tag_in ); bsp_move ( & payload_in , sizeof ( int )); printf ( \"payload: %i, tag: %i\" , payload_in , tag_in ); } // Bulk auto s = world . rank (); auto p = world . active_processors (); auto q = bulk :: queue < int , int > ( world ); q ( world . next_rank ()). send ( 1 , 42 + s ); world . sync (); for ( auto [ tag , content ] : queue ) { world . log ( \"payload: %i, tag: %i\" , content , tag ); } In addition, Bulk supports sending arbitrary data either using custom structs, or by composing messages on the fly. For example, to send a 3D tensor element with indices and its value, we can write: auto q = bulk :: queue < int , int , int , float > ( world ); q ( world . next_rank ()). send ( 1 , 2 , 3 , 4.0f ); world . sync (); for ( auto [ i , j , k , value ] : queue ) { world . log ( \"element: A(%i, %i, %i) = %f\" , i , j , k , value ); } Also, multiple queues can be constructed, which eliminates a common use case for using tags. Other The algorithmic skeletons in Bulk allow common patterns to be implemented in fewer lines compared to BSPlib. As an example, we show how to find the maximum element over all processors. auto maxs = bulk :: gather_all ( world , max ); max = * std :: max_element ( maxs . begin (), maxs . end ()); Compare this to the way this is done when using BSPlib: int * global_max = malloc ( sizeof ( int ) * bsp_nprocs ()); bsp_push_reg ( global_max , sizeof ( int ) * bsp_nprocs ()); for ( int t = 0 ; t < p ; ++ t ) { bsp_put ( t , & max , global_max , bsp_pid (), sizeof ( int )); } bsp_sync (); for ( int t = 0 ; t < p ; ++ t ) { if ( max < global_max [ t ]) { max = global_max [ t ]; } } bsp_pop_reg ( global_max ); free ( global_max );","title":"Bulk vs BSPlib"},{"location":"bulk_vs_bsplib/#bulk-vs-bsplib","text":"In this section we highlight some of the differences between Bulk and BSPlib.","title":"Bulk vs BSPlib"},{"location":"bulk_vs_bsplib/#no-global-state","text":"In BSPlib, the SPMD section is delimited using bsp_begin() and bsp_end() calls. In Bulk, the SPMD section is passed as an argument to the environment::spawn function. // BSPlib #include <bsp.h> int main () { bsp_begin ( bsp_nprocs ()); int s = bsp_pid (); int p = bsp_nprocs (); printf ( \"Hello World from processor %d / %d\" , s , p ); bsp_end (); return 0 ; } // Bulk #include <bulk/bulk.hpp> #include <bulk/backends/mpi/mpi.hpp> int main () { bulk :: mpi :: environment env ; env . spawn ( env . available_processors (), []( auto & world ) { auto s = world . rank (); auto p = world . active_processors (); world . log ( \"Hello world from processor %d / %d!\" , s , p ); }); } When using BSPlib, all calls to the parallel system happen globally. In particular, calls such as bsp_sync() and bsp_push_reg(...) implicitly modify some global state. In Bulk, the state is captured in a world object. Besides the well-known reasons not to use global state, this allows for multi-layered parallelism. For example, one world could contain the nodes in an MPI cluster, while another world represents the multi-core system on such a node.","title":"No global state"},{"location":"bulk_vs_bsplib/#registration-of-variables","text":"Variables and message queues are registered and initialized upon creation, and deregistered when they go out of scope. This means that explicit registration calls are no longer necessary. Compare: // BSPlib int x = 0 ; bsp_push_reg ( & x , sizeof ( int )); bsp_sync (); ... bsp_pop_reg ( & x ); // Bulk auto x = bulk :: var < int > ( world );","title":"Registration of variables"},{"location":"bulk_vs_bsplib/#communication","text":"Communication using simple distributed variables is expressed more compactly in Bulk. Compare: // BSPlib int b = 3 ; bsp_put (( s + 1 ) % p , & b , & x , 0 , sizeof ( int )); int c = 0 ; bsp_get (( s + 1 ) % p , & x , 0 , & c , sizeof ( int )); bsp_sync (); // Bulk x ( world . next_rank ()) = 3 ; auto c = x ( world . next_rank ()). get (); world . sync ();","title":"Communication"},{"location":"bulk_vs_bsplib/#arrays","text":"Bulk treats distributed arrays differently from simple values. This is done using coarrays. Compare: // BSPlib int * xs = malloc ( 10 * sizeof ( int )); bsp_push_reg ( xs , 10 * sizeof ( int )); bsp_sync (); int ys [ 3 ] = { 1 , 2 , 3 }; bsp_put (( s + 1 ) % p , ys , xs , 2 , 3 * sizeof ( int )); int z = 5 ; bsp_put (( s + 1 ) % p , & z , xs , 0 , sizeof ( int )); bsp_sync (); ... bsp_pop_reg ( xs ); free ( xs ); // Bulk auto xs = bulk :: coarray < int > ( world , 10 ); xs ( world . next_rank ())[{ 2 , 5 }] = { 2 , 3 , 4 }; xs ( world . next_rank ())[ 0 ] = 5 ; world . sync ();","title":"Arrays"},{"location":"bulk_vs_bsplib/#message-passing","text":"In BSPlib, messages consist of a tag and a content . In Bulk, we don\u2019t force this message structure, but we do support it. Compare: // BSPlib int s = bsp_pid (); int p = bsp_nprocs (); int tagsize = sizeof ( int ); bsp_set_tagsize ( & tagsize ); bsp_sync (); int tag = 1 ; int payload = 42 + s ; bsp_send (( s + 1 ) % p , & tag , & payload , sizeof ( int )); bsp_sync (); int packets = 0 ; int accum_bytes = 0 ; bsp_qsize ( & packets , & accum_bytes ); int payload_in = 0 ; int payload_size = 0 ; int tag_in = 0 ; for ( int i = 0 ; i < packets ; ++ i ) { bsp_get_tag ( & payload_size , & tag_in ); bsp_move ( & payload_in , sizeof ( int )); printf ( \"payload: %i, tag: %i\" , payload_in , tag_in ); } // Bulk auto s = world . rank (); auto p = world . active_processors (); auto q = bulk :: queue < int , int > ( world ); q ( world . next_rank ()). send ( 1 , 42 + s ); world . sync (); for ( auto [ tag , content ] : queue ) { world . log ( \"payload: %i, tag: %i\" , content , tag ); } In addition, Bulk supports sending arbitrary data either using custom structs, or by composing messages on the fly. For example, to send a 3D tensor element with indices and its value, we can write: auto q = bulk :: queue < int , int , int , float > ( world ); q ( world . next_rank ()). send ( 1 , 2 , 3 , 4.0f ); world . sync (); for ( auto [ i , j , k , value ] : queue ) { world . log ( \"element: A(%i, %i, %i) = %f\" , i , j , k , value ); } Also, multiple queues can be constructed, which eliminates a common use case for using tags.","title":"Message passing"},{"location":"bulk_vs_bsplib/#other","text":"The algorithmic skeletons in Bulk allow common patterns to be implemented in fewer lines compared to BSPlib. As an example, we show how to find the maximum element over all processors. auto maxs = bulk :: gather_all ( world , max ); max = * std :: max_element ( maxs . begin (), maxs . end ()); Compare this to the way this is done when using BSPlib: int * global_max = malloc ( sizeof ( int ) * bsp_nprocs ()); bsp_push_reg ( global_max , sizeof ( int ) * bsp_nprocs ()); for ( int t = 0 ; t < p ; ++ t ) { bsp_put ( t , & max , global_max , bsp_pid (), sizeof ( int )); } bsp_sync (); for ( int t = 0 ; t < p ; ++ t ) { if ( max < global_max [ t ]) { max = global_max [ t ]; } } bsp_pop_reg ( global_max ); free ( global_max );","title":"Other"},{"location":"coarrays/","text":"Coarrays Coarrays are a convenient way to store, and manipulate distributed arrays. These distributed arrays can be seen as distributed variables, whose images are a local array. With Bulk, we provide a coarray that is modeled after Coarray Fortran . auto xs = bulk :: coarray < int > ( world , 5 ); Here, we create a coarray with local size equal to 5 . The total number of elements in the coarray is therefore 5 * p . We use a constant size here, but this is not required as the local size is allowed to vary over the processors. Coarrays provide syntactic sugar to make manipulating distributed arrays as easy as possible. For example, we can write: xs ( 3 )[ 2 ] = 1 ; This writes the value 1 to the element with local index 2 on the processor with index 3 . The local image of an array is iterable, so we can write for example: int result = 0 ; for ( auto x : xs ) { result += x ; } to compute the local sum of the numbers in the coarray image. Slices Often, you need to deal with multiple elements of a coarray image at once. For this, Bulk supports for slices. For example, to write to a range of elements at once: auto xs = bulk :: coarray < int > ( world , 10 ); xs ( world . next_rank ())[{ 2 , 5 }] = { 2 , 3 , 4 }; Or to get a range of elements: auto xs = bulk :: coarray < int > ( world , 10 ); auto ys = xs ( world . next_rank ())[{ 2 , 5 }]. get (); world . sync (); // ys[0], ys[1], ys[2] are now available;","title":"Coarrays"},{"location":"coarrays/#coarrays","text":"Coarrays are a convenient way to store, and manipulate distributed arrays. These distributed arrays can be seen as distributed variables, whose images are a local array. With Bulk, we provide a coarray that is modeled after Coarray Fortran . auto xs = bulk :: coarray < int > ( world , 5 ); Here, we create a coarray with local size equal to 5 . The total number of elements in the coarray is therefore 5 * p . We use a constant size here, but this is not required as the local size is allowed to vary over the processors. Coarrays provide syntactic sugar to make manipulating distributed arrays as easy as possible. For example, we can write: xs ( 3 )[ 2 ] = 1 ; This writes the value 1 to the element with local index 2 on the processor with index 3 . The local image of an array is iterable, so we can write for example: int result = 0 ; for ( auto x : xs ) { result += x ; } to compute the local sum of the numbers in the coarray image.","title":"Coarrays"},{"location":"coarrays/#slices","text":"Often, you need to deal with multiple elements of a coarray image at once. For this, Bulk supports for slices. For example, to write to a range of elements at once: auto xs = bulk :: coarray < int > ( world , 10 ); xs ( world . next_rank ())[{ 2 , 5 }] = { 2 , 3 , 4 }; Or to get a range of elements: auto xs = bulk :: coarray < int > ( world , 10 ); auto ys = xs ( world . next_rank ())[{ 2 , 5 }]. get (); world . sync (); // ys[0], ys[1], ys[2] are now available;","title":"Slices"},{"location":"environment_world/","text":"Environment and world In the upcoming sections we will get you started with programming in Bulk. Two important concepts are that of an environment and a world. In these code examples, we will often use the short-hand s for the local processor id which is referred to as its rank , and p for the active number of processors , and we will not always define these variables explicitly. Parallel environments A program runs in some parallel environment. For example, this environment could be an MPI cluster, a many-core co-processor, or simply threads on a multi-core computer. This environment is accessed within the program through a bulk::environment object. This object is specialized for each backend , which is an implementation of the lower-level communication that reflects the actual environment. For example, to setup an environment on an MPI cluster, we would write: #include <bulk/bulk.hpp> #include <bulk/backends/mpi/mpi.hpp> int main () { bulk :: mpi :: environment env ; } For a list of default providers, consult the backends section of this documentation. This environment object contains information on the parallel system, for example we can request the number of processors that are available. We note that throughout this documentation (and in the library), processor is a general term for the entity that executes the SPMD section (more on this later) and communicates with other processors \u2013 this can be an MPI node, a core, or a thread, depending on the backend that is used, but they are all treated in the same manner. auto processor_count = env . available_processors (); This information can be used to spawn the program on the right amount of processors. Programs written in Bulk follow the SPMD (Single Program Multiple Data) paradigm. This means that each processor executes the same code, but has its own (local) data that it manipulates. In Bulk, the SPMD section is a function object . This can be a C++ lambda, a std::function , or a C function pointer. In this documentation we will use lambda functions for our examples. This function will run on each processor, and should take three arguments. The first, contains the world object, which we will describe in detail in the next section. The SPMD section is executed in the following way: env . spawn ( env . available_processors (), []( auto & world ) { auto s = world . rank (); auto p = world . available_processors (); world . log ( \"Hello world from processor %d / %d!\" , s , p ); } The spawn function takes two arguments. The first is the total number of processors to run the SPMD section on, here we simply use all the processors that are available. The second is the SPMD function itself, that is run on the given number of processors. The world of a processor Each processor can communicate to other processors using the world object of type bulk::world . The world object contains some information on the specifics of the SPMD section, such as the number of processors executing the section, and its identifier (as we have seen, these are also provided as arguments for programmer convenience). We can also obtain indices of the neighbouring processors: auto next = world . next_rank (); auto previous = world . prev_rank (); The next and previous processor can also be computed manually using: next = ( s + 1 ) % p ; previous = ( s + p - 1 ) % p ; However, we would suggest using the appropriate methods of world to increase readability. Another important mechanism exposed through the world object is the ability to perform a bulk synchronization , which is the cornerstone of programs written in BSP style: world . sync (); We will see the specific uses of bulk synchronization in the upcoming sections.","title":"Environment and world"},{"location":"environment_world/#environment-and-world","text":"In the upcoming sections we will get you started with programming in Bulk. Two important concepts are that of an environment and a world. In these code examples, we will often use the short-hand s for the local processor id which is referred to as its rank , and p for the active number of processors , and we will not always define these variables explicitly.","title":"Environment and world"},{"location":"environment_world/#parallel-environments","text":"A program runs in some parallel environment. For example, this environment could be an MPI cluster, a many-core co-processor, or simply threads on a multi-core computer. This environment is accessed within the program through a bulk::environment object. This object is specialized for each backend , which is an implementation of the lower-level communication that reflects the actual environment. For example, to setup an environment on an MPI cluster, we would write: #include <bulk/bulk.hpp> #include <bulk/backends/mpi/mpi.hpp> int main () { bulk :: mpi :: environment env ; } For a list of default providers, consult the backends section of this documentation. This environment object contains information on the parallel system, for example we can request the number of processors that are available. We note that throughout this documentation (and in the library), processor is a general term for the entity that executes the SPMD section (more on this later) and communicates with other processors \u2013 this can be an MPI node, a core, or a thread, depending on the backend that is used, but they are all treated in the same manner. auto processor_count = env . available_processors (); This information can be used to spawn the program on the right amount of processors. Programs written in Bulk follow the SPMD (Single Program Multiple Data) paradigm. This means that each processor executes the same code, but has its own (local) data that it manipulates. In Bulk, the SPMD section is a function object . This can be a C++ lambda, a std::function , or a C function pointer. In this documentation we will use lambda functions for our examples. This function will run on each processor, and should take three arguments. The first, contains the world object, which we will describe in detail in the next section. The SPMD section is executed in the following way: env . spawn ( env . available_processors (), []( auto & world ) { auto s = world . rank (); auto p = world . available_processors (); world . log ( \"Hello world from processor %d / %d!\" , s , p ); } The spawn function takes two arguments. The first is the total number of processors to run the SPMD section on, here we simply use all the processors that are available. The second is the SPMD function itself, that is run on the given number of processors.","title":"Parallel environments"},{"location":"environment_world/#the-world-of-a-processor","text":"Each processor can communicate to other processors using the world object of type bulk::world . The world object contains some information on the specifics of the SPMD section, such as the number of processors executing the section, and its identifier (as we have seen, these are also provided as arguments for programmer convenience). We can also obtain indices of the neighbouring processors: auto next = world . next_rank (); auto previous = world . prev_rank (); The next and previous processor can also be computed manually using: next = ( s + 1 ) % p ; previous = ( s + p - 1 ) % p ; However, we would suggest using the appropriate methods of world to increase readability. Another important mechanism exposed through the world object is the ability to perform a bulk synchronization , which is the cornerstone of programs written in BSP style: world . sync (); We will see the specific uses of bulk synchronization in the upcoming sections.","title":"The world of a processor"},{"location":"getting_started/","text":"The easiest way to get started using Bulk is to download the source code from GitHub . If you use Bulk in a project we suggest to add Bulk as a submodule, since it is in active development. Bulk requires an up-to-date compiler, that supports C++17, e.g. GCC >= 7.0, or Clang >= 4.0. Currently we only actively support Linux, but we avoid platform specific code in the library, so building on other platforms should be possible. Bulk supports a number of different backends , allowing the programs to run in parallel using: thread for multi-core systems using standard C++ <thread> threading support mpi for distributed environments using MPI. We suggest to use the OpenMPI implementation, since is the implementation we test against. The examples in the examples directory work for every backend. They are built separately for each backend. The backends (e.g. thread , mpi ) are built optionally, just remove or add the option if you do not require them. mkdir build cd build cmake .. make thread mpi The examples will be compiled in the bin/{backend} directory, prepended with the backend name, i.e. to run the hello example with the thread backend: ./bin/thread/thread_hello Using Bulk in a project To use Bulk in a project managed with git, add it as a submodule: git submodule add https://www.github.com/jwbuurlage/bulk ext/bulk git submodule update --init --remote And add ext/bulk/include as an include directory when building. The entire library is header only, but backends may have dependencies. See their documentation for details.","title":"Getting started"},{"location":"getting_started/#using-bulk-in-a-project","text":"To use Bulk in a project managed with git, add it as a submodule: git submodule add https://www.github.com/jwbuurlage/bulk ext/bulk git submodule update --init --remote And add ext/bulk/include as an include directory when building. The entire library is header only, but backends may have dependencies. See their documentation for details.","title":"Using Bulk in a project"},{"location":"message_passing/","text":"Message passing Another way to communicate between processors is by using message queues. These queues can be used to send and receive an arbitrary number of messages . Messages have an attached tag and some content . Messages can be put into message queues, which have images on each processor. This queue can then be iterated over. To create a queue, you write: auto queue = bulk :: queue < int , float > ( world ); This will create a queue that stores message with integer tags, and float content. For example, a message can correspond to a component of a vector of floats. To put a message into a remote queue, we use queue(pid).send : queue ( world . next_rank ()). send ( 1 , 1.0f ); queue ( world . next_rank ()). send ( 2 , 5.0f ); This will send two messages to the next logical processor, with tags 1 and 2 respectively, and with contents 1.0f and 5.0f. As with communication through variables, this mechanism is also bulk synchronous , which means that the remote queue will only have access to the messages in the next superstep. Warning Message queues, like variables, are identified by the order in which they are constructed. Make sure this order is the same on each processor. world . sync (); for ( auto [ tag , content ] : queue ) { world . log ( \"Received tag: %d and content %f\" , tag , content ); }; It is perfectly legal, and even encouraged, to make a separate queue for different types of messages. Each message queue has its own independent types. In addition, you are not limited to \u2018tag + content\u2019 type of messages, you can also send untagged data, or custom data such as index tuples, or even your own structs. For example: auto raw_queue = bulk :: queue < int > ( world ); raw_queue ( world . next_rank ()). send ( 1 ); raw_queue ( world . next_rank ()). send ( 2 ); raw_queue ( world . next_rank ()). send ( 123 ); auto tuple_queue = bulk :: queue < int , int , int > ( world ); tuple_queue ( world . next_rank ()). send ( 1 , 2 , 3 ); tuple_queue ( world . next_rank ()). send ( 4 , 5 , 6 ); world . sync (); // read queue for ( auto x : raw_queue ) { world . log ( \"the first queue received a message: %d\" , x ); } for ( auto [ i , j , k ] : tuple_queue ) { world . log ( \"the second queue received a tuple: (%d, %d, %d)\" , i , j , k ); } It is also possible to send arrays using queues, by having a message component of type T[] . Components of queues of type T[] , require a std::vector<T> as input to send . Similarly, when iterating through the queue the T[] component of the message will be represented by a std::vector<T> . auto q = bulk :: queue < int [], int > ( world ); q ( world . next_rank ()). send ({ 1 , 2 , 3 , 4 }, 1 ); world . sync (); for ( auto [ xs , y ] : q ) { // ... xs is of type std::vector<int> }","title":"Message passing"},{"location":"message_passing/#message-passing","text":"Another way to communicate between processors is by using message queues. These queues can be used to send and receive an arbitrary number of messages . Messages have an attached tag and some content . Messages can be put into message queues, which have images on each processor. This queue can then be iterated over. To create a queue, you write: auto queue = bulk :: queue < int , float > ( world ); This will create a queue that stores message with integer tags, and float content. For example, a message can correspond to a component of a vector of floats. To put a message into a remote queue, we use queue(pid).send : queue ( world . next_rank ()). send ( 1 , 1.0f ); queue ( world . next_rank ()). send ( 2 , 5.0f ); This will send two messages to the next logical processor, with tags 1 and 2 respectively, and with contents 1.0f and 5.0f. As with communication through variables, this mechanism is also bulk synchronous , which means that the remote queue will only have access to the messages in the next superstep. Warning Message queues, like variables, are identified by the order in which they are constructed. Make sure this order is the same on each processor. world . sync (); for ( auto [ tag , content ] : queue ) { world . log ( \"Received tag: %d and content %f\" , tag , content ); }; It is perfectly legal, and even encouraged, to make a separate queue for different types of messages. Each message queue has its own independent types. In addition, you are not limited to \u2018tag + content\u2019 type of messages, you can also send untagged data, or custom data such as index tuples, or even your own structs. For example: auto raw_queue = bulk :: queue < int > ( world ); raw_queue ( world . next_rank ()). send ( 1 ); raw_queue ( world . next_rank ()). send ( 2 ); raw_queue ( world . next_rank ()). send ( 123 ); auto tuple_queue = bulk :: queue < int , int , int > ( world ); tuple_queue ( world . next_rank ()). send ( 1 , 2 , 3 ); tuple_queue ( world . next_rank ()). send ( 4 , 5 , 6 ); world . sync (); // read queue for ( auto x : raw_queue ) { world . log ( \"the first queue received a message: %d\" , x ); } for ( auto [ i , j , k ] : tuple_queue ) { world . log ( \"the second queue received a tuple: (%d, %d, %d)\" , i , j , k ); } It is also possible to send arrays using queues, by having a message component of type T[] . Components of queues of type T[] , require a std::vector<T> as input to send . Similarly, when iterating through the queue the T[] component of the message will be represented by a std::vector<T> . auto q = bulk :: queue < int [], int > ( world ); q ( world . next_rank ()). send ({ 1 , 2 , 3 , 4 }, 1 ); world . sync (); for ( auto [ xs , y ] : q ) { // ... xs is of type std::vector<int> }","title":"Message passing"},{"location":"tour/","text":"A tour of Bulk On this page we aim to highlight some of the main features of the library, and to give an impression of the overall syntax. Hello bulk::world ! We start out with the obligatory Hello World! in Bulk , and subsequently explain the code line-by-line. In this code we will use the MPI backend, but everything written here is completely general, and guaranteed to work on top of any conforming Bulk backend. #include <bulk/bulk.hpp> #include <bulk/backends/mpi/mpi.hpp> int main () { bulk :: mpi :: environment env ; env . spawn ( env . available_processors (), []( auto & world ) { auto s = world . rank (); auto p = world . active_processors (); world . log ( \"Hello world from processor %d / %d!\" , s , p ); }); } On lines 1 and 2 we include the library, and the backend of our choosing (in our case MPI). On line 5, we initialize an environment , which sets up the parallel or distributed system. On line 6, we spawn the SPMD section of our program within the environment. The first argument denotes the number of processors that we want to run the section on, while the second argument provides a function-like object (here a C++ lambda function) that is executed on the requested number of processors. This function obtains a bulk::world object, which it can use to communicate with other processors. For convenience we suggest to alias the processor identifier (or rank) to s and the total number of processes that are spawned to p . As shown in the example, these can be obtained from world using world.rank() and world.active_processors() respectively. Communication between processors Next, we look at some basic forms of communication between processors. The main way to talk to other processors, is by using variables. A variable is created as follows: auto x = bulk :: var < T > ( world ); Here, T is the type of the variable, for example an int . Values can be assigned to the (local) variable: x = 5 ; The reason to use such a distributed variable, is that a processor can write to a remote image of a variable. bulk :: put ( world . next_rank (), 4 , x ); // or the short-hand: x ( world . next_rank ()) = 4 ; This will overwrite the value of the variable x on the next logical processor (i.e. processor (s + 1) % p ) with 4 . We can obtain the value of a remote image using: auto y = bulk :: get ( world . next_rank (), x ); // or the short-hand: auto y = x ( world . next_rank ()). get (); Here, y is a bulk::future object. A future object does not immediately hold the remote value of x , but after a future call to world.sync() , we can extract the remote value out of y . world . sync (); auto x_next = y . value (); Coarrays Coarrays are a convenient way to store, and manipulate distributed data. We provide a coarray that is modeled after Coarray Fortran . Arrays are initialized and used as follows: auto xs = bulk :: coarray < int > ( world , s ); xs ( 3 )[ 2 ] = 1 ; Here, we create a coarray of varying local size (each processor holds s many elements). Next we write the value 1 to the element with local index 2 on processor with index 3 . Algorithmic skeletons Bulk comes equipped with a number of higher-level functions, also known as algorithmic skeletons . For example, say we want to compute the dot-product of two coarrays, then we write this as: auto xs = bulk :: coarray < int > ( world , s ); auto ys = bulk :: coarray < int > ( world , s ); // fill xs and ys with data auto result = bulk :: var < int > ( world ); for ( int i = 0 ; i < s ; ++ i ) { result . value () += xs [ i ] * ys [ i ]; } // reduce to find global dot product auto alpha = bulk :: foldl ( result , []( int & lhs , int rhs ) { lhs += rhs ; }); Here we first compute the local inner product, and finally use the higher-level function bulk::foldl result. Another example is finding a maximum element over all processors, here max is the maximum value found locally: auto maxs = bulk :: gather_all ( world , max ); max = * std :: max_element ( maxs . begin (), maxs . end ());","title":"Tour"},{"location":"tour/#a-tour-of-bulk","text":"On this page we aim to highlight some of the main features of the library, and to give an impression of the overall syntax.","title":"A tour of Bulk"},{"location":"tour/#hello-bulkworld","text":"We start out with the obligatory Hello World! in Bulk , and subsequently explain the code line-by-line. In this code we will use the MPI backend, but everything written here is completely general, and guaranteed to work on top of any conforming Bulk backend. #include <bulk/bulk.hpp> #include <bulk/backends/mpi/mpi.hpp> int main () { bulk :: mpi :: environment env ; env . spawn ( env . available_processors (), []( auto & world ) { auto s = world . rank (); auto p = world . active_processors (); world . log ( \"Hello world from processor %d / %d!\" , s , p ); }); } On lines 1 and 2 we include the library, and the backend of our choosing (in our case MPI). On line 5, we initialize an environment , which sets up the parallel or distributed system. On line 6, we spawn the SPMD section of our program within the environment. The first argument denotes the number of processors that we want to run the section on, while the second argument provides a function-like object (here a C++ lambda function) that is executed on the requested number of processors. This function obtains a bulk::world object, which it can use to communicate with other processors. For convenience we suggest to alias the processor identifier (or rank) to s and the total number of processes that are spawned to p . As shown in the example, these can be obtained from world using world.rank() and world.active_processors() respectively.","title":"Hello bulk::world!"},{"location":"tour/#communication-between-processors","text":"Next, we look at some basic forms of communication between processors. The main way to talk to other processors, is by using variables. A variable is created as follows: auto x = bulk :: var < T > ( world ); Here, T is the type of the variable, for example an int . Values can be assigned to the (local) variable: x = 5 ; The reason to use such a distributed variable, is that a processor can write to a remote image of a variable. bulk :: put ( world . next_rank (), 4 , x ); // or the short-hand: x ( world . next_rank ()) = 4 ; This will overwrite the value of the variable x on the next logical processor (i.e. processor (s + 1) % p ) with 4 . We can obtain the value of a remote image using: auto y = bulk :: get ( world . next_rank (), x ); // or the short-hand: auto y = x ( world . next_rank ()). get (); Here, y is a bulk::future object. A future object does not immediately hold the remote value of x , but after a future call to world.sync() , we can extract the remote value out of y . world . sync (); auto x_next = y . value ();","title":"Communication between processors"},{"location":"tour/#coarrays","text":"Coarrays are a convenient way to store, and manipulate distributed data. We provide a coarray that is modeled after Coarray Fortran . Arrays are initialized and used as follows: auto xs = bulk :: coarray < int > ( world , s ); xs ( 3 )[ 2 ] = 1 ; Here, we create a coarray of varying local size (each processor holds s many elements). Next we write the value 1 to the element with local index 2 on processor with index 3 .","title":"Coarrays"},{"location":"tour/#algorithmic-skeletons","text":"Bulk comes equipped with a number of higher-level functions, also known as algorithmic skeletons . For example, say we want to compute the dot-product of two coarrays, then we write this as: auto xs = bulk :: coarray < int > ( world , s ); auto ys = bulk :: coarray < int > ( world , s ); // fill xs and ys with data auto result = bulk :: var < int > ( world ); for ( int i = 0 ; i < s ; ++ i ) { result . value () += xs [ i ] * ys [ i ]; } // reduce to find global dot product auto alpha = bulk :: foldl ( result , []( int & lhs , int rhs ) { lhs += rhs ; }); Here we first compute the local inner product, and finally use the higher-level function bulk::foldl result. Another example is finding a maximum element over all processors, here max is the maximum value found locally: auto maxs = bulk :: gather_all ( world , max ); max = * std :: max_element ( maxs . begin (), maxs . end ());","title":"Algorithmic skeletons"},{"location":"variables/","text":"Variables Now that we are able to set up the environment, and gained some familiarity with the world object that can be used to communicate with other processors, we are ready to discuss communication between processors. The most fundamental way of communicating between processors is using distributed variables . The variables can be created as follows: auto x = bulk :: var < int >( world ); Here we create a distributed variable that holds an integer. A distributed variable exists on every processor, but can have different values on different processors. These different local \u2018copies\u2019 are referred to as images of the variable. The variable lives within the world of the current SPMD section, and we explicitely write this by passing the world object as a parameter to the variable creation function. While x refers to the local image of a variable, it is identified with images on remote processors by the order in which variables are constructed (which is possible because of the SPMD nature of Bulk programs). This allows us to write to and read from remote images of a variable by simply passing x to communication functions. Bulk synchronous communication The main way to manipulate remote images of variables is using the communication primitives bulk::put and bulk::get for writing and reading respectively. For example, to write the value 1 to the remote image held by the next logical processor, we write: bulk :: put ( world . next_rank (), 1 , x ); To obtain the value of a remote image we write: auto y = bulk :: get ( world . next_rank (), x ); Note Equivalently, we can use the short-hand syntax: x(world.next_rank()) = 1 for putting, and auto y = x(world.next_rank()).get() for getting. Initially, communication is only staged. This means that the values are not valid immediately after the execution of the communication primitives. Instead, they are available in the next \u2018section\u2019 of the program, known as a (BSP) superstep . Supersteps can be viewed as the section of the program within successive calls to world.sync() . This barrier synchronization asserts that all processors have reached that point of the program, and resolves all outstanding communication such as those staged by calls to put and get. After the barrier synchronization returns, all communication staged in the previous superstep is guaranteed to have occurred. In case of put , the remote image now contains the value written to it (assuming that the local processor is the only one who wrote to that specific remote image). For read requests using get , it is slightly more complicated. The type of y is a bulk::future<T> . A future object is a placeholder, that will contain the correct value in the next superstep. This value can be obtained after the synchronization using: auto value = y.value(); This way of communicating is particularly useful when dealing with simple data objects. If instead we deal with distributed array-like objects, we recommend using coarrays , which are introduced in the next section.","title":"Distributed variables"},{"location":"variables/#variables","text":"Now that we are able to set up the environment, and gained some familiarity with the world object that can be used to communicate with other processors, we are ready to discuss communication between processors. The most fundamental way of communicating between processors is using distributed variables . The variables can be created as follows: auto x = bulk :: var < int >( world ); Here we create a distributed variable that holds an integer. A distributed variable exists on every processor, but can have different values on different processors. These different local \u2018copies\u2019 are referred to as images of the variable. The variable lives within the world of the current SPMD section, and we explicitely write this by passing the world object as a parameter to the variable creation function. While x refers to the local image of a variable, it is identified with images on remote processors by the order in which variables are constructed (which is possible because of the SPMD nature of Bulk programs). This allows us to write to and read from remote images of a variable by simply passing x to communication functions.","title":"Variables"},{"location":"variables/#bulk-synchronous-communication","text":"The main way to manipulate remote images of variables is using the communication primitives bulk::put and bulk::get for writing and reading respectively. For example, to write the value 1 to the remote image held by the next logical processor, we write: bulk :: put ( world . next_rank (), 1 , x ); To obtain the value of a remote image we write: auto y = bulk :: get ( world . next_rank (), x ); Note Equivalently, we can use the short-hand syntax: x(world.next_rank()) = 1 for putting, and auto y = x(world.next_rank()).get() for getting. Initially, communication is only staged. This means that the values are not valid immediately after the execution of the communication primitives. Instead, they are available in the next \u2018section\u2019 of the program, known as a (BSP) superstep . Supersteps can be viewed as the section of the program within successive calls to world.sync() . This barrier synchronization asserts that all processors have reached that point of the program, and resolves all outstanding communication such as those staged by calls to put and get. After the barrier synchronization returns, all communication staged in the previous superstep is guaranteed to have occurred. In case of put , the remote image now contains the value written to it (assuming that the local processor is the only one who wrote to that specific remote image). For read requests using get , it is slightly more complicated. The type of y is a bulk::future<T> . A future object is a placeholder, that will contain the correct value in the next superstep. This value can be obtained after the synchronization using: auto value = y.value(); This way of communicating is particularly useful when dealing with simple data objects. If instead we deal with distributed array-like objects, we recommend using coarrays , which are introduced in the next section.","title":"Bulk synchronous communication"},{"location":"api/","text":"Bulk API reference System bulk::environment the central object that encapsulates the distributed system bulk::world an implementation of the low-level functions Distributed objects and communication bulk::var a distributed variable with an image for each processor bulk::future an object which encapsulates a value known in future supersteps bulk::coarray a distributed array with a local array image for each processor Message passing bulk::queue a container containing messages Algorithms bulk::foldl a left fold over a var bulk::gather_all gather results Utility bulk::util::timer wall timer for benchmarking bulk::util::flatten flatten multi-indices bulk::util::unflatten unflatten mutli-indices","title":"Index"},{"location":"api/#bulk-api-reference","text":"System bulk::environment the central object that encapsulates the distributed system bulk::world an implementation of the low-level functions Distributed objects and communication bulk::var a distributed variable with an image for each processor bulk::future an object which encapsulates a value known in future supersteps bulk::coarray a distributed array with a local array image for each processor Message passing bulk::queue a container containing messages Algorithms bulk::foldl a left fold over a var bulk::gather_all gather results Utility bulk::util::timer wall timer for benchmarking bulk::util::flatten flatten multi-indices bulk::util::unflatten unflatten mutli-indices","title":"Bulk API reference"},{"location":"api/coarray/","text":"bulk::coarray Defined in header <bulk/coarray.hpp> . template < typename T > class coarray ; Distributed array with easy element access, loosely based on the behaviour of Coarray Fortran . Usage Coarrays provide a convenient way to share data across processors. Instead of manually sending and receiving data elements, coarrays model distributed data as a 2-dimensional array, where the first dimension is over the processors, and the second dimension is over local 1-dimensional array indices. Template parameters T - the type of the value stored in the local image of the coarray. Member types value_type : the type of the image values (i.e. T ). Nested classes image representation of coarray image writer allows for modification for remote coarray image slice slices of coarrays slice_writer modify slices of coarrays Member functions (constructor) constructs the coarray (deconstructor) deconstructs the coarray Value access operator() obtain an image of the coarray operator[] access the local elements of the coarray World access world returns the world to which the coarray belongs Example auto xs = bulk :: coarray < int > ( world , 10 ); // set the 5th element on the 1st processor to 4 xs ( 1 )[ 5 ] = 4 ; // set the 3rd element on the local processor to 2 xs [ 3 ] = 2 ; // set a slice xs ( 1 )[{ 2 , 5 }] = { 1 , 2 , 3 }; // get a slice auto values = xs ( 2 )[{ 2 , 5 }]. get ();","title":"coarray"},{"location":"api/coarray/#bulkcoarray","text":"Defined in header <bulk/coarray.hpp> . template < typename T > class coarray ; Distributed array with easy element access, loosely based on the behaviour of Coarray Fortran .","title":"bulk::coarray"},{"location":"api/coarray/#usage","text":"Coarrays provide a convenient way to share data across processors. Instead of manually sending and receiving data elements, coarrays model distributed data as a 2-dimensional array, where the first dimension is over the processors, and the second dimension is over local 1-dimensional array indices.","title":"Usage"},{"location":"api/coarray/#template-parameters","text":"T - the type of the value stored in the local image of the coarray.","title":"Template parameters"},{"location":"api/coarray/#member-types","text":"value_type : the type of the image values (i.e. T ).","title":"Member types"},{"location":"api/coarray/#nested-classes","text":"image representation of coarray image writer allows for modification for remote coarray image slice slices of coarrays slice_writer modify slices of coarrays","title":"Nested classes"},{"location":"api/coarray/#member-functions","text":"(constructor) constructs the coarray (deconstructor) deconstructs the coarray Value access operator() obtain an image of the coarray operator[] access the local elements of the coarray World access world returns the world to which the coarray belongs","title":"Member functions"},{"location":"api/coarray/#example","text":"auto xs = bulk :: coarray < int > ( world , 10 ); // set the 5th element on the 1st processor to 4 xs ( 1 )[ 5 ] = 4 ; // set the 3rd element on the local processor to 2 xs [ 3 ] = 2 ; // set a slice xs ( 1 )[{ 2 , 5 }] = { 1 , 2 , 3 }; // get a slice auto values = xs ( 2 )[{ 2 , 5 }]. get ();","title":"Example"},{"location":"api/environment/","text":"bulk::environment Defined in header <bulk/environment.hpp> . class environment ; bulk::environment encodes the environment of a parallel layer, and provides information on the system. Member functions Initialization spawn spawns a spmd section on a given number of processors System information available_processors returns the number of available processors Example #include \"bulk/bulk.hpp\" #include \"set_backend.hpp\" int main () { environment env ; env . spawn ( env . available_processors (), []( bulk :: world & world ) { int s = world . processor_id (); int p = world . active_processors (); world . log ( \"Hello, world %d/%d\" , s , p ); }); return 0 ; }","title":"environment"},{"location":"api/environment/#bulkenvironment","text":"Defined in header <bulk/environment.hpp> . class environment ; bulk::environment encodes the environment of a parallel layer, and provides information on the system.","title":"bulk::environment"},{"location":"api/environment/#member-functions","text":"Initialization spawn spawns a spmd section on a given number of processors System information available_processors returns the number of available processors","title":"Member functions"},{"location":"api/environment/#example","text":"#include \"bulk/bulk.hpp\" #include \"set_backend.hpp\" int main () { environment env ; env . spawn ( env . available_processors (), []( bulk :: world & world ) { int s = world . processor_id (); int p = world . active_processors (); world . log ( \"Hello, world %d/%d\" , s , p ); }); return 0 ; }","title":"Example"},{"location":"api/flatten/","text":"bulk::util::flatten template < int D > int flatten ( std :: array < int , D > volume , std :: array < int , D > idxs ); Flatten a multi-index in a D-dimensional volume. Template parameters D - the dimension of the index space Parameters volume - the size of the volume idxs - the multi-index","title":"flatten"},{"location":"api/flatten/#bulkutilflatten","text":"template < int D > int flatten ( std :: array < int , D > volume , std :: array < int , D > idxs ); Flatten a multi-index in a D-dimensional volume.","title":"bulk::util::flatten"},{"location":"api/flatten/#template-parameters","text":"D - the dimension of the index space","title":"Template parameters"},{"location":"api/flatten/#parameters","text":"volume - the size of the volume idxs - the multi-index","title":"Parameters"},{"location":"api/foldl/","text":"bulk::foldl template < typename T , typename Func > T foldl ( var < T >& x , Func f , T start_value = 0 ) Perform a left-fold over a distributed variable. Template parameters T - the value type of the variable/array Func - type of a binary function of the form (T, T) -> T that is used to fold Parameters x - the distributed variable f - the folding function start_value - the (optional) initial alue of the accumulator Complexity and cost Cost : costof(f) * p + sizeof(T) * p * g + l","title":"foldl"},{"location":"api/foldl/#bulkfoldl","text":"template < typename T , typename Func > T foldl ( var < T >& x , Func f , T start_value = 0 ) Perform a left-fold over a distributed variable.","title":"bulk::foldl"},{"location":"api/foldl/#template-parameters","text":"T - the value type of the variable/array Func - type of a binary function of the form (T, T) -> T that is used to fold","title":"Template parameters"},{"location":"api/foldl/#parameters","text":"x - the distributed variable f - the folding function start_value - the (optional) initial alue of the accumulator","title":"Parameters"},{"location":"api/foldl/#complexity-and-cost","text":"Cost : costof(f) * p + sizeof(T) * p * g + l","title":"Complexity and cost"},{"location":"api/future/","text":"bulk::future Defined in header <bulk/future.hpp> . template < typename T > class future ; // (1) template < typename T > class future < T [] > ; // (2) bulk::future represents a value (1) or array (2) that will or has become known in the superstep after its creation. Template parameters T - the type of the value(s) stored in the future Member functions (constructor) constructs the future (deconstructor) deconstructs the future operator= assign a future Value access value returns the value of the future (1) operator[] return an element of the array (2) Hub access world returns the hub to which the future belongs","title":"future"},{"location":"api/future/#bulkfuture","text":"Defined in header <bulk/future.hpp> . template < typename T > class future ; // (1) template < typename T > class future < T [] > ; // (2) bulk::future represents a value (1) or array (2) that will or has become known in the superstep after its creation.","title":"bulk::future"},{"location":"api/future/#template-parameters","text":"T - the type of the value(s) stored in the future","title":"Template parameters"},{"location":"api/future/#member-functions","text":"(constructor) constructs the future (deconstructor) deconstructs the future operator= assign a future Value access value returns the value of the future (1) operator[] return an element of the array (2) Hub access world returns the hub to which the future belongs","title":"Member functions"},{"location":"api/gather_all/","text":"bulk::gather_all template < typename T > bulk :: coarray < T > gather_all ( bulk :: world & world , T value ) This function takes a value on each processor, and gathers all of these in the local images of a coarray. Template parameters T - the value type Parameters world - the world in which we gather value - the distributed variable Returns A coarray, whose local images consists of p elements with on the s -th position the value passed by the s -th processor. Complexity and cost Cost : sizeof(T) * p * g + l","title":"gather_all"},{"location":"api/gather_all/#bulkgather_all","text":"template < typename T > bulk :: coarray < T > gather_all ( bulk :: world & world , T value ) This function takes a value on each processor, and gathers all of these in the local images of a coarray.","title":"bulk::gather_all"},{"location":"api/gather_all/#template-parameters","text":"T - the value type","title":"Template parameters"},{"location":"api/gather_all/#parameters","text":"world - the world in which we gather value - the distributed variable","title":"Parameters"},{"location":"api/gather_all/#returns","text":"A coarray, whose local images consists of p elements with on the s -th position the value passed by the s -th processor.","title":"Returns"},{"location":"api/gather_all/#complexity-and-cost","text":"Cost : sizeof(T) * p * g + l","title":"Complexity and cost"},{"location":"api/get/","text":"bulk::get template < typename T , typename Hub > future < T , Hub > get ( int processor , var < T , Hub >& the_variable ); // 1. Get a value from a (remote) image of a variable (1.). Template parameters T - the value type of the variable/array Hub - the type of the hub that the variable/array belongs to Parameters processor - the index of the (remote) processor the_variable - the source variable Complexity and cost Cost sizeof(T) * g Example #include <iostream> #include <bulk/hub.hpp> #include <bulk/communication.hpp> #include <bulk/bsp/bulk.hpp> int main () { auto hub = bulk :: hub < bulk :: bsp :: provider > (); hub . spawn ( hub . available_processors (), [ & hub ]( int s , int ) { auto x = bulk :: create_var < int > ( hub ); auto y = bulk :: get ( hub . next_processor (), x ); // 1. hub . sync (); std :: cout << s << \" <- \" << y . value () << std :: endl ; }); return 0 ; }","title":"`bulk::get`"},{"location":"api/get/#bulkget","text":"template < typename T , typename Hub > future < T , Hub > get ( int processor , var < T , Hub >& the_variable ); // 1. Get a value from a (remote) image of a variable (1.).","title":"bulk::get"},{"location":"api/get/#template-parameters","text":"T - the value type of the variable/array Hub - the type of the hub that the variable/array belongs to","title":"Template parameters"},{"location":"api/get/#parameters","text":"processor - the index of the (remote) processor the_variable - the source variable","title":"Parameters"},{"location":"api/get/#complexity-and-cost","text":"Cost sizeof(T) * g","title":"Complexity and cost"},{"location":"api/get/#example","text":"#include <iostream> #include <bulk/hub.hpp> #include <bulk/communication.hpp> #include <bulk/bsp/bulk.hpp> int main () { auto hub = bulk :: hub < bulk :: bsp :: provider > (); hub . spawn ( hub . available_processors (), [ & hub ]( int s , int ) { auto x = bulk :: create_var < int > ( hub ); auto y = bulk :: get ( hub . next_processor (), x ); // 1. hub . sync (); std :: cout << s << \" <- \" << y . value () << std :: endl ; }); return 0 ; }","title":"Example"},{"location":"api/log/","text":"bulk::log Not yet available","title":"`bulk::log`"},{"location":"api/log/#bulklog","text":"Not yet available","title":"bulk::log"},{"location":"api/put/","text":"bulk::put template < typename T , typename Hub > void put ( int processor , T value , var < T , Hub >& the_variable ); // 1. template < typename T , typename Hub > void put ( int processor , T value , array < T , Hub >& the_array , int offset = 0 , int count = 1 ); // 2. Put a value in a (remote) image of a variable (1.), or array (2.). Template parameters T - the value type of the variable/array Hub - the type of the hub that the variable/array belongs to Parameters processor - the index of the (remote) processor value - the value to write the_variable - the target variable the_array - the target array offset - the index of the array element to start writing at count - a number of elements to write Complexity and cost Cost sizeof(T) * g (sizeof(T) * count) * g Example #include <iostream> #include <bulk/hub.hpp> #include <bulk/communication.hpp> #include <bulk/bsp/bulk.hpp> int main () { auto hub = bulk :: hub < bulk :: bsp :: provider > (); hub . spawn ( hub . available_processors (), [ & hub ]( int s , int ) { auto x = bulk :: create_var < int > ( hub ); bulk :: put ( hub . next_processor (), s , x ); // 1. hub . sync (); std :: cout << s << \" <- \" << x . value () << std :: endl ; }); return 0 ; }","title":"`bulk::put`"},{"location":"api/put/#bulkput","text":"template < typename T , typename Hub > void put ( int processor , T value , var < T , Hub >& the_variable ); // 1. template < typename T , typename Hub > void put ( int processor , T value , array < T , Hub >& the_array , int offset = 0 , int count = 1 ); // 2. Put a value in a (remote) image of a variable (1.), or array (2.).","title":"bulk::put"},{"location":"api/put/#template-parameters","text":"T - the value type of the variable/array Hub - the type of the hub that the variable/array belongs to","title":"Template parameters"},{"location":"api/put/#parameters","text":"processor - the index of the (remote) processor value - the value to write the_variable - the target variable the_array - the target array offset - the index of the array element to start writing at count - a number of elements to write","title":"Parameters"},{"location":"api/put/#complexity-and-cost","text":"Cost sizeof(T) * g (sizeof(T) * count) * g","title":"Complexity and cost"},{"location":"api/put/#example","text":"#include <iostream> #include <bulk/hub.hpp> #include <bulk/communication.hpp> #include <bulk/bsp/bulk.hpp> int main () { auto hub = bulk :: hub < bulk :: bsp :: provider > (); hub . spawn ( hub . available_processors (), [ & hub ]( int s , int ) { auto x = bulk :: create_var < int > ( hub ); bulk :: put ( hub . next_processor (), s , x ); // 1. hub . sync (); std :: cout << s << \" <- \" << x . value () << std :: endl ; }); return 0 ; }","title":"Example"},{"location":"api/queue/","text":"bulk::queue Defined in header <bulk/messages.hpp> . template < typename T , typename ... Ts > class queue ; bulk::queue is an inbox for receiving messages passed by processors. Template parameters T - the type of the message content Ts - a parameter pack, optionally containing extra message content Note: content components of array type, e.g. T[] are also supported. They are represented by a std::vector<T> . Member types message_type : the underlying type used by the messages. Equal to: T if sizeof...(Ts) == 0 , std::tuple<T, Ts...> otherwise. iterator : the type of the iterator used for the local inbox Member functions (constructor) constructs the queue (deconstructor) deconstructs the queue operator= assign the queue Communication operator() obtain a sender to a remote queue Container begin obtain an iterator to the start end obtain an iterator to the end size obtain the number of messages empty check if the queue is empty World access world returns the world of the queue Nested classes sender : an object providing syntactic sugar for sending messages Example #include \"bulk/bulk.hpp\" #include \"set_backend.hpp\" int main () { environment env ; env . spawn ( env . available_processors (), []( bulk :: world & world ) { auto raw_queue = bulk :: queue < int > ( world ); raw_queue ( world . next_processor ()). send ( 1 ); raw_queue ( world . next_processor ()). send ( 2 ); raw_queue ( world . next_processor ()). send ( 123 ); auto tuple_queue = bulk :: queue < int , int , int > ( world ); tuple_queue ( world . next_processor ()). send ( 1 , 2 , 3 ); tuple_queue ( world . next_processor ()). send ( 4 , 5 , 6 ); world . sync (); // read queue for ( auto x : raw_queue ) { world . log ( \"the first queue received a message: %d\" , x ); } for ( auto [ i , j , k ] : tuple_queue ) { world . log ( \"the second queue received a tuple: (%d, %d, %d)\" , i , j , k ); } }); return 0 ; }","title":"queue"},{"location":"api/queue/#bulkqueue","text":"Defined in header <bulk/messages.hpp> . template < typename T , typename ... Ts > class queue ; bulk::queue is an inbox for receiving messages passed by processors.","title":"bulk::queue"},{"location":"api/queue/#template-parameters","text":"T - the type of the message content Ts - a parameter pack, optionally containing extra message content Note: content components of array type, e.g. T[] are also supported. They are represented by a std::vector<T> .","title":"Template parameters"},{"location":"api/queue/#member-types","text":"message_type : the underlying type used by the messages. Equal to: T if sizeof...(Ts) == 0 , std::tuple<T, Ts...> otherwise. iterator : the type of the iterator used for the local inbox","title":"Member types"},{"location":"api/queue/#member-functions","text":"(constructor) constructs the queue (deconstructor) deconstructs the queue operator= assign the queue Communication operator() obtain a sender to a remote queue Container begin obtain an iterator to the start end obtain an iterator to the end size obtain the number of messages empty check if the queue is empty World access world returns the world of the queue","title":"Member functions"},{"location":"api/queue/#nested-classes","text":"sender : an object providing syntactic sugar for sending messages","title":"Nested classes"},{"location":"api/queue/#example","text":"#include \"bulk/bulk.hpp\" #include \"set_backend.hpp\" int main () { environment env ; env . spawn ( env . available_processors (), []( bulk :: world & world ) { auto raw_queue = bulk :: queue < int > ( world ); raw_queue ( world . next_processor ()). send ( 1 ); raw_queue ( world . next_processor ()). send ( 2 ); raw_queue ( world . next_processor ()). send ( 123 ); auto tuple_queue = bulk :: queue < int , int , int > ( world ); tuple_queue ( world . next_processor ()). send ( 1 , 2 , 3 ); tuple_queue ( world . next_processor ()). send ( 4 , 5 , 6 ); world . sync (); // read queue for ( auto x : raw_queue ) { world . log ( \"the first queue received a message: %d\" , x ); } for ( auto [ i , j , k ] : tuple_queue ) { world . log ( \"the second queue received a tuple: (%d, %d, %d)\" , i , j , k ); } }); return 0 ; }","title":"Example"},{"location":"api/timer/","text":"bulk::util::timer Defined in header <bulk/util/timer.hpp> . class timer ; Constructs a timer that immediately starts ticking. bulk::util::timer::get template < typename resolution = std :: milli > double get () returns the number of (by default) milliseconds that have passed since the construction of the timer.","title":"timer"},{"location":"api/timer/#bulkutiltimer","text":"Defined in header <bulk/util/timer.hpp> . class timer ; Constructs a timer that immediately starts ticking.","title":"bulk::util::timer"},{"location":"api/timer/#bulkutiltimerget","text":"template < typename resolution = std :: milli > double get () returns the number of (by default) milliseconds that have passed since the construction of the timer.","title":"bulk::util::timer::get"},{"location":"api/unflatten/","text":"bulk::util::unflatten template < int D > std :: array < int , D > unflatten ( std :: array < int , D > volume , int flattened ); Unflatten a multi-index in a D-dimensional volume. Template parameters D - the dimension of the index space Parameters volume - the size of the volume idxs - the multi-index","title":"unflatten"},{"location":"api/unflatten/#bulkutilunflatten","text":"template < int D > std :: array < int , D > unflatten ( std :: array < int , D > volume , int flattened ); Unflatten a multi-index in a D-dimensional volume.","title":"bulk::util::unflatten"},{"location":"api/unflatten/#template-parameters","text":"D - the dimension of the index space","title":"Template parameters"},{"location":"api/unflatten/#parameters","text":"volume - the size of the volume idxs - the multi-index","title":"Parameters"},{"location":"api/var/","text":"bulk::var Defined in header <bulk/variable.hpp> . template < typename T > class var ; bulk::var represents a distributed object with an image on each processor. This image is readable and writable from remote processors. Template parameters T - the type of the values stored in the images of the variable. Member types value_type : the type of the distributed data (i.e. T ) Member functions (constructor) constructs the variable (deconstructor) deconstructs the variable operator= assign values to the variable Value access value returns the value of the local variable image operator T implicit cast to value reference Communication operator() obtain an image to a remote value broadcast broadcast a value to all remote images World access world returns the world of the variable Nested classes image : an object providing syntactic sugar for reading and writing to images. Example #include \"bulk/bulk.hpp\" #include \"set_backend.hpp\" int main () { environment env ; env . spawn ( env . available_processors (), []( bulk :: world & world ) { int s = world . processor_id (); int p = world . active_processors (); bulk :: var < int > a ( world ); a ( world . next_processor ()) = s ; world . sync (); world . log ( \"%d/%d <- %d\" , s , p , a . value ()); auto b = a ( world . next_processor ()). get (); world . sync (); world . log ( \"%d/%d -> %d\" , s , p , b . value ()); }); return 0 ; }","title":"var"},{"location":"api/var/#bulkvar","text":"Defined in header <bulk/variable.hpp> . template < typename T > class var ; bulk::var represents a distributed object with an image on each processor. This image is readable and writable from remote processors.","title":"bulk::var"},{"location":"api/var/#template-parameters","text":"T - the type of the values stored in the images of the variable.","title":"Template parameters"},{"location":"api/var/#member-types","text":"value_type : the type of the distributed data (i.e. T )","title":"Member types"},{"location":"api/var/#member-functions","text":"(constructor) constructs the variable (deconstructor) deconstructs the variable operator= assign values to the variable Value access value returns the value of the local variable image operator T implicit cast to value reference Communication operator() obtain an image to a remote value broadcast broadcast a value to all remote images World access world returns the world of the variable","title":"Member functions"},{"location":"api/var/#nested-classes","text":"image : an object providing syntactic sugar for reading and writing to images.","title":"Nested classes"},{"location":"api/var/#example","text":"#include \"bulk/bulk.hpp\" #include \"set_backend.hpp\" int main () { environment env ; env . spawn ( env . available_processors (), []( bulk :: world & world ) { int s = world . processor_id (); int p = world . active_processors (); bulk :: var < int > a ( world ); a ( world . next_processor ()) = s ; world . sync (); world . log ( \"%d/%d <- %d\" , s , p , a . value ()); auto b = a ( world . next_processor ()). get (); world . sync (); world . log ( \"%d/%d -> %d\" , s , p , b . value ()); }); return 0 ; }","title":"Example"},{"location":"api/world/","text":"bulk::world Defined in header <bulk/world.hpp> . class world ; bulk::world represents the world of a processor and its place within it, by providing information and mechanisms to communicate with other processors, or obtain information about the local processor. Member functions System information active_processors returns the number of active processors rank returns the id of the local processor next_rank returns the id of the next logical processor prev_rank returns the id of the previous logical processor Communication and coordination sync performs a bulk synchronization barrier performs a bulk barrier Example #include \"bulk/bulk.hpp\" #include \"set_backend.hpp\" int main () { environment env ; env . spawn ( env . available_processors (), []( bulk :: world & world ) { int s = world . rank (); int p = world . active_processors (); world . log ( \"Hello, world! %d/%d\" , s , p ); }); return 0 ; }","title":"world"},{"location":"api/world/#bulkworld","text":"Defined in header <bulk/world.hpp> . class world ; bulk::world represents the world of a processor and its place within it, by providing information and mechanisms to communicate with other processors, or obtain information about the local processor.","title":"bulk::world"},{"location":"api/world/#member-functions","text":"System information active_processors returns the number of active processors rank returns the id of the local processor next_rank returns the id of the next logical processor prev_rank returns the id of the previous logical processor Communication and coordination sync performs a bulk synchronization barrier performs a bulk barrier","title":"Member functions"},{"location":"api/world/#example","text":"#include \"bulk/bulk.hpp\" #include \"set_backend.hpp\" int main () { environment env ; env . spawn ( env . available_processors (), []( bulk :: world & world ) { int s = world . rank (); int p = world . active_processors (); world . log ( \"Hello, world! %d/%d\" , s , p ); }); return 0 ; }","title":"Example"},{"location":"api/coarray/constructor/","text":"bulk::coarray::coarray coarray ( world & world , int local_size ); // (1) coarray ( world & world , int local_size , T default_value ); // (2) Constructs a coarray of size p x local_size and registers it with world . \u2026 In addition, also initializes the elements as default_value . Parameters world - the world this variable belongs to local_size - the size of the coarray image of the local processor default_value - the initial value of the local coarray elements Complexity and cost Cost - l or free (backend dependent)","title":"coarray::constructor"},{"location":"api/coarray/constructor/#bulkcoarraycoarray","text":"coarray ( world & world , int local_size ); // (1) coarray ( world & world , int local_size , T default_value ); // (2) Constructs a coarray of size p x local_size and registers it with world . \u2026 In addition, also initializes the elements as default_value .","title":"bulk::coarray::coarray"},{"location":"api/coarray/constructor/#parameters","text":"world - the world this variable belongs to local_size - the size of the coarray image of the local processor default_value - the initial value of the local coarray elements","title":"Parameters"},{"location":"api/coarray/constructor/#complexity-and-cost","text":"Cost - l or free (backend dependent)","title":"Complexity and cost"},{"location":"api/coarray/deconstructor/","text":"bulk::coarray::~coarray ~ coarray (); Deconstructs a coarray and deregisters it with its world . Complexity and cost Cost - l or free (backend dependent)","title":"coarray::deconstructor"},{"location":"api/coarray/deconstructor/#bulkcoarraycoarray","text":"~ coarray (); Deconstructs a coarray and deregisters it with its world .","title":"bulk::coarray::~coarray"},{"location":"api/coarray/deconstructor/#complexity-and-cost","text":"Cost - l or free (backend dependent)","title":"Complexity and cost"},{"location":"api/coarray/image/","text":"bulk::coarray::image Defined in header <bulk/coarray.hpp> . class image ; A coarray image, allows for remote element access Member functions operator[] returns a writer to a remote image element bulk::coarray::image::operator[] writer operator []( int i ); parameters i - the index of the image element returns a bulk::coarray::writer to the remote image element","title":"coarray::image"},{"location":"api/coarray/image/#bulkcoarrayimage","text":"Defined in header <bulk/coarray.hpp> . class image ; A coarray image, allows for remote element access","title":"bulk::coarray::image"},{"location":"api/coarray/image/#member-functions","text":"operator[] returns a writer to a remote image element","title":"Member functions"},{"location":"api/coarray/image/#bulkcoarrayimageoperator","text":"writer operator []( int i ); parameters i - the index of the image element returns a bulk::coarray::writer to the remote image element","title":"bulk::coarray::image::operator[]"},{"location":"api/coarray/parentheses_operator/","text":"bulk::coarray::operator() image operator ()( int t ); Obtain an object encapsulating the image of the coarray. Parameters t - the image index","title":"coarray::operator()"},{"location":"api/coarray/parentheses_operator/#bulkcoarrayoperator","text":"image operator ()( int t ); Obtain an object encapsulating the image of the coarray.","title":"bulk::coarray::operator()"},{"location":"api/coarray/parentheses_operator/#parameters","text":"t - the image index","title":"Parameters"},{"location":"api/coarray/slice/","text":"bulk::coarray::slice Defined in header <bulk/coarray.hpp> . struct slice { int first ; int last ; };","title":"coarray::slice"},{"location":"api/coarray/slice/#bulkcoarrayslice","text":"Defined in header <bulk/coarray.hpp> . struct slice { int first ; int last ; };","title":"bulk::coarray::slice"},{"location":"api/coarray/slice_writer/","text":"bulk::coarray::slice_writer Defined in header <bulk/coarray.hpp> . class slice_writer ; Modify remote slices. Member functions operator= assign a value to a remote element get get a future to a slice bulk::coarray::slice_writer::operator= void operator = ( const std :: vector < T >& values ); parameters values - the new values of the slice bulk::coarray::slice_writer::get future < T [] > get (); returns a future array containing the slice","title":"coarray::slice_writer"},{"location":"api/coarray/slice_writer/#bulkcoarrayslice_writer","text":"Defined in header <bulk/coarray.hpp> . class slice_writer ; Modify remote slices.","title":"bulk::coarray::slice_writer"},{"location":"api/coarray/slice_writer/#member-functions","text":"operator= assign a value to a remote element get get a future to a slice","title":"Member functions"},{"location":"api/coarray/slice_writer/#bulkcoarrayslice_writeroperator","text":"void operator = ( const std :: vector < T >& values ); parameters values - the new values of the slice","title":"bulk::coarray::slice_writer::operator="},{"location":"api/coarray/slice_writer/#bulkcoarrayslice_writerget","text":"future < T [] > get (); returns a future array containing the slice","title":"bulk::coarray::slice_writer::get"},{"location":"api/coarray/square_brackets_operator/","text":"bulk::coarray::operator[] T & operator []( int i ); Access the i-th element of the local coarray image Returns A reference to the i-th element of the local image. Parameters i - the element index","title":"coarray::operator[]"},{"location":"api/coarray/square_brackets_operator/#bulkcoarrayoperator","text":"T & operator []( int i ); Access the i-th element of the local coarray image","title":"bulk::coarray::operator[]"},{"location":"api/coarray/square_brackets_operator/#returns","text":"A reference to the i-th element of the local image.","title":"Returns"},{"location":"api/coarray/square_brackets_operator/#parameters","text":"i - the element index","title":"Parameters"},{"location":"api/coarray/world/","text":"bulk::coarray::world bulk :: world & world (); Returns a reference to the world the variable belongs to Return value A reference to the world.","title":"coarray::world"},{"location":"api/coarray/world/#bulkcoarrayworld","text":"bulk :: world & world (); Returns a reference to the world the variable belongs to","title":"bulk::coarray::world"},{"location":"api/coarray/world/#return-value","text":"A reference to the world.","title":"Return value"},{"location":"api/coarray/writer/","text":"bulk::coarray::writer Defined in header <bulk/coarray.hpp> . class writer ; A coarray image writer, allows for the modification of remote elements. Member functions operator= assign a value to a remote element get obtain a remote value bulk::coarray::writer::operator= void operator = ( T value ); parameters value - the new value of the element bulk::coarray::writer::get future < T > get (); returns a future to the element","title":"coarray::writer"},{"location":"api/coarray/writer/#bulkcoarraywriter","text":"Defined in header <bulk/coarray.hpp> . class writer ; A coarray image writer, allows for the modification of remote elements.","title":"bulk::coarray::writer"},{"location":"api/coarray/writer/#member-functions","text":"operator= assign a value to a remote element get obtain a remote value","title":"Member functions"},{"location":"api/coarray/writer/#bulkcoarraywriteroperator","text":"void operator = ( T value ); parameters value - the new value of the element","title":"bulk::coarray::writer::operator="},{"location":"api/coarray/writer/#bulkcoarraywriterget","text":"future < T > get (); returns a future to the element","title":"bulk::coarray::writer::get"},{"location":"api/environment/available_processors/","text":"bulk::environment::available_processors int available_processors () const ; Returns the total number of processors available on the system. Return value int : The number of available processors.","title":"environment::available_processors"},{"location":"api/environment/available_processors/#bulkenvironmentavailable_processors","text":"int available_processors () const ; Returns the total number of processors available on the system.","title":"bulk::environment::available_processors"},{"location":"api/environment/available_processors/#return-value","text":"int : The number of available processors.","title":"Return value"},{"location":"api/environment/spawn/","text":"bulk::environment::spawn void spawn ( int processors , std :: function < void ( bulk :: world & ) > spmd ); Start an SPMD section on a given number of processors. Parameters processors - the number of processors to run the SPMD section on. spmd - the SPMD function that gets run on each (virtual) processor. A reference to the world of the processor will be passed as the first and only argument.","title":"environment::spawn"},{"location":"api/environment/spawn/#bulkenvironmentspawn","text":"void spawn ( int processors , std :: function < void ( bulk :: world & ) > spmd ); Start an SPMD section on a given number of processors.","title":"bulk::environment::spawn"},{"location":"api/environment/spawn/#parameters","text":"processors - the number of processors to run the SPMD section on. spmd - the SPMD function that gets run on each (virtual) processor. A reference to the world of the processor will be passed as the first and only argument.","title":"Parameters"},{"location":"api/future/assignment_operator/","text":"bulk::future::operator= void operator = ( future < T >&& other ); Move assignment operator. Replaces the target future *this with the source future other , and invalidates the source. Parameters other - another future to move away from","title":"future::operator="},{"location":"api/future/assignment_operator/#bulkfutureoperator","text":"void operator = ( future < T >&& other ); Move assignment operator. Replaces the target future *this with the source future other , and invalidates the source.","title":"bulk::future::operator="},{"location":"api/future/assignment_operator/#parameters","text":"other - another future to move away from","title":"Parameters"},{"location":"api/future/bracket_operator/","text":"bulk::future<T[]>::operator[] T & operator []( int i ); Access the i-th element of the array image of the future. Returns A reference to the i-th element of the future. Parameters i - the element index","title":"future::operator[]"},{"location":"api/future/bracket_operator/#bulkfuturelttgtoperator","text":"T & operator []( int i ); Access the i-th element of the array image of the future.","title":"bulk::future&lt;T[]&gt;::operator[]"},{"location":"api/future/bracket_operator/#returns","text":"A reference to the i-th element of the future.","title":"Returns"},{"location":"api/future/bracket_operator/#parameters","text":"i - the element index","title":"Parameters"},{"location":"api/future/constructor/","text":"bulk::future::future future ( world & world ); Constructs a message future for use in world . Parameters world - the world this future belongs to","title":"future::constructor"},{"location":"api/future/constructor/#bulkfuturefuture","text":"future ( world & world ); Constructs a message future for use in world .","title":"bulk::future::future"},{"location":"api/future/constructor/#parameters","text":"world - the world this future belongs to","title":"Parameters"},{"location":"api/future/deconstructor/","text":"bulk::future::~future ~ future (); Deconstructs a future and invalidates its buffer.","title":"future::deconstructor"},{"location":"api/future/deconstructor/#bulkfuturefuture","text":"~ future (); Deconstructs a future and invalidates its buffer.","title":"bulk::future::~future"},{"location":"api/future/value/","text":"bulk::future::value T & value (); Returns a reference to the value held by the future Return value A reference to the value Note This becomes valid after the next global synchronisation upon the initialization of the value of the future using e.g. bulk::get .","title":"future::value"},{"location":"api/future/value/#bulkfuturevalue","text":"T & value (); Returns a reference to the value held by the future","title":"bulk::future::value"},{"location":"api/future/value/#return-value","text":"A reference to the value","title":"Return value"},{"location":"api/future/value/#note","text":"This becomes valid after the next global synchronisation upon the initialization of the value of the future using e.g. bulk::get .","title":"Note"},{"location":"api/future/world/","text":"bulk::future::world bulk :: world & world (); Returns a reference to the world the future belongs to Return value A reference to the world.","title":"future::world"},{"location":"api/future/world/#bulkfutureworld","text":"bulk :: world & world (); Returns a reference to the world the future belongs to","title":"bulk::future::world"},{"location":"api/future/world/#return-value","text":"A reference to the world.","title":"Return value"},{"location":"api/queue/begin/","text":"bulk::queue::begin iterator begin (); Obtain an iterator to the begin of the local queue. Return value an iterator to the begin of the local queue","title":"queue::begin"},{"location":"api/queue/begin/#bulkqueuebegin","text":"iterator begin (); Obtain an iterator to the begin of the local queue.","title":"bulk::queue::begin"},{"location":"api/queue/begin/#return-value","text":"an iterator to the begin of the local queue","title":"Return value"},{"location":"api/queue/constructor/","text":"bulk::queue::queue queue ( world & world ); Constructs a message queue for use in world . Parameters world - the world this queue belongs to","title":"queue::constructor"},{"location":"api/queue/constructor/#bulkqueuequeue","text":"queue ( world & world ); Constructs a message queue for use in world .","title":"bulk::queue::queue"},{"location":"api/queue/constructor/#parameters","text":"world - the world this queue belongs to","title":"Parameters"},{"location":"api/queue/deconstructor/","text":"bulk::queue::~queue ~ queue (); Deconstructs a queue, clears and deregisters it.","title":"queue::deconstructor"},{"location":"api/queue/deconstructor/#bulkqueuequeue","text":"~ queue (); Deconstructs a queue, clears and deregisters it.","title":"bulk::queue::~queue"},{"location":"api/queue/empty/","text":"bulk::queue::empty bool empty () const ; Checks whether the inbox is empty. Return value true if the inbox is empty, false otherwise.","title":"queue::empty"},{"location":"api/queue/empty/#bulkqueueempty","text":"bool empty () const ; Checks whether the inbox is empty.","title":"bulk::queue::empty"},{"location":"api/queue/empty/#return-value","text":"true if the inbox is empty, false otherwise.","title":"Return value"},{"location":"api/queue/end/","text":"bulk::queue::end iterator end (); Obtain an iterator to the end of the local queue. Return value an iterator to the end of the local queue","title":"queue::end"},{"location":"api/queue/end/#bulkqueueend","text":"iterator end (); Obtain an iterator to the end of the local queue.","title":"bulk::queue::end"},{"location":"api/queue/end/#return-value","text":"an iterator to the end of the local queue","title":"Return value"},{"location":"api/queue/sender/","text":"bulk::queue::sender Defined in header <bulk/messages.hpp> . class sender ; Provides a way to send messages to remote queues. Member functions Value access send assign values to the variable","title":"queue::sender"},{"location":"api/queue/sender/#bulkqueuesender","text":"Defined in header <bulk/messages.hpp> . class sender ; Provides a way to send messages to remote queues.","title":"bulk::queue::sender"},{"location":"api/queue/sender/#member-functions","text":"Value access send assign values to the variable","title":"Member functions"},{"location":"api/queue/size/","text":"bulk::queue::size size_t size () const ; Obtain the number of messages in the local queue. Return value the number of messages in the local queue","title":"queue::size"},{"location":"api/queue/size/#bulkqueuesize","text":"size_t size () const ; Obtain the number of messages in the local queue.","title":"bulk::queue::size"},{"location":"api/queue/size/#return-value","text":"the number of messages in the local queue","title":"Return value"},{"location":"api/queue/world/","text":"bulk::queue::world bulk :: world & world (); Returns a reference to the world the queue belongs to Return value A reference to the world.","title":"queue::world"},{"location":"api/queue/world/#bulkqueueworld","text":"bulk :: world & world (); Returns a reference to the world the queue belongs to","title":"bulk::queue::world"},{"location":"api/queue/world/#return-value","text":"A reference to the world.","title":"Return value"},{"location":"api/queue/sender/send/","text":"bulk::queue::sender::send template < typename ... Us > void send ( Us ... args ) Send a message to a remote queue Parameters args - the content to send Complexity and cost Cost - sizeof(Us...) * g","title":"queue::sender::send"},{"location":"api/queue/sender/send/#bulkqueuesendersend","text":"template < typename ... Us > void send ( Us ... args ) Send a message to a remote queue","title":"bulk::queue::sender::send"},{"location":"api/queue/sender/send/#parameters","text":"args - the content to send","title":"Parameters"},{"location":"api/queue/sender/send/#complexity-and-cost","text":"Cost - sizeof(Us...) * g","title":"Complexity and cost"},{"location":"api/var/T_operator/","text":"bulk::var::operator T operator T & (); operator const T & (); Obtain an implicit (const) reference to the value of the local image. Example This allows for convenient syntax when working with local images, e.g.: auto x = bulk :: var < int > ( world , 5 ); auto y = x + 5 ; // y is an int with value 10","title":"var::operator T"},{"location":"api/var/T_operator/#bulkvaroperator-t","text":"operator T & (); operator const T & (); Obtain an implicit (const) reference to the value of the local image.","title":"bulk::var::operator T"},{"location":"api/var/T_operator/#example","text":"This allows for convenient syntax when working with local images, e.g.: auto x = bulk :: var < int > ( world , 5 ); auto y = x + 5 ; // y is an int with value 10","title":"Example"},{"location":"api/var/assignment_operator/","text":"bulk::var::operator= void operator = ( var < T >&& other ); Move assignment operator. Replaces the target variable *this with the source variable other , and invalidates the source. Parameters other - another variable to move away from Complexity and cost Cost - l or free (backend dependent)","title":"var::operator="},{"location":"api/var/assignment_operator/#bulkvaroperator","text":"void operator = ( var < T >&& other ); Move assignment operator. Replaces the target variable *this with the source variable other , and invalidates the source.","title":"bulk::var::operator="},{"location":"api/var/assignment_operator/#parameters","text":"other - another variable to move away from","title":"Parameters"},{"location":"api/var/assignment_operator/#complexity-and-cost","text":"Cost - l or free (backend dependent)","title":"Complexity and cost"},{"location":"api/var/broadcast/","text":"bulk::var::broadcast void broadcast ( T x ); Broadcasts a value to all images. For one variable, this function should be called by a single processor in any given superstep. The broadcasted value is valid starting from the subsequent superstep. Parameters x - the value to broadcast Complexity and cost Cost - p * g","title":"var::broadcast"},{"location":"api/var/broadcast/#bulkvarbroadcast","text":"void broadcast ( T x ); Broadcasts a value to all images. For one variable, this function should be called by a single processor in any given superstep. The broadcasted value is valid starting from the subsequent superstep.","title":"bulk::var::broadcast"},{"location":"api/var/broadcast/#parameters","text":"x - the value to broadcast","title":"Parameters"},{"location":"api/var/broadcast/#complexity-and-cost","text":"Cost - p * g","title":"Complexity and cost"},{"location":"api/var/constructor/","text":"bulk::var::var var ( world & world ); // (1) var ( world & world , T value ); // (2) Constructs a variable and registers it with world . Requires T to be trivially constructable. \u2026 In addition, set the initial value of the local image to value . Parameters world - the world this variable belongs to value - initial value of the local image Complexity and cost Cost - l or free (backend dependent)","title":"var::constructor"},{"location":"api/var/constructor/#bulkvarvar","text":"var ( world & world ); // (1) var ( world & world , T value ); // (2) Constructs a variable and registers it with world . Requires T to be trivially constructable. \u2026 In addition, set the initial value of the local image to value .","title":"bulk::var::var"},{"location":"api/var/constructor/#parameters","text":"world - the world this variable belongs to value - initial value of the local image","title":"Parameters"},{"location":"api/var/constructor/#complexity-and-cost","text":"Cost - l or free (backend dependent)","title":"Complexity and cost"},{"location":"api/var/deconstructor/","text":"bulk::var::~var ~ var (); Deconstructs a variable and deregisters it with its world . Complexity and cost Cost - l or free, depending on the backend","title":"var::deconstructor"},{"location":"api/var/deconstructor/#bulkvarvar","text":"~ var (); Deconstructs a variable and deregisters it with its world .","title":"bulk::var::~var"},{"location":"api/var/deconstructor/#complexity-and-cost","text":"Cost - l or free, depending on the backend","title":"Complexity and cost"},{"location":"api/var/image/","text":"bulk::var::image Defined in header <bulk/variable.hpp> . class image ; bulk::var::image provides syntactic sugar for dealing with remote images. Member functions Value access operator= assign values to the variable get returns the value of the local variable image","title":"var::image"},{"location":"api/var/image/#bulkvarimage","text":"Defined in header <bulk/variable.hpp> . class image ; bulk::var::image provides syntactic sugar for dealing with remote images.","title":"bulk::var::image"},{"location":"api/var/image/#member-functions","text":"Value access operator= assign values to the variable get returns the value of the local variable image","title":"Member functions"},{"location":"api/var/paren_operator/","text":"bulk::var::operator() image operator ()( int t ); Obtain an image object, used to communicate with a remote image. Parameters t - the id of the remote processor","title":"var::operator()"},{"location":"api/var/paren_operator/#bulkvaroperator","text":"image operator ()( int t ); Obtain an image object, used to communicate with a remote image.","title":"bulk::var::operator()"},{"location":"api/var/paren_operator/#parameters","text":"t - the id of the remote processor","title":"Parameters"},{"location":"api/var/value/","text":"bulk::var::value T & value (); Returns a reference to the value held by the local image of the variable. Return value A reference to the value of the local image","title":"var::value"},{"location":"api/var/value/#bulkvarvalue","text":"T & value (); Returns a reference to the value held by the local image of the variable.","title":"bulk::var::value"},{"location":"api/var/value/#return-value","text":"A reference to the value of the local image","title":"Return value"},{"location":"api/var/world/","text":"bulk::var::world bulk :: world & world (); Returns a reference to the world the variable belongs to Return value A reference to the world.","title":"var::world"},{"location":"api/var/world/#bulkvarworld","text":"bulk :: world & world (); Returns a reference to the world the variable belongs to","title":"bulk::var::world"},{"location":"api/var/world/#return-value","text":"A reference to the world.","title":"Return value"},{"location":"api/var/image/assignment_operator/","text":"bulk::var::image::operator= var < T >& operator = ( const T & value ); Assign a value to a remote image Parameters value - the new value of the image Complexity and cost Cost - sizeof(T) * g","title":"var::image::operator="},{"location":"api/var/image/assignment_operator/#bulkvarimageoperator","text":"var < T >& operator = ( const T & value ); Assign a value to a remote image","title":"bulk::var::image::operator="},{"location":"api/var/image/assignment_operator/#parameters","text":"value - the new value of the image","title":"Parameters"},{"location":"api/var/image/assignment_operator/#complexity-and-cost","text":"Cost - sizeof(T) * g","title":"Complexity and cost"},{"location":"api/var/image/get/","text":"bulk::var::image::get future < T > get () const ; Obtain a future to a remote image value Complexity and cost Cost - sizeof(T) * g ;","title":"var::image::get"},{"location":"api/var/image/get/#bulkvarimageget","text":"future < T > get () const ; Obtain a future to a remote image value","title":"bulk::var::image::get"},{"location":"api/var/image/get/#complexity-and-cost","text":"Cost - sizeof(T) * g ;","title":"Complexity and cost"},{"location":"api/world/active_processors/","text":"bulk::world::active_processors int active_processors () const ; Returns the total number of active processors in an SPMD section. Return value int : The number of active processors.","title":"world::active_processors"},{"location":"api/world/active_processors/#bulkworldactive_processors","text":"int active_processors () const ; Returns the total number of active processors in an SPMD section.","title":"bulk::world::active_processors"},{"location":"api/world/active_processors/#return-value","text":"int : The number of active processors.","title":"Return value"},{"location":"api/world/barrier/","text":"bulk::world::barrier void barrier () const ; Performs a global barrier of the active processors. Complexity and cost Cost - l (approximately)","title":"world::barrier"},{"location":"api/world/barrier/#bulkworldbarrier","text":"void barrier () const ; Performs a global barrier of the active processors.","title":"bulk::world::barrier"},{"location":"api/world/barrier/#complexity-and-cost","text":"Cost - l (approximately)","title":"Complexity and cost"},{"location":"api/world/next_rank/","text":"bulk::world::next_rank int next_rank () const ; Returns the id of the next logical processor. Return value int : The id of the next processor","title":"world::next_rank"},{"location":"api/world/next_rank/#bulkworldnext_rank","text":"int next_rank () const ; Returns the id of the next logical processor.","title":"bulk::world::next_rank"},{"location":"api/world/next_rank/#return-value","text":"int : The id of the next processor","title":"Return value"},{"location":"api/world/prev_rank/","text":"bulk::world::prev_rank int prev_rank () const ; Returns the id of the previous logical processor. Return value int : The id of the previous processor","title":"world::prev_rank"},{"location":"api/world/prev_rank/#bulkworldprev_rank","text":"int prev_rank () const ; Returns the id of the previous logical processor.","title":"bulk::world::prev_rank"},{"location":"api/world/prev_rank/#return-value","text":"int : The id of the previous processor","title":"Return value"},{"location":"api/world/rank/","text":"bulk::world::rank int rank () const ; Returns the local processor id Return value int : The id of the local processor.","title":"world::rank"},{"location":"api/world/rank/#bulkworldrank","text":"int rank () const ; Returns the local processor id","title":"bulk::world::rank"},{"location":"api/world/rank/#return-value","text":"int : The id of the local processor.","title":"Return value"},{"location":"api/world/sync/","text":"bulk::world::sync void sync () const ; Performs a global barrier synchronization of the active processors, resolving any outstanding communication. Complexity and cost Cost - l","title":"world::sync"},{"location":"api/world/sync/#bulkworldsync","text":"void sync () const ; Performs a global barrier synchronization of the active processors, resolving any outstanding communication.","title":"bulk::world::sync"},{"location":"api/world/sync/#complexity-and-cost","text":"Cost - l","title":"Complexity and cost"},{"location":"backends/mpi/","text":"MPI If you choose to use the MPI backend, then simply include the Bulk headers, and set up your project build as though it is an MPI project. We suggest to use the OpenMPI implementation, since is the implementation we test against.","title":"MPI"},{"location":"backends/mpi/#mpi","text":"If you choose to use the MPI backend, then simply include the Bulk headers, and set up your project build as though it is an MPI project. We suggest to use the OpenMPI implementation, since is the implementation we test against.","title":"MPI"},{"location":"backends/thread/","text":"<thread> This backend uses the shared-memory parallelism provided by the standard C++ library <thread> . To use it on Linux, link against the pthread library. There are two supported barrier implementations, a mutex-based barrier and the (default) spinlock-based barrier. The mutex barrier is more energy efficient, while the spinlock barrier is significantly faster. Choosing the barrier can be done by passing a template argument to bulk::thread::environment_ , while bulk::thread::environment is a non-template type alias to the environment using the default barrier implementation. // default (with spinning barrier) auto env = bulk :: thread :: environment ; // explicit (with spinning barrier) auto env = bulk :: thread :: environment_ < bulk :: thread :: spinning_barrier > ; // explicit (with mutex barrier) auto env = bulk :: thread :: environment_ < bulk :: thread :: mutex_barrier > ;","title":"thread"},{"location":"backends/thread/#ltthreadgt","text":"This backend uses the shared-memory parallelism provided by the standard C++ library <thread> . To use it on Linux, link against the pthread library. There are two supported barrier implementations, a mutex-based barrier and the (default) spinlock-based barrier. The mutex barrier is more energy efficient, while the spinlock barrier is significantly faster. Choosing the barrier can be done by passing a template argument to bulk::thread::environment_ , while bulk::thread::environment is a non-template type alias to the environment using the default barrier implementation. // default (with spinning barrier) auto env = bulk :: thread :: environment ; // explicit (with spinning barrier) auto env = bulk :: thread :: environment_ < bulk :: thread :: spinning_barrier > ; // explicit (with mutex barrier) auto env = bulk :: thread :: environment_ < bulk :: thread :: mutex_barrier > ;","title":"&lt;thread&gt;"}]}