{
    "docs": [
        {
            "location": "/",
            "text": "Bulk\n\u00b6\n\n\n\n\n\n\n\n\nBulk is a new interface for writing parallel programs in C++ in bulk-synchronous style. The library does away with the unnecessary boilerplate and ubiquitous pointer arithmetic that is found in libraries based on for example MPI, or the BSPlib standard. Our BSP interface supports and encourages the use of modern C++ features such as smart pointers, range based for loops and anonymous functions, enabling safer and more efficient distributed programming. The flexible backend architecture ensures the portability of parallel programs written with Bulk.\n\n\nAuthors\n\u00b6\n\n\nBulk is developed by:\n\n\n\n\nJan-Willem Buurlage (jwbuurlage)\n\n\nTom Bannink (tombana)\n\n\n\n\nExamples\n\u00b6\n\n\nHello world!\n\n\nbulk\n::\nthread\n::\nenvironment\n \nenv\n;\n\n\nenv\n.\nspawn\n(\nenv\n.\navailable_processors\n(),\n \n[](\nauto\n&\n \nworld\n)\n \n{\n\n    \nauto\n \ns\n \n=\n \nworld\n.\nprocessor_id\n();\n\n    \nauto\n \np\n \n=\n \nworld\n.\nactive_processors\n();\n\n\n    \nworld\n.\nlog\n(\n\"Hello world from processor %d / %d\n\\n\n\"\n,\n \ns\n,\n \np\n);\n\n\n});\n\n\n\n\n\n\nDistributed variables are the easiest way to communicate.\n\n\nauto\n \na\n \n=\n \nbulk\n::\nvar\n<\nint\n>\n(\nworld\n);\n\n\na\n(\nworld\n.\nnext_processor\n())\n \n=\n \ns\n;\n\n\nworld\n.\nsync\n();\n\n\n// ... a is now updated\n\n\n\nauto\n \nb\n \n=\n \na\n(\nworld\n.\nnext_processor\n()).\nget\n();\n\n\nworld\n.\nsync\n();\n\n\n// ... b.value() is now available\n\n\n\n\n\n\nCoarrays provide a convenient syntax for working with distributed arrays.\n\n\nauto\n \nxs\n \n=\n \nbulk\n::\ncoarray\n<\nint\n>\n(\nworld\n,\n \n10\n);\n\n\nxs\n(\nworld\n.\nnext_processor\n())[\n3\n]\n \n=\n \ns\n;\n\n\n\n\n\n\nMessage passing can be used for more flexible communication.\n\n\nauto\n \nq\n \n=\n \nbulk\n::\nqueue\n<\nint\n,\n \nfloat\n>\n(\nworld\n);\n\n\nfor\n \n(\nint\n \nt\n \n=\n \n0\n;\n \nt\n \n<\n \np\n;\n \n++\nt\n)\n \n{\n\n    \nq\n(\nt\n).\nsend\n(\ns\n,\n \n3.1415f\n);\n  \n// send (s, pi) to processor t\n\n\n}\n\n\nworld\n.\nsync\n();\n\n\n\n// messages are now available in q\n\n\nfor\n \n(\nauto\n \n[\ntag\n,\n \ncontent\n]\n \n:\n \nq\n)\n \n{\n\n    \nworld\n.\nlog\n(\n\"%d got sent %d, %f\n\\n\n\"\n,\n \ns\n,\n \ntag\n,\n \ncontent\n);\n\n\n}\n\n\n\n\n\n\nAPI\n\u00b6\n\n\nBulk provides a modern bulk-synchronous parallel API which is \ndocumented in detail here\n.\n\n\nLicense\n\u00b6\n\n\nBulk is released under the MIT license, for details see the file LICENSE.md.\n\n\nContributing\n\u00b6\n\n\nWe welcome contributions. Please submit pull requests against the develop branch.",
            "title": "Home"
        },
        {
            "location": "/#bulk",
            "text": "Bulk is a new interface for writing parallel programs in C++ in bulk-synchronous style. The library does away with the unnecessary boilerplate and ubiquitous pointer arithmetic that is found in libraries based on for example MPI, or the BSPlib standard. Our BSP interface supports and encourages the use of modern C++ features such as smart pointers, range based for loops and anonymous functions, enabling safer and more efficient distributed programming. The flexible backend architecture ensures the portability of parallel programs written with Bulk.",
            "title": "Bulk"
        },
        {
            "location": "/#authors",
            "text": "Bulk is developed by:   Jan-Willem Buurlage (jwbuurlage)  Tom Bannink (tombana)",
            "title": "Authors"
        },
        {
            "location": "/#examples",
            "text": "Hello world!  bulk :: thread :: environment   env ;  env . spawn ( env . available_processors (),   []( auto &   world )   { \n     auto   s   =   world . processor_id (); \n     auto   p   =   world . active_processors (); \n\n     world . log ( \"Hello world from processor %d / %d \\n \" ,   s ,   p );  });   Distributed variables are the easiest way to communicate.  auto   a   =   bulk :: var < int > ( world );  a ( world . next_processor ())   =   s ;  world . sync ();  // ... a is now updated  auto   b   =   a ( world . next_processor ()). get ();  world . sync ();  // ... b.value() is now available   Coarrays provide a convenient syntax for working with distributed arrays.  auto   xs   =   bulk :: coarray < int > ( world ,   10 );  xs ( world . next_processor ())[ 3 ]   =   s ;   Message passing can be used for more flexible communication.  auto   q   =   bulk :: queue < int ,   float > ( world );  for   ( int   t   =   0 ;   t   <   p ;   ++ t )   { \n     q ( t ). send ( s ,   3.1415f );    // send (s, pi) to processor t  }  world . sync ();  // messages are now available in q  for   ( auto   [ tag ,   content ]   :   q )   { \n     world . log ( \"%d got sent %d, %f \\n \" ,   s ,   tag ,   content );  }",
            "title": "Examples"
        },
        {
            "location": "/#api",
            "text": "Bulk provides a modern bulk-synchronous parallel API which is  documented in detail here .",
            "title": "API"
        },
        {
            "location": "/#license",
            "text": "Bulk is released under the MIT license, for details see the file LICENSE.md.",
            "title": "License"
        },
        {
            "location": "/#contributing",
            "text": "We welcome contributions. Please submit pull requests against the develop branch.",
            "title": "Contributing"
        },
        {
            "location": "/getting_started/",
            "text": "The easiest way to get started using Bulk is to download the source code from \nGitHub\n. If you use Bulk in a project we suggest to add Bulk as a submodule, since it is in active development.\n\n\nBulk requires an up-to-date compiler, that supports C++17, e.g. GCC >= 7.0, or Clang >= 4.0. As of now, we only provide support for Linux, but there is, and will not be, any platform specific code in the library.\n\n\nBulk supports a number of different \nbackends\n, allowing the programs to run in parallel using:\n\n\n\n\nthread\n for multi-core systems using standard C++ \n<thread>\n threading support\n\n\nmpi\n for distributed environments using MPI. We suggest to use the OpenMPI implementation, since is the implementation we test against.\n\n\n\n\nThe examples in the \nexamples\n directory work for every backend. They are built separately for each backend. The backends (e.g. \nthread\n, \nmpi\n) are built optionally, just remove or add the option if you do not require them.\n\n\nmkdir build\ncd build\ncmake ..\nmake thread mpi\n\n\n\n\n\nThe examples will be compiled in the \nbin/{backend}\n directory, prepended with the backend name, i.e. to run the \nhello\n example with the \nthread\n backend:\n\n\n./bin/thread/thread_hello\n\n\n\n\n\nUsing Bulk in a project\n\u00b6\n\n\nTo use Bulk in a project managed with git, add it as a submodule:\n\n\ngit submodule add https://www.github.com/jwbuurlage/bulk ext/bulk\ngit submodule update --init --remote\n\n\n\n\n\nAnd add \next/bulk/include\n as an include directory when building.\n\n\nThe entire library is header only, but backends may have dependencies. See their documentation for details.",
            "title": "Getting started"
        },
        {
            "location": "/getting_started/#using-bulk-in-a-project",
            "text": "To use Bulk in a project managed with git, add it as a submodule:  git submodule add https://www.github.com/jwbuurlage/bulk ext/bulk\ngit submodule update --init --remote  And add  ext/bulk/include  as an include directory when building.  The entire library is header only, but backends may have dependencies. See their documentation for details.",
            "title": "Using Bulk in a project"
        },
        {
            "location": "/tour/",
            "text": "A tour of Bulk\n\u00b6\n\n\nOn this page we aim to highlight some of the main features of the\nlibrary, and to give an impression of the overall syntax.\n\n\nHello \nbulk::world\n!\n\u00b6\n\n\nWe start out with the obligatory Hello World! in Bulk , and subsequently\nexplain the code line-by-line. In this code we will use the \nMPI\n\nbackend, but everything written here is completely general, and\nguarenteed to work on top of any conforming Bulk backend.\n\n\n#include\n \n<bulk/bulk.hpp>\n\n\n#include\n \n<bulk/backends/mpi/mpi.hpp>\n\n\n\nint\n \nmain\n()\n \n{\n\n    \nbulk\n::\nmpi\n::\nenvironment\n \nenv\n;\n\n    \nenv\n.\nspawn\n(\nenv\n.\navailable_processors\n(),\n \n[](\nauto\n&\n \nworld\n)\n \n{\n\n        \nauto\n \ns\n \n=\n \nworld\n.\nprocessor_id\n();\n\n        \nauto\n \np\n \n=\n \nworld\n.\nactive_processors\n();\n\n\n        \nworld\n.\nlog\n(\n\"Hello world from processor %d / %d!\"\n,\n \ns\n,\n \np\n);\n\n    \n});\n\n\n}\n\n\n\n\n\n\nOn lines 1 and 2 we include the library, and the backend of our choosing\n(in our case MPI). On line 5, we initialize an \nenvironment\n, which\nsets up the parallel or distributed system.\n\n\nOn line 6, we spawn the \nSPMD\n section of our program within the\nenvironment. The first argument denotes the number of processors that we\nwant to run the section on, while the second argument provides a\nfunction-like object (here a C++ lambda function) that is executed on\nthe requested number of processors. This function obtains a\n\nbulk::world\n object, which it can use to communicate with other\nprocessors, for programmer convenience its identifier \ns\n\nand the total number of processes that are spawned \np\n are\npassed as well. These can alternatively be obtained from world using\n\nworld.processor_id()\n and\n\nworld.active_processors()\n respectively.\n\n\nCommunication between processors\n\u00b6\n\n\nNext, we look at some basic forms of communication between processors.\nThe main way to \ntalk\n to other processors, is by using variables. A\nvariable is created as follows:\n\n\nauto\n \nx\n \n=\n \nbulk\n::\nvar\n<\nT\n>\n(\nworld\n);\n\n\n\n\n\n\nHere, \nT\n is the type of the variable, for example an\n\nint\n. Values can be assigned to the (local) variable:\n\n\nx\n \n=\n \n5\n;\n\n\n\n\n\n\nThe reason to use a variable, is that a processor can \nwrite\n to a\nremote \nimage\n of a variable.\n\n\nbulk\n::\nput\n(\nworld\n.\nnext_processor\n(),\n \n4\n,\n \nx\n);\n\n\n\n\n\n\nThis will overwrite the value of the variable \nx\n on the\nnext logical processor (i.e. processor \ns + 1 % p\n) with\n\n4\n. We can obtain the value of a remote image using:\n\n\nauto\n \ny\n \n=\n \nbulk\n::\nget\n(\nworld\n.\nnext_processor\n(),\n \nx\n);\n\n\n\n\n\n\nHere, \ny\n is a \nbulk::future\n object. A future\nobject does not immediately hold the remote value of \nx\n,\nbut after a \nfuture\n call to \nworld.sync()\n, we can extract\nthe remote value out of \ny\n.\n\n\nworld\n.\nsync\n();\n\n\nauto\n \nx_next\n \n=\n \ny\n.\nvalue\n();\n\n\n\n\n\n\nCoarrays\n\u00b6\n\n\nCoarrays are a convenient way to store, and manipulate distributed\ndata. We provide a co-array that is modeled after \nCoarray\nFortran\n. Arrays are\ninitialized and used as follows:\n\n\nauto\n \nxs\n \n=\n \nbulk\n::\ncoarray\n<\nint\n>\n(\nworld\n,\n \ns\n);\n\n\nxs\n(\n3\n)[\n2\n]\n \n=\n \n1\n;\n\n\n\n\n\n\nHere, we create a co-array of varying local size (each processor holds\n\ns\n many elements). Next we write the value\n\n1\n to the element with local index \n2\n on\nprocessor with index \n3\n.\n\n\nAlgorithmic skeletons\n\u00b6\n\n\ncomes equipped with a number of higher-level functions, also known as\n\nalgorithmic skeletons\n. For example, say we want to compute the\ndot-product of two coarrays, then we write this as:\n\n\nauto\n \nxs\n \n=\n \nbulk\n::\ncoarray\n<\nint\n>\n(\nworld\n,\n \ns\n);\n\n\nauto\n \nys\n \n=\n \nbulk\n::\ncoarray\n<\nint\n>\n(\nworld\n,\n \ns\n);\n\n\n\n// fill xs and ys with data\n\n\nauto\n \nresult\n \n=\n \nbulk\n::\nvar\n<\nint\n>\n(\nworld\n);\n\n\nfor\n \n(\nint\n \ni\n \n=\n \n0\n;\n \ni\n \n<\n \ns\n;\n \n++\ni\n)\n \n{\n\n    \nresult\n.\nvalue\n()\n \n+=\n \nxs\n[\ni\n]\n \n*\n \nys\n[\ni\n];\n\n\n}\n\n\n\n// reduce to find global dot product\n\n\nauto\n \nalpha\n \n=\n \nbulk\n::\nfoldl\n(\nresult\n,\n \n[](\nint\n&\n \nlhs\n,\n \nint\n \nrhs\n)\n \n{\n \nlhs\n \n+=\n \nrhs\n;\n \n});\n\n\n\n\n\n\nHere we first compute the local inner product, and finally use the\nhigher-level function \nbulk::foldl\n\nresult.\n\n\nAnother example is finding a maximum element over all processors, here\nmax is the maximum value found locally:\n\n\nauto\n \nmaxs\n \n=\n \nbulk\n::\ngather_all\n(\nworld\n,\n \nmax\n);\n\n\nmax\n \n=\n \n*\nstd\n::\nmax_element\n(\nmaxs\n.\nbegin\n(),\n \nmaxs\n.\nend\n());\n\n\n\n\n\n\nCompare this to the way this is done using e.g. BSPlib:\n\n\nint\n*\n \nglobal_max\n \n=\n \nmalloc\n(\nsizeof\n(\nint\n)\n \n*\n \nbsp_nprocs\n());\n\n\nbsp_push_reg\n(\nglobal_max\n,\n \nsizeof\n(\nint\n)\n \n*\n \nbsp_nprocs\n());\n\n\n\nfor\n \n(\nint\n \nt\n \n=\n \n0\n;\n \nt\n \n<\n \np\n;\n \n++\nt\n)\n \n{\n\n    \nbsp_put\n(\nt\n,\n \n&\nmax\n,\n \nglobal_max\n,\n \nbsp_pid\n(),\n \nsizeof\n(\nint\n));\n\n\n}\n\n\nbsp_sync\n();\n\n\n\nfor\n \n(\nint\n \nt\n \n=\n \n0\n;\n \nt\n \n<\n \np\n;\n \n++\nt\n)\n \n{\n\n    \nif\n \n(\nmax\n \n<\n \nglobal_max\n[\nt\n])\n \n{\n\n        \nmax\n \n=\n \nglobal_max\n[\nt\n];\n\n    \n}\n\n\n}",
            "title": "Tour"
        },
        {
            "location": "/tour/#a-tour-of-bulk",
            "text": "On this page we aim to highlight some of the main features of the\nlibrary, and to give an impression of the overall syntax.",
            "title": "A tour of Bulk"
        },
        {
            "location": "/tour/#hello-bulkworld",
            "text": "We start out with the obligatory Hello World! in Bulk , and subsequently\nexplain the code line-by-line. In this code we will use the  MPI \nbackend, but everything written here is completely general, and\nguarenteed to work on top of any conforming Bulk backend.  #include   <bulk/bulk.hpp>  #include   <bulk/backends/mpi/mpi.hpp>  int   main ()   { \n     bulk :: mpi :: environment   env ; \n     env . spawn ( env . available_processors (),   []( auto &   world )   { \n         auto   s   =   world . processor_id (); \n         auto   p   =   world . active_processors (); \n\n         world . log ( \"Hello world from processor %d / %d!\" ,   s ,   p ); \n     });  }   On lines 1 and 2 we include the library, and the backend of our choosing\n(in our case MPI). On line 5, we initialize an  environment , which\nsets up the parallel or distributed system.  On line 6, we spawn the  SPMD  section of our program within the\nenvironment. The first argument denotes the number of processors that we\nwant to run the section on, while the second argument provides a\nfunction-like object (here a C++ lambda function) that is executed on\nthe requested number of processors. This function obtains a bulk::world  object, which it can use to communicate with other\nprocessors, for programmer convenience its identifier  s \nand the total number of processes that are spawned  p  are\npassed as well. These can alternatively be obtained from world using world.processor_id()  and world.active_processors()  respectively.",
            "title": "Hello bulk::world!"
        },
        {
            "location": "/tour/#communication-between-processors",
            "text": "Next, we look at some basic forms of communication between processors.\nThe main way to  talk  to other processors, is by using variables. A\nvariable is created as follows:  auto   x   =   bulk :: var < T > ( world );   Here,  T  is the type of the variable, for example an int . Values can be assigned to the (local) variable:  x   =   5 ;   The reason to use a variable, is that a processor can  write  to a\nremote  image  of a variable.  bulk :: put ( world . next_processor (),   4 ,   x );   This will overwrite the value of the variable  x  on the\nnext logical processor (i.e. processor  s + 1 % p ) with 4 . We can obtain the value of a remote image using:  auto   y   =   bulk :: get ( world . next_processor (),   x );   Here,  y  is a  bulk::future  object. A future\nobject does not immediately hold the remote value of  x ,\nbut after a  future  call to  world.sync() , we can extract\nthe remote value out of  y .  world . sync ();  auto   x_next   =   y . value ();",
            "title": "Communication between processors"
        },
        {
            "location": "/tour/#coarrays",
            "text": "Coarrays are a convenient way to store, and manipulate distributed\ndata. We provide a co-array that is modeled after  Coarray\nFortran . Arrays are\ninitialized and used as follows:  auto   xs   =   bulk :: coarray < int > ( world ,   s );  xs ( 3 )[ 2 ]   =   1 ;   Here, we create a co-array of varying local size (each processor holds s  many elements). Next we write the value 1  to the element with local index  2  on\nprocessor with index  3 .",
            "title": "Coarrays"
        },
        {
            "location": "/tour/#algorithmic-skeletons",
            "text": "comes equipped with a number of higher-level functions, also known as algorithmic skeletons . For example, say we want to compute the\ndot-product of two coarrays, then we write this as:  auto   xs   =   bulk :: coarray < int > ( world ,   s );  auto   ys   =   bulk :: coarray < int > ( world ,   s );  // fill xs and ys with data  auto   result   =   bulk :: var < int > ( world );  for   ( int   i   =   0 ;   i   <   s ;   ++ i )   { \n     result . value ()   +=   xs [ i ]   *   ys [ i ];  }  // reduce to find global dot product  auto   alpha   =   bulk :: foldl ( result ,   []( int &   lhs ,   int   rhs )   {   lhs   +=   rhs ;   });   Here we first compute the local inner product, and finally use the\nhigher-level function  bulk::foldl \nresult.  Another example is finding a maximum element over all processors, here\nmax is the maximum value found locally:  auto   maxs   =   bulk :: gather_all ( world ,   max );  max   =   * std :: max_element ( maxs . begin (),   maxs . end ());   Compare this to the way this is done using e.g. BSPlib:  int *   global_max   =   malloc ( sizeof ( int )   *   bsp_nprocs ());  bsp_push_reg ( global_max ,   sizeof ( int )   *   bsp_nprocs ());  for   ( int   t   =   0 ;   t   <   p ;   ++ t )   { \n     bsp_put ( t ,   & max ,   global_max ,   bsp_pid (),   sizeof ( int ));  }  bsp_sync ();  for   ( int   t   =   0 ;   t   <   p ;   ++ t )   { \n     if   ( max   <   global_max [ t ])   { \n         max   =   global_max [ t ]; \n     }  }",
            "title": "Algorithmic skeletons"
        },
        {
            "location": "/environment_world/",
            "text": "Environment and world\n\u00b6\n\n\nIn the upcoming sections we will get you started with programming in Bulk. Two important concepts are that of an environment and a world.\n\n\nIn these code examples, we will often use the short-hand \ns\n for the \nlocal processor id\n, and \np\n for the \nactive number of processors\n, and we will not always define these variables explicitely.\n\n\nParallel environments\n\u00b6\n\n\nA program runs in some parallel environment. For example, this\nenvironment could be an MPI cluster, a many-core co-processor, or simply\nthreads on a multi-core computer. This environment is accessed within\nthe program through a \nbulk::environment\n object.\nThis object is specialized for each \nbackend\n, which is an\nimplementation of the lower-level communication that reflect the actual\nenvironment. For example, to setup a environment on an MPI cluster, we\nwould write:\n\n\n#include\n \n<bulk/bulk.hpp>\n\n\n#include\n \n<bulk/backends/mpi/mpi.hpp>\n\n\n\nint\n \nmain\n()\n \n{\n\n    \nbulk\n::\nmpi\n::\nenvironment\n \nenv\n;\n\n\n}\n\n\n\n\n\n\nFor a list of default providers, consult the \nbackends\n section of this\ndocumentation.\n\n\nThis environment object contains information on the parallel system, for\nexample we can request the number of processors that are available.\n\n\nWe note that throughout this documentation (and in the library),\n\nprocessor\n is a general term for the entity that executes the SPMD\nsection (more on this later) and communicates with other processors \u2013\nthis can be an MPI node, a core, or a thread, depending on the backend\nthat is used, but they are all treated in the same manner.\n\n\nauto\n \nprocessor_count\n \n=\n \nenv\n.\navailable_processors\n();\n\n\n\n\n\n\nThis information can be used to \nspawn\n the program on the right amount\nof processors. Programs written in Bulk follow that \nSPMD\n (Single\nProgram Multiple Data) paradigm. This means that each processor executes\nthe same code, but has its own (local) data that it manipulates. In\nBulk, the SPMD section is a \nfunction object\n. This can be a C++ lambda,\na \nstd::function\n, or a C function pointer. In this\ndocumentation we will use lambda functions for our examples.\n\n\nThis function will run on each processor, and should take three\narguments. The first, contains the \nworld\n object, which we will\ndescribe in detail in the next section. The SPMD section is executed\nin the following way:\n\n\nenv\n.\nspawn\n(\nenv\n.\navailable_processors\n(),\n \n[](\nauto\n&\n \nworld\n)\n \n{\n\n    \nauto\n \ns\n \n=\n \nworld\n.\nprocessor_id\n();\n\n    \nauto\n \np\n \n=\n \nworld\n.\navailable_proecssors\n();\n\n    \nworld\n.\nlog\n(\n\"Hello world from processor %d / %d!\"\n,\n \ns\n,\n \np\n);\n\n\n}\n\n\n\n\n\n\nThe \nspawn\n function takes two arguments. The first is the\ntotal number of processors to run the SPMD section on, here we simply\nuse all the processors that are available. The second is the SPMD\nfunction itself, that is run on the given number of processors.\n\n\nThe world of a processor\n\u00b6\n\n\n\n\nEach processor can communicate to other processors using the \nworld\n\nobject of type \nbulk::world\n. The world object contains\nsome information on the specifics of SPMD section, such as the number of\nprocessors executing the section, and its identifier (as we have seen,\nthese are also provided as arguments for programmer convenience). We can\nalso obtain indices of the neighbouring processors:\n\n\nauto\n \nnext\n \n=\n \nworld\n.\nnext_processor\n();\n\n\nauto\n \nprevious\n \n=\n \nworld\n.\nprev_processor\n();\n\n\n\n\n\n\nThe next and previous processor can also be computed manually using:\n\n\nnext\n \n=\n \n(\ns\n \n+\n \n1\n)\n \n%\n \np\n;\n\n\nprevious\n \n=\n \n(\ns\n \n+\n \np\n \n-\n \n1\n)\n \n%\n \np\n;\n\n\n\n\n\n\nHowever, we would suggest using the appropriate methods of world to\nincrease readability. Another important mechanism exposed through the\nworld object is the ability to perform a \nbulk-synchronization\n, which\nis the cornerstone of programs written in BSP style:\n\n\nworld\n.\nsync\n();\n\n\n\n\n\n\nWe will see the specific uses of bulk-synchronization in the upcoming\nsections.",
            "title": "Environment and world"
        },
        {
            "location": "/environment_world/#environment-and-world",
            "text": "In the upcoming sections we will get you started with programming in Bulk. Two important concepts are that of an environment and a world.  In these code examples, we will often use the short-hand  s  for the  local processor id , and  p  for the  active number of processors , and we will not always define these variables explicitely.",
            "title": "Environment and world"
        },
        {
            "location": "/environment_world/#parallel-environments",
            "text": "A program runs in some parallel environment. For example, this\nenvironment could be an MPI cluster, a many-core co-processor, or simply\nthreads on a multi-core computer. This environment is accessed within\nthe program through a  bulk::environment  object.\nThis object is specialized for each  backend , which is an\nimplementation of the lower-level communication that reflect the actual\nenvironment. For example, to setup a environment on an MPI cluster, we\nwould write:  #include   <bulk/bulk.hpp>  #include   <bulk/backends/mpi/mpi.hpp>  int   main ()   { \n     bulk :: mpi :: environment   env ;  }   For a list of default providers, consult the  backends  section of this\ndocumentation.  This environment object contains information on the parallel system, for\nexample we can request the number of processors that are available.  We note that throughout this documentation (and in the library), processor  is a general term for the entity that executes the SPMD\nsection (more on this later) and communicates with other processors \u2013\nthis can be an MPI node, a core, or a thread, depending on the backend\nthat is used, but they are all treated in the same manner.  auto   processor_count   =   env . available_processors ();   This information can be used to  spawn  the program on the right amount\nof processors. Programs written in Bulk follow that  SPMD  (Single\nProgram Multiple Data) paradigm. This means that each processor executes\nthe same code, but has its own (local) data that it manipulates. In\nBulk, the SPMD section is a  function object . This can be a C++ lambda,\na  std::function , or a C function pointer. In this\ndocumentation we will use lambda functions for our examples.  This function will run on each processor, and should take three\narguments. The first, contains the  world  object, which we will\ndescribe in detail in the next section. The SPMD section is executed\nin the following way:  env . spawn ( env . available_processors (),   []( auto &   world )   { \n     auto   s   =   world . processor_id (); \n     auto   p   =   world . available_proecssors (); \n     world . log ( \"Hello world from processor %d / %d!\" ,   s ,   p );  }   The  spawn  function takes two arguments. The first is the\ntotal number of processors to run the SPMD section on, here we simply\nuse all the processors that are available. The second is the SPMD\nfunction itself, that is run on the given number of processors.",
            "title": "Parallel environments"
        },
        {
            "location": "/environment_world/#the-world-of-a-processor",
            "text": "Each processor can communicate to other processors using the  world \nobject of type  bulk::world . The world object contains\nsome information on the specifics of SPMD section, such as the number of\nprocessors executing the section, and its identifier (as we have seen,\nthese are also provided as arguments for programmer convenience). We can\nalso obtain indices of the neighbouring processors:  auto   next   =   world . next_processor ();  auto   previous   =   world . prev_processor ();   The next and previous processor can also be computed manually using:  next   =   ( s   +   1 )   %   p ;  previous   =   ( s   +   p   -   1 )   %   p ;   However, we would suggest using the appropriate methods of world to\nincrease readability. Another important mechanism exposed through the\nworld object is the ability to perform a  bulk-synchronization , which\nis the cornerstone of programs written in BSP style:  world . sync ();   We will see the specific uses of bulk-synchronization in the upcoming\nsections.",
            "title": "The world of a processor"
        },
        {
            "location": "/variables/",
            "text": "Variables\n\u00b6\n\n\nNow that we are able to set up the environment, and gained some\nfamiliarity with the \nworld\n object that can be used to communicate with\nother processors, we are ready to discuss communication between\nprocessors. The most fundamental way of communicating between processors\nis using \ndistributed variables\n. The variables can be created as\nfollows:\n\n\nauto x = bulk::var<int>(world);\n\n\n\n\n\nHere we create a distributed variable that holds an integer. A\ndistributed variable exists on every processor, but can have different\nvalues on different processors. These different local \u2018copies\u2019 are\nreferred to as \nimages\n of the variable. The variable lives within the\n\nworld\n of the current SPMD section, and we explicitely write this by\npassing the world object as a parameter to the variable creation\nfunction.\n\n\nWhile \nx\n refers to the \nlocal image\n of a variable, it is\nidentified with images on remote processors by the order in which\nvariables are constructed (which is possible because of the SPMD nature\nof Bulk programs). This allows us to \nwrite to\n and \nread from\n remote\nimages of a variable by simply passing \nx\n to communication\nfunctions.\n\n\nBulk-synchronous communication\n\u00b6\n\n\nThe main way to manipulate remote images of variables is using the\ncommunication primitives \nbulk::put\n and\n\nbulk::get\n for writing and reading respectively. For\nexample, to write the value \n1\n to the remote image held by\nthe next logical processor, we write:\n\n\nbulk::put(world.next_processor(), 1, x);\n\n\n\n\n\nTo obtain the value of a remote image we write:\n\n\nauto y = bulk::get(world.next_processor(), x);\n\n\n\n\n\n\n\nNote\n\n\nEquivalently, we can use the short-hand syntax: \nx(world.next_processor()) = 1\n for putting, and \nauto y = x(world.next_processor()).get()\n for getting.\n\n\n\n\n\n\nThis communication is \nasynchronous\n, meaning that the values are not\nvalid immediately after the execution of the communication primitives.\nInstead, they are available in the next \u2018section\u2019 of the program, known\nas a (BSP) \nsuperstep\n. Supersteps can be viewed as the section of the\nprogram within successive calls to \nworld.sync()\n. This\nbarrier synchronization asserts that all processors have reached that\npoint of the program, and resolves all outstanding communication such as\nthose staged by calls to put and get. After the barrier synchronization\nreturns, all communication staged in the previous superstep is\nguarenteed to have occured.\n\n\n\n\nIn case of \nput\n, the remote image now contains the value written to it\n(assuming that the local processor is the only one who wrote to that\nspecific remote image). For read requests using \nget\n, it is slightly\nmore complicated. The type of \ny\n is a\n\nbulk::future<T>\n. A future object is a placeholder, that\nwill contain the correct value in the next superstep. This value can be\nobtained after the synchronization using:\n\n\nauto value = y.value();\n\n\n\n\n\nThis way of communicating is particularly useful when dealing with\nsimple data objects. If instead we deal with distributed array-like\nobjects, we recommend using \nco-arrays\n, which are introduced in the\nnext section.",
            "title": "Distributed variables"
        },
        {
            "location": "/variables/#variables",
            "text": "Now that we are able to set up the environment, and gained some\nfamiliarity with the  world  object that can be used to communicate with\nother processors, we are ready to discuss communication between\nprocessors. The most fundamental way of communicating between processors\nis using  distributed variables . The variables can be created as\nfollows:  auto x = bulk::var<int>(world);  Here we create a distributed variable that holds an integer. A\ndistributed variable exists on every processor, but can have different\nvalues on different processors. These different local \u2018copies\u2019 are\nreferred to as  images  of the variable. The variable lives within the world  of the current SPMD section, and we explicitely write this by\npassing the world object as a parameter to the variable creation\nfunction.  While  x  refers to the  local image  of a variable, it is\nidentified with images on remote processors by the order in which\nvariables are constructed (which is possible because of the SPMD nature\nof Bulk programs). This allows us to  write to  and  read from  remote\nimages of a variable by simply passing  x  to communication\nfunctions.",
            "title": "Variables"
        },
        {
            "location": "/variables/#bulk-synchronous-communication",
            "text": "The main way to manipulate remote images of variables is using the\ncommunication primitives  bulk::put  and bulk::get  for writing and reading respectively. For\nexample, to write the value  1  to the remote image held by\nthe next logical processor, we write:  bulk::put(world.next_processor(), 1, x);  To obtain the value of a remote image we write:  auto y = bulk::get(world.next_processor(), x);   Note  Equivalently, we can use the short-hand syntax:  x(world.next_processor()) = 1  for putting, and  auto y = x(world.next_processor()).get()  for getting.    This communication is  asynchronous , meaning that the values are not\nvalid immediately after the execution of the communication primitives.\nInstead, they are available in the next \u2018section\u2019 of the program, known\nas a (BSP)  superstep . Supersteps can be viewed as the section of the\nprogram within successive calls to  world.sync() . This\nbarrier synchronization asserts that all processors have reached that\npoint of the program, and resolves all outstanding communication such as\nthose staged by calls to put and get. After the barrier synchronization\nreturns, all communication staged in the previous superstep is\nguarenteed to have occured.   In case of  put , the remote image now contains the value written to it\n(assuming that the local processor is the only one who wrote to that\nspecific remote image). For read requests using  get , it is slightly\nmore complicated. The type of  y  is a bulk::future<T> . A future object is a placeholder, that\nwill contain the correct value in the next superstep. This value can be\nobtained after the synchronization using:  auto value = y.value();  This way of communicating is particularly useful when dealing with\nsimple data objects. If instead we deal with distributed array-like\nobjects, we recommend using  co-arrays , which are introduced in the\nnext section.",
            "title": "Bulk-synchronous communication"
        },
        {
            "location": "/coarrays/",
            "text": "Coarrays\n\u00b6\n\n\nCoarrays are a convenient way to store, and manipulate distributed\narrays. These \ndistributed arrays\n can be seen as distributed variables,\nwhose images are a local array. With Bulk, we provide a co-array that is\nmodeled after \nCoarray Fortran\n.\n\n\nauto\n \nxs\n \n=\n \nbulk\n::\ncoarray\n<\nint\n>\n(\nworld\n,\n \n5\n);\n\n\n\n\n\n\nHere, we create a co-array with local size equal to \n5\n. The total\nnumber of elements in the co-array is therefore \n5 * p\n. We\nuse a constant size here, but this is not required as the local size is\nallowed to vary over the processors. Coarrays provide syntactic sugar\nto make manipulating distributed arrays as easy as possible. For\nexample, we can write:\n\n\nxs\n(\n3\n)[\n2\n]\n \n=\n \n1\n;\n\n\n\n\n\n\nThis writes the value \n1\n to the element with local index\n\n2\n on processor with index \n3\n. The local\nimage of an array is iterable, so we can write for example:\n\n\nint\n \nresult\n \n=\n \n0\n;\n\n\nfor\n \n(\nauto\n \nx\n \n:\n \nxs\n)\n \n{\n\n    \nresult\n \n+=\n \nx\n;\n\n\n}\n\n\n\n\n\n\nTo compute the local sum of the numbers in the co-array image.",
            "title": "Coarrays"
        },
        {
            "location": "/coarrays/#coarrays",
            "text": "Coarrays are a convenient way to store, and manipulate distributed\narrays. These  distributed arrays  can be seen as distributed variables,\nwhose images are a local array. With Bulk, we provide a co-array that is\nmodeled after  Coarray Fortran .  auto   xs   =   bulk :: coarray < int > ( world ,   5 );   Here, we create a co-array with local size equal to  5 . The total\nnumber of elements in the co-array is therefore  5 * p . We\nuse a constant size here, but this is not required as the local size is\nallowed to vary over the processors. Coarrays provide syntactic sugar\nto make manipulating distributed arrays as easy as possible. For\nexample, we can write:  xs ( 3 )[ 2 ]   =   1 ;   This writes the value  1  to the element with local index 2  on processor with index  3 . The local\nimage of an array is iterable, so we can write for example:  int   result   =   0 ;  for   ( auto   x   :   xs )   { \n     result   +=   x ;  }   To compute the local sum of the numbers in the co-array image.",
            "title": "Coarrays"
        },
        {
            "location": "/message_passing/",
            "text": "Message passing\n\u00b6\n\n\nAnother way to communicate between processors is by using message\nqueues. These queues can be used to send and receive an arbitrary number\nof \nmessages\n. Messages have an attached \ntag\n and some \ncontent\n.\nMessages can be put into message queues, which have images on each\nprocessor. This queue can then be iterated over. To create a queue, you\nwrite:\n\n\nauto\n \nqueue\n \n=\n \nbulk\n::\nqueue\n<\nint\n,\n \nfloat\n>\n(\nworld\n);\n\n\n\n\n\n\nThis will create a queue that stores message with \ninteger\n tags, and\n\nfloat\n content. For example, a message can correspond to a component of\na vector of floats. To put a message into a remote queue, we use\n\nqueue(pid).send\n:\n\n\nqueue\n(\nworld\n.\nnext_processor\n()).\nsend\n(\n1\n,\n \n1.0f\n);\n\n\nqueue\n(\nworld\n.\nnext_processor\n()).\nsend\n(\n2\n,\n \n5.0f\n);\n\n\n\n\n\n\nThis will send two messages to the next logical processor, with tags 1\nand 2 respectively, and with contents 1.0f and 5.0f. As with\ncommunication through variables, this mechanism is also\n\nbulk-synchronous\n, which means that the remote queue will only have\naccess to the messages in the next superstep.\n\n\n\n\nWarning\n\n\nMessage queues, like variables, are identified by the order in which\nthey are constructed. Make sure this order is the same on each\nprocessor.\n\n\n\n\nworld\n.\nsync\n();\n\n\n\nfor\n \n(\nauto\n \n[\ntag\n,\n \ncontent\n]\n \n:\n \nqueue\n)\n \n{\n\n    \nworld\n.\nlog\n(\n\"Received tag: %d and content %f\"\n,\n \ntag\n,\n \ncontent\n);\n\n\n};\n\n\n\n\n\n\nIt is perfectly legal, and even encouraged, to make a seperate queue for\ndifferent types of messages. Each message queue has its own independent\ntypes. In addition, you are not limited to \u2018tag + content\u2019 type of messages, you can also send untagged data, or custom data such as index tuples, or even your own structs. For example:\n\n\nauto\n \nraw_queue\n \n=\n \nbulk\n::\nqueue\n<\nint\n>\n(\nworld\n);\n\n\nraw_queue\n(\nworld\n.\nnext_processor\n()).\nsend\n(\n1\n);\n\n\nraw_queue\n(\nworld\n.\nnext_processor\n()).\nsend\n(\n2\n);\n\n\nraw_queue\n(\nworld\n.\nnext_processor\n()).\nsend\n(\n123\n);\n\n\n\nauto\n \ntuple_queue\n \n=\n \nbulk\n::\nqueue\n<\nint\n,\n \nint\n,\n \nint\n>\n(\nworld\n);\n\n\ntuple_queue\n(\nworld\n.\nnext_processor\n()).\nsend\n(\n1\n,\n \n2\n,\n \n3\n);\n\n\ntuple_queue\n(\nworld\n.\nnext_processor\n()).\nsend\n(\n4\n,\n \n5\n,\n \n6\n);\n\n\n\nworld\n.\nsync\n();\n\n\n\n// read queue\n\n\nfor\n \n(\nauto\n \nx\n \n:\n \nraw_queue\n)\n \n{\n\n    \nworld\n.\nlog\n(\n\"the first queue received a message: %d\"\n,\n \nx\n);\n\n\n}\n\n\n\nfor\n \n(\nauto\n \n[\ni\n,\n \nj\n,\n \nk\n]\n \n:\n \ntuple_queue\n)\n \n{\n\n    \nworld\n.\nlog\n(\n\"the second queue received a tuple: (%d, %d, %d)\"\n,\n \ni\n,\n \nj\n,\n \nk\n);\n\n\n}",
            "title": "Message passing"
        },
        {
            "location": "/message_passing/#message-passing",
            "text": "Another way to communicate between processors is by using message\nqueues. These queues can be used to send and receive an arbitrary number\nof  messages . Messages have an attached  tag  and some  content .\nMessages can be put into message queues, which have images on each\nprocessor. This queue can then be iterated over. To create a queue, you\nwrite:  auto   queue   =   bulk :: queue < int ,   float > ( world );   This will create a queue that stores message with  integer  tags, and float  content. For example, a message can correspond to a component of\na vector of floats. To put a message into a remote queue, we use queue(pid).send :  queue ( world . next_processor ()). send ( 1 ,   1.0f );  queue ( world . next_processor ()). send ( 2 ,   5.0f );   This will send two messages to the next logical processor, with tags 1\nand 2 respectively, and with contents 1.0f and 5.0f. As with\ncommunication through variables, this mechanism is also bulk-synchronous , which means that the remote queue will only have\naccess to the messages in the next superstep.   Warning  Message queues, like variables, are identified by the order in which\nthey are constructed. Make sure this order is the same on each\nprocessor.   world . sync ();  for   ( auto   [ tag ,   content ]   :   queue )   { \n     world . log ( \"Received tag: %d and content %f\" ,   tag ,   content );  };   It is perfectly legal, and even encouraged, to make a seperate queue for\ndifferent types of messages. Each message queue has its own independent\ntypes. In addition, you are not limited to \u2018tag + content\u2019 type of messages, you can also send untagged data, or custom data such as index tuples, or even your own structs. For example:  auto   raw_queue   =   bulk :: queue < int > ( world );  raw_queue ( world . next_processor ()). send ( 1 );  raw_queue ( world . next_processor ()). send ( 2 );  raw_queue ( world . next_processor ()). send ( 123 );  auto   tuple_queue   =   bulk :: queue < int ,   int ,   int > ( world );  tuple_queue ( world . next_processor ()). send ( 1 ,   2 ,   3 );  tuple_queue ( world . next_processor ()). send ( 4 ,   5 ,   6 );  world . sync ();  // read queue  for   ( auto   x   :   raw_queue )   { \n     world . log ( \"the first queue received a message: %d\" ,   x );  }  for   ( auto   [ i ,   j ,   k ]   :   tuple_queue )   { \n     world . log ( \"the second queue received a tuple: (%d, %d, %d)\" ,   i ,   j ,   k );  }",
            "title": "Message passing"
        },
        {
            "location": "/api/",
            "text": "Bulk API reference\n\u00b6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSystem\n\n\n\n\n\n\n\n\nbulk::environment\n\n\nthe central object that encapsulates the distributed system\n\n\n\n\n\n\nbulk::world\n\n\nan implementation of the low-level functions\n\n\n\n\n\n\nDistributed objects and communication\n\n\n\n\n\n\n\n\nbulk::var\n\n\na distributed variable with an image for each processor\n\n\n\n\n\n\nbulk::future\n\n\nan object which encapsulates a value known in future supersteps\n\n\n\n\n\n\nbulk::coarray\n\n\na distributed array with a local array image for each processor\n\n\n\n\n\n\nbulk::put\n\n\nsend information to a remote processor\n\n\n\n\n\n\nbulk::get\n\n\nobtain information from a remote processor\n\n\n\n\n\n\nMessage passing\n\n\n\n\n\n\n\n\nbulk::queue\n\n\na container containing messages\n\n\n\n\n\n\nAlgorithm\n\n\n\n\n\n\n\n\nbulk::foldl\n\n\na left fold over a \nvar\n\n\n\n\n\n\nbulk::gather_all\n\n\ngather results\n\n\n\n\n\n\nUtility\n\n\n\n\n\n\n\n\nbulk::util::timer\n\n\nwall timer for benchmarking\n\n\n\n\n\n\nbulk::util::flatten\n\n\nflatten multi-indices\n\n\n\n\n\n\nbulk::util::unflatten\n\n\nunflatten mutli-indices",
            "title": "Index"
        },
        {
            "location": "/api/#bulk-api-reference",
            "text": "System     bulk::environment  the central object that encapsulates the distributed system    bulk::world  an implementation of the low-level functions    Distributed objects and communication     bulk::var  a distributed variable with an image for each processor    bulk::future  an object which encapsulates a value known in future supersteps    bulk::coarray  a distributed array with a local array image for each processor    bulk::put  send information to a remote processor    bulk::get  obtain information from a remote processor    Message passing     bulk::queue  a container containing messages    Algorithm     bulk::foldl  a left fold over a  var    bulk::gather_all  gather results    Utility     bulk::util::timer  wall timer for benchmarking    bulk::util::flatten  flatten multi-indices    bulk::util::unflatten  unflatten mutli-indices",
            "title": "Bulk API reference"
        },
        {
            "location": "/api/environment/",
            "text": "bulk::environment\n\u00b6\n\n\nDefined in header \n<bulk/environment.hpp>\n.\n\n\nclass\n \nenvironment\n;\n\n\n\n\n\n\nbulk::environment\n encodes the environment of a parallel layer, and provides information on the system.\n\n\nMember functions\n\u00b6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInitialization\n\n\n\n\n\n\n\n\nspawn\n\n\nspawns a spmd section on a given number of processors\n\n\n\n\n\n\nSystem information\n\n\n\n\n\n\n\n\navailable_processors\n\n\nreturns the number of available processors\n\n\n\n\n\n\n\n\nExample\n\u00b6\n\n\n#include\n \n\"bulk/bulk.hpp\"\n\n\n\n#include\n \n\"set_backend.hpp\"\n\n\n\nint\n \nmain\n()\n \n{\n\n    \nenvironment\n \nenv\n;\n\n\n    \nenv\n.\nspawn\n(\nenv\n.\navailable_processors\n(),\n \n[](\nbulk\n::\nworld\n&\n \nworld\n)\n \n{\n\n        \nint\n \ns\n \n=\n \nworld\n.\nprocessor_id\n();\n\n        \nint\n \np\n \n=\n \nworld\n.\nactive_processors\n();\n\n\n        \nworld\n.\nlog\n(\n\"Hello, world %d/%d\"\n,\n \ns\n,\n \np\n);\n\n    \n});\n\n\n    \nreturn\n \n0\n;\n\n\n}",
            "title": "environment"
        },
        {
            "location": "/api/environment/#bulkenvironment",
            "text": "Defined in header  <bulk/environment.hpp> .  class   environment ;   bulk::environment  encodes the environment of a parallel layer, and provides information on the system.",
            "title": "bulk::environment"
        },
        {
            "location": "/api/environment/#member-functions",
            "text": "Initialization     spawn  spawns a spmd section on a given number of processors    System information     available_processors  returns the number of available processors",
            "title": "Member functions"
        },
        {
            "location": "/api/environment/#example",
            "text": "#include   \"bulk/bulk.hpp\"  #include   \"set_backend.hpp\"  int   main ()   { \n     environment   env ; \n\n     env . spawn ( env . available_processors (),   []( bulk :: world &   world )   { \n         int   s   =   world . processor_id (); \n         int   p   =   world . active_processors (); \n\n         world . log ( \"Hello, world %d/%d\" ,   s ,   p ); \n     }); \n\n     return   0 ;  }",
            "title": "Example"
        },
        {
            "location": "/api/world/",
            "text": "bulk::world\n\u00b6\n\n\nDefined in header \n<bulk/world.hpp>\n.\n\n\nclass\n \nworld\n;\n\n\n\n\n\n\nbulk::world\n represents the world of a processor and its place within it, by providing information and mechanisms to communicate with other processors, or obtain information about the local processor.\n\n\nMember functions\n\u00b6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSystem information\n\n\n\n\n\n\n\n\nactive_processors\n\n\nreturns the number of active processors\n\n\n\n\n\n\nprocessor_id\n\n\nreturns the id of the local processor\n\n\n\n\n\n\nnext_processor\n\n\nreturns the id of the next logical processor\n\n\n\n\n\n\nprev_processor\n\n\nreturns the id of the previous logical processor\n\n\n\n\n\n\nCommunication and coordination\n\n\n\n\n\n\n\n\nsync\n\n\nperforms a bulk synchronization\n\n\n\n\n\n\nbarrier\n\n\nperforms a bulk barrier\n\n\n\n\n\n\n\n\nExample\n\u00b6\n\n\n#include\n \n\"bulk/bulk.hpp\"\n\n\n\n#include\n \n\"set_backend.hpp\"\n\n\n\nint\n \nmain\n()\n \n{\n\n    \nenvironment\n \nenv\n;\n\n\n    \nenv\n.\nspawn\n(\nenv\n.\navailable_processors\n(),\n \n[](\nbulk\n::\nworld\n&\n \nworld\n)\n \n{\n\n        \nint\n \ns\n \n=\n \nworld\n.\nprocessor_id\n();\n\n        \nint\n \np\n \n=\n \nworld\n.\nactive_processors\n();\n\n\n        \nworld\n.\nlog\n(\n\"Hello, world %d/%d\"\n,\n \ns\n,\n \np\n);\n\n    \n});\n\n\n    \nreturn\n \n0\n;\n\n\n}",
            "title": "world"
        },
        {
            "location": "/api/world/#bulkworld",
            "text": "Defined in header  <bulk/world.hpp> .  class   world ;   bulk::world  represents the world of a processor and its place within it, by providing information and mechanisms to communicate with other processors, or obtain information about the local processor.",
            "title": "bulk::world"
        },
        {
            "location": "/api/world/#member-functions",
            "text": "System information     active_processors  returns the number of active processors    processor_id  returns the id of the local processor    next_processor  returns the id of the next logical processor    prev_processor  returns the id of the previous logical processor    Communication and coordination     sync  performs a bulk synchronization    barrier  performs a bulk barrier",
            "title": "Member functions"
        },
        {
            "location": "/api/world/#example",
            "text": "#include   \"bulk/bulk.hpp\"  #include   \"set_backend.hpp\"  int   main ()   { \n     environment   env ; \n\n     env . spawn ( env . available_processors (),   []( bulk :: world &   world )   { \n         int   s   =   world . processor_id (); \n         int   p   =   world . active_processors (); \n\n         world . log ( \"Hello, world %d/%d\" ,   s ,   p ); \n     }); \n\n     return   0 ;  }",
            "title": "Example"
        },
        {
            "location": "/api/var/",
            "text": "bulk::var\n\u00b6\n\n\nDefined in header \n<bulk/variable.hpp>\n.\n\n\ntemplate\n \n<\ntypename\n \nT\n>\n\n\nclass\n \nvar\n;\n\n\n\n\n\n\nbulk::var\n represents a distributed object with an image on each processor. This image is readable and writable from remote processors.\n\n\nTemplate parameters\n\u00b6\n\n\n\n\nT\n - the type of the values stored in the images of the variable.\n\n\n\n\nMember types\n\u00b6\n\n\n\n\nvalue_type\n: the type of the distributed data\n\n\nimage\n: an object providing syntactic sugar for reading and writing to images\n\n\n\n\nMember functions\n\u00b6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(constructor)\n\n\nconstructs the variable\n\n\n\n\n\n\n(deconstructor)\n\n\ndeconstructs the variable\n\n\n\n\n\n\noperator=\n\n\nassign values to the variable\n\n\n\n\n\n\nValue access\n\n\n\n\n\n\n\n\nvalue\n\n\nreturns the value of the local variable image\n\n\n\n\n\n\noperator T\n\n\nimplicit cast to value reference\n\n\n\n\n\n\nCommunication\n\n\n\n\n\n\n\n\noperator()\n\n\nobtain an image to a remote value\n\n\n\n\n\n\nbroadcast\n\n\nbroadcast a value to all remote images\n\n\n\n\n\n\nWorld access\n\n\n\n\n\n\n\n\nworld\n\n\nreturns the world of the variable\n\n\n\n\n\n\n\n\nSee also\n\u00b6\n\n\n\n\nbulk::var::image\n\n\n\n\nExample\n\u00b6\n\n\n#include\n \n\"bulk/bulk.hpp\"\n\n\n\n#include\n \n\"set_backend.hpp\"\n\n\n\nint\n \nmain\n()\n \n{\n\n    \nenvironment\n \nenv\n;\n\n\n    \nenv\n.\nspawn\n(\nenv\n.\navailable_processors\n(),\n \n[](\nbulk\n::\nworld\n&\n \nworld\n)\n \n{\n\n        \nint\n \ns\n \n=\n \nworld\n.\nprocessor_id\n();\n\n        \nint\n \np\n \n=\n \nworld\n.\nactive_processors\n();\n\n\n        \nbulk\n::\nvar\n<\nint\n>\n \na\n(\nworld\n);\n\n\n        \na\n(\nworld\n.\nnext_processor\n())\n \n=\n \ns\n;\n\n        \nworld\n.\nsync\n();\n\n\n        \nworld\n.\nlog\n(\n\"%d/%d <- %d\"\n,\n \ns\n,\n \np\n,\n \na\n.\nvalue\n());\n\n\n        \nauto\n \nb\n \n=\n \na\n(\nworld\n.\nnext_processor\n()).\nget\n();\n\n\n        \nworld\n.\nsync\n();\n\n\n        \nworld\n.\nlog\n(\n\"%d/%d -> %d\"\n,\n \ns\n,\n \np\n,\n \nb\n.\nvalue\n());\n\n    \n});\n\n\n    \nreturn\n \n0\n;\n\n\n}",
            "title": "var"
        },
        {
            "location": "/api/var/#bulkvar",
            "text": "Defined in header  <bulk/variable.hpp> .  template   < typename   T >  class   var ;   bulk::var  represents a distributed object with an image on each processor. This image is readable and writable from remote processors.",
            "title": "bulk::var"
        },
        {
            "location": "/api/var/#template-parameters",
            "text": "T  - the type of the values stored in the images of the variable.",
            "title": "Template parameters"
        },
        {
            "location": "/api/var/#member-types",
            "text": "value_type : the type of the distributed data  image : an object providing syntactic sugar for reading and writing to images",
            "title": "Member types"
        },
        {
            "location": "/api/var/#member-functions",
            "text": "(constructor)  constructs the variable    (deconstructor)  deconstructs the variable    operator=  assign values to the variable    Value access     value  returns the value of the local variable image    operator T  implicit cast to value reference    Communication     operator()  obtain an image to a remote value    broadcast  broadcast a value to all remote images    World access     world  returns the world of the variable",
            "title": "Member functions"
        },
        {
            "location": "/api/var/#see-also",
            "text": "bulk::var::image",
            "title": "See also"
        },
        {
            "location": "/api/var/#example",
            "text": "#include   \"bulk/bulk.hpp\"  #include   \"set_backend.hpp\"  int   main ()   { \n     environment   env ; \n\n     env . spawn ( env . available_processors (),   []( bulk :: world &   world )   { \n         int   s   =   world . processor_id (); \n         int   p   =   world . active_processors (); \n\n         bulk :: var < int >   a ( world ); \n\n         a ( world . next_processor ())   =   s ; \n         world . sync (); \n\n         world . log ( \"%d/%d <- %d\" ,   s ,   p ,   a . value ()); \n\n         auto   b   =   a ( world . next_processor ()). get (); \n\n         world . sync (); \n\n         world . log ( \"%d/%d -> %d\" ,   s ,   p ,   b . value ()); \n     }); \n\n     return   0 ;  }",
            "title": "Example"
        },
        {
            "location": "/api/future/",
            "text": "bulk::future\n\u00b6\n\n\nDefined in header \n<bulk/future.hpp>\n.\n\n\ntemplate\n \n<\ntypename\n \nT\n,\n \nclass\n \nHub\n>\n\n\nclass\n \nfuture\n;\n\n\n\n\n\n\nbulk::future\n represents a value that will become known in the upcoming superstep.\n\n\nTemplate parameters\n\u00b6\n\n\n\n\nT\n - the type of the value stored in the future\n\n\nHub\n - the type of hub to which the future belongs.\n\n\n\n\nMember functions\n\u00b6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(constructor)\n\n\nconstructs the future\n\n\n\n\n\n\n(deconstructor)\n\n\ndeconstructs the future\n\n\n\n\n\n\noperator=\n\n\nassign values to the future\n\n\n\n\n\n\nValue access\n\n\n\n\n\n\n\n\nvalue\n\n\nreturns the value of the future\n\n\n\n\n\n\nHub access\n\n\n\n\n\n\n\n\nhub\n\n\nreturns the hub to which the future belongs\n\n\n\n\n\n\n\n\nSee also\n\u00b6\n\n\n\n\ncreate_future\n\n\n\n\nExample\n\u00b6\n\n\n#include\n \n<iostream>\n\n\n\n#include\n \n<bulk/hub.hpp>\n\n\n#include\n \n<bulk/variable.hpp>\n\n\n#include\n \n<bulk/communication.hpp>\n\n\n#include\n \n<bulk/bsp/bulk.hpp>\n\n\n#include\n \n<bulk/util/log.hpp>\n\n\n\n\nint\n \nmain\n()\n \n{\n\n    \nauto\n \nhub\n \n=\n \nbulk\n::\nhub\n<\nbulk\n::\nbsp\n::\nprovider\n>\n();\n\n\n    \nhub\n.\nspawn\n(\nhub\n.\navailable_processors\n(),\n \n[\n&\nhub\n](\nint\n \ns\n,\n \nint\n)\n \n{\n\n        \nauto\n \na\n \n=\n \nbulk\n::\ncreate_var\n<\nint\n>\n(\nhub\n);\n\n\n        \nbulk\n::\nput\n(\nhub\n.\nnext_processor\n(),\n \ns\n,\n \na\n);\n\n        \nhub\n.\nsync\n();\n\n\n        \nstd\n::\ncout\n \n<<\n \ns\n \n<<\n \n\" <- \"\n \n<<\n \na\n.\nvalue\n()\n \n<<\n \nstd\n::\nendl\n;\n\n\n        \nauto\n \nb\n \n=\n \nbulk\n::\nget\n(\nhub\n.\nnext_processor\n(),\n \na\n);\n\n\n        \nhub\n.\nsync\n();\n\n\n        \nstd\n::\ncout\n \n<<\n \ns\n \n<<\n \n\" -> \"\n \n<<\n \nb\n.\nvalue\n()\n \n<<\n \nstd\n::\nendl\n;\n\n    \n});\n\n\n    \nreturn\n \n0\n;\n\n\n}",
            "title": "future"
        },
        {
            "location": "/api/future/#bulkfuture",
            "text": "Defined in header  <bulk/future.hpp> .  template   < typename   T ,   class   Hub >  class   future ;   bulk::future  represents a value that will become known in the upcoming superstep.",
            "title": "bulk::future"
        },
        {
            "location": "/api/future/#template-parameters",
            "text": "T  - the type of the value stored in the future  Hub  - the type of hub to which the future belongs.",
            "title": "Template parameters"
        },
        {
            "location": "/api/future/#member-functions",
            "text": "(constructor)  constructs the future    (deconstructor)  deconstructs the future    operator=  assign values to the future    Value access     value  returns the value of the future    Hub access     hub  returns the hub to which the future belongs",
            "title": "Member functions"
        },
        {
            "location": "/api/future/#see-also",
            "text": "create_future",
            "title": "See also"
        },
        {
            "location": "/api/future/#example",
            "text": "#include   <iostream>  #include   <bulk/hub.hpp>  #include   <bulk/variable.hpp>  #include   <bulk/communication.hpp>  #include   <bulk/bsp/bulk.hpp>  #include   <bulk/util/log.hpp>  int   main ()   { \n     auto   hub   =   bulk :: hub < bulk :: bsp :: provider > (); \n\n     hub . spawn ( hub . available_processors (),   [ & hub ]( int   s ,   int )   { \n         auto   a   =   bulk :: create_var < int > ( hub ); \n\n         bulk :: put ( hub . next_processor (),   s ,   a ); \n         hub . sync (); \n\n         std :: cout   <<   s   <<   \" <- \"   <<   a . value ()   <<   std :: endl ; \n\n         auto   b   =   bulk :: get ( hub . next_processor (),   a ); \n\n         hub . sync (); \n\n         std :: cout   <<   s   <<   \" -> \"   <<   b . value ()   <<   std :: endl ; \n     }); \n\n     return   0 ;  }",
            "title": "Example"
        },
        {
            "location": "/api/coarray/",
            "text": "bulk::coarray\n\u00b6\n\n\nDefined in header \n<bulk/coarray.hpp>\n.\n\n\ntemplate\n \n<\ntypename\n \nT\n,\n \nclass\n \nWorld\n>\n\n\nclass\n \ncoarray\n;\n\n\n\n\n\n\nDistributed array with easy element access, loosely based on the behaviour of \nCo-Array Fortran\n.\n\n\nUsage\n\u00b6\n\n\nCo-arrays provide a convenient way to share data across processors. Instead of\nmanually sending and receiving data elements, co-arrays model distributed data\nas a 2-dimensional array, where the first dimension is over the processors,\nand the second dimension is over local 1-dimensional array indices.\n\n\nauto\n \nxs\n \n=\n \ncreate_coarray\n<\nint\n>\n(\nworld\n,\n \n10\n);\n\n\n// set the 5th element on the 1st processor to 4\n\n\nxs\n(\n1\n)[\n5\n]\n \n=\n \n4\n;\n\n\n// set the 3rd element on the local processor to 2\n\n\nxs\n[\n3\n]\n \n=\n \n2\n;\n\n\n\n\n\n\nTemplate parameters\n\u00b6\n\n\n\n\nT\n - the type of the value stored in the local image of the coarray.\n\n\nWorld\n - the type of world to which this coarray belongs.\n\n\n\n\nMember classes\n\u00b6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimage\n\n\nrepresentation of coarray image\n\n\n\n\n\n\nwriter\n\n\nallows for modification for remote coarray image\n\n\n\n\n\n\n\n\nMember functions\n\u00b6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(constructor)\n\n\nconstructs the coarray\n\n\n\n\n\n\n(deconstructor)\n\n\ndeconstructs the coarray\n\n\n\n\n\n\nValue access\n\n\n\n\n\n\n\n\noperator()\n\n\nobtain an image of the coarray\n\n\n\n\n\n\noperator[]\n\n\naccess the local elements of the coarray\n\n\n\n\n\n\nWorld access\n\n\n\n\n\n\n\n\nworld\n\n\nreturns the world to which the coarray belongs\n\n\n\n\n\n\n\n\nSee also\n\u00b6\n\n\n\n\ncreate_coarray",
            "title": "coarray"
        },
        {
            "location": "/api/coarray/#bulkcoarray",
            "text": "Defined in header  <bulk/coarray.hpp> .  template   < typename   T ,   class   World >  class   coarray ;   Distributed array with easy element access, loosely based on the behaviour of  Co-Array Fortran .",
            "title": "bulk::coarray"
        },
        {
            "location": "/api/coarray/#usage",
            "text": "Co-arrays provide a convenient way to share data across processors. Instead of\nmanually sending and receiving data elements, co-arrays model distributed data\nas a 2-dimensional array, where the first dimension is over the processors,\nand the second dimension is over local 1-dimensional array indices.  auto   xs   =   create_coarray < int > ( world ,   10 );  // set the 5th element on the 1st processor to 4  xs ( 1 )[ 5 ]   =   4 ;  // set the 3rd element on the local processor to 2  xs [ 3 ]   =   2 ;",
            "title": "Usage"
        },
        {
            "location": "/api/coarray/#template-parameters",
            "text": "T  - the type of the value stored in the local image of the coarray.  World  - the type of world to which this coarray belongs.",
            "title": "Template parameters"
        },
        {
            "location": "/api/coarray/#member-classes",
            "text": "image  representation of coarray image    writer  allows for modification for remote coarray image",
            "title": "Member classes"
        },
        {
            "location": "/api/coarray/#member-functions",
            "text": "(constructor)  constructs the coarray    (deconstructor)  deconstructs the coarray    Value access     operator()  obtain an image of the coarray    operator[]  access the local elements of the coarray    World access     world  returns the world to which the coarray belongs",
            "title": "Member functions"
        },
        {
            "location": "/api/coarray/#see-also",
            "text": "create_coarray",
            "title": "See also"
        },
        {
            "location": "/api/queue/",
            "text": "",
            "title": "queue"
        },
        {
            "location": "/api/timer/",
            "text": "",
            "title": "timer"
        },
        {
            "location": "/api/put/",
            "text": "bulk::put\n\u00b6\n\n\ntemplate\n \n<\ntypename\n \nT\n,\n \ntypename\n \nHub\n>\n\n\nvoid\n \nput\n(\nint\n \nprocessor\n,\n \nT\n \nvalue\n,\n \nvar\n<\nT\n,\n \nHub\n>&\n \nthe_variable\n);\n \n// 1.\n\n\n\ntemplate\n \n<\ntypename\n \nT\n,\n \ntypename\n \nHub\n>\n\n\nvoid\n \nput\n(\nint\n \nprocessor\n,\n \nT\n \nvalue\n,\n \narray\n<\nT\n,\n \nHub\n>&\n \nthe_array\n,\n \nint\n \noffset\n \n=\n \n0\n,\n\n         \nint\n \ncount\n \n=\n \n1\n);\n \n// 2.\n\n\n\n\n\n\nPut a value in a (remote) image of a \nvariable\n (1.), or \narray\n (2.).\n\n\nTemplate parameters\n\u00b6\n\n\n\n\nT\n - the value type of the variable/array\n\n\nHub\n - the type of the hub that the variable/array belongs to\n\n\n\n\nParameters\n\u00b6\n\n\n\n\nprocessor\n - the index of the (remote) processor\n\n\nvalue\n - the value to write\n\n\nthe_variable\n - the target variable\n\n\nthe_array\n - the target array\n\n\noffset\n - the index of the array element to start writing at\n\n\ncount\n - a number of elements to write\n\n\n\n\nComplexity and cost\n\u00b6\n\n\n\n\n\n\nCost\n\n\n\n\nsizeof(T) * g\n\n\n(sizeof(T) * count) * g\n\n\n\n\n\n\n\n\nExample\n\u00b6\n\n\n#include\n \n<iostream>\n\n\n\n#include\n \n<bulk/hub.hpp>\n\n\n#include\n \n<bulk/communication.hpp>\n\n\n#include\n \n<bulk/bsp/bulk.hpp>\n\n\n\n\nint\n \nmain\n()\n \n{\n\n    \nauto\n \nhub\n \n=\n \nbulk\n::\nhub\n<\nbulk\n::\nbsp\n::\nprovider\n>\n();\n\n\n    \nhub\n.\nspawn\n(\nhub\n.\navailable_processors\n(),\n \n[\n&\nhub\n](\nint\n \ns\n,\n \nint\n)\n \n{\n\n        \nauto\n \nx\n \n=\n \nbulk\n::\ncreate_var\n<\nint\n>\n(\nhub\n);\n\n        \nbulk\n::\nput\n(\nhub\n.\nnext_processor\n(),\n \ns\n,\n \nx\n);\n \n// 1.\n\n        \nhub\n.\nsync\n();\n\n\n        \nstd\n::\ncout\n \n<<\n \ns\n \n<<\n \n\" <- \"\n \n<<\n \nx\n.\nvalue\n()\n \n<<\n \nstd\n::\nendl\n;\n\n    \n});\n\n\n    \nreturn\n \n0\n;\n\n\n}",
            "title": "put"
        },
        {
            "location": "/api/put/#bulkput",
            "text": "template   < typename   T ,   typename   Hub >  void   put ( int   processor ,   T   value ,   var < T ,   Hub >&   the_variable );   // 1.  template   < typename   T ,   typename   Hub >  void   put ( int   processor ,   T   value ,   array < T ,   Hub >&   the_array ,   int   offset   =   0 , \n          int   count   =   1 );   // 2.   Put a value in a (remote) image of a  variable  (1.), or  array  (2.).",
            "title": "bulk::put"
        },
        {
            "location": "/api/put/#template-parameters",
            "text": "T  - the value type of the variable/array  Hub  - the type of the hub that the variable/array belongs to",
            "title": "Template parameters"
        },
        {
            "location": "/api/put/#parameters",
            "text": "processor  - the index of the (remote) processor  value  - the value to write  the_variable  - the target variable  the_array  - the target array  offset  - the index of the array element to start writing at  count  - a number of elements to write",
            "title": "Parameters"
        },
        {
            "location": "/api/put/#complexity-and-cost",
            "text": "Cost   sizeof(T) * g  (sizeof(T) * count) * g",
            "title": "Complexity and cost"
        },
        {
            "location": "/api/put/#example",
            "text": "#include   <iostream>  #include   <bulk/hub.hpp>  #include   <bulk/communication.hpp>  #include   <bulk/bsp/bulk.hpp>  int   main ()   { \n     auto   hub   =   bulk :: hub < bulk :: bsp :: provider > (); \n\n     hub . spawn ( hub . available_processors (),   [ & hub ]( int   s ,   int )   { \n         auto   x   =   bulk :: create_var < int > ( hub ); \n         bulk :: put ( hub . next_processor (),   s ,   x );   // 1. \n         hub . sync (); \n\n         std :: cout   <<   s   <<   \" <- \"   <<   x . value ()   <<   std :: endl ; \n     }); \n\n     return   0 ;  }",
            "title": "Example"
        },
        {
            "location": "/api/get/",
            "text": "bulk::get\n\u00b6\n\n\ntemplate\n \n<\ntypename\n \nT\n,\n \ntypename\n \nHub\n>\n\n\nfuture\n<\nT\n,\n \nHub\n>\n \nget\n(\nint\n \nprocessor\n,\n \nvar\n<\nT\n,\n \nHub\n>&\n \nthe_variable\n);\n \n// 1.\n\n\n\n\n\n\nGet a value from a (remote) image of a \nvariable\n (1.).\n\n\nTemplate parameters\n\u00b6\n\n\n\n\nT\n - the value type of the variable/array\n\n\nHub\n - the type of the hub that the variable/array belongs to\n\n\n\n\nParameters\n\u00b6\n\n\n\n\nprocessor\n - the index of the (remote) processor\n\n\nthe_variable\n - the source variable\n\n\n\n\nComplexity and cost\n\u00b6\n\n\n\n\n\n\nCost\n\n\n\n\nsizeof(T) * g\n\n\n\n\n\n\n\n\nExample\n\u00b6\n\n\n#include\n \n<iostream>\n\n\n\n#include\n \n<bulk/hub.hpp>\n\n\n#include\n \n<bulk/communication.hpp>\n\n\n#include\n \n<bulk/bsp/bulk.hpp>\n\n\n\n\nint\n \nmain\n()\n \n{\n\n    \nauto\n \nhub\n \n=\n \nbulk\n::\nhub\n<\nbulk\n::\nbsp\n::\nprovider\n>\n();\n\n\n    \nhub\n.\nspawn\n(\nhub\n.\navailable_processors\n(),\n \n[\n&\nhub\n](\nint\n \ns\n,\n \nint\n)\n \n{\n\n        \nauto\n \nx\n \n=\n \nbulk\n::\ncreate_var\n<\nint\n>\n(\nhub\n);\n\n        \nauto\n \ny\n \n=\n \nbulk\n::\nget\n(\nhub\n.\nnext_processor\n(),\n \nx\n);\n \n// 1.\n\n\n        \nhub\n.\nsync\n();\n\n\n        \nstd\n::\ncout\n \n<<\n \ns\n \n<<\n \n\" <- \"\n \n<<\n \ny\n.\nvalue\n()\n \n<<\n \nstd\n::\nendl\n;\n\n    \n});\n\n\n    \nreturn\n \n0\n;\n\n\n}",
            "title": "get"
        },
        {
            "location": "/api/get/#bulkget",
            "text": "template   < typename   T ,   typename   Hub >  future < T ,   Hub >   get ( int   processor ,   var < T ,   Hub >&   the_variable );   // 1.   Get a value from a (remote) image of a  variable  (1.).",
            "title": "bulk::get"
        },
        {
            "location": "/api/get/#template-parameters",
            "text": "T  - the value type of the variable/array  Hub  - the type of the hub that the variable/array belongs to",
            "title": "Template parameters"
        },
        {
            "location": "/api/get/#parameters",
            "text": "processor  - the index of the (remote) processor  the_variable  - the source variable",
            "title": "Parameters"
        },
        {
            "location": "/api/get/#complexity-and-cost",
            "text": "Cost   sizeof(T) * g",
            "title": "Complexity and cost"
        },
        {
            "location": "/api/get/#example",
            "text": "#include   <iostream>  #include   <bulk/hub.hpp>  #include   <bulk/communication.hpp>  #include   <bulk/bsp/bulk.hpp>  int   main ()   { \n     auto   hub   =   bulk :: hub < bulk :: bsp :: provider > (); \n\n     hub . spawn ( hub . available_processors (),   [ & hub ]( int   s ,   int )   { \n         auto   x   =   bulk :: create_var < int > ( hub ); \n         auto   y   =   bulk :: get ( hub . next_processor (),   x );   // 1. \n\n         hub . sync (); \n\n         std :: cout   <<   s   <<   \" <- \"   <<   y . value ()   <<   std :: endl ; \n     }); \n\n     return   0 ;  }",
            "title": "Example"
        },
        {
            "location": "/api/foldl/",
            "text": "bulk::reduce\n\u00b6\n\n\nNot yet available",
            "title": "foldl"
        },
        {
            "location": "/api/foldl/#bulkreduce",
            "text": "Not yet available",
            "title": "bulk::reduce"
        },
        {
            "location": "/api/gather_all/",
            "text": "",
            "title": "gather_all"
        },
        {
            "location": "/api/flatten/",
            "text": "",
            "title": "flatten"
        },
        {
            "location": "/api/unflatten/",
            "text": "",
            "title": "unflatten"
        },
        {
            "location": "/api/var/image/",
            "text": "bulk::var::image\n\u00b6\n\n\nDefined in header \n<bulk/variable.hpp>\n.\n\n\nclass\n \nimage\n\n\n\n\n\n\nbulk::var::image\n provides syntactic sugar for dealing with remote images.\n\n\nMember functions\n\u00b6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nValue access\n\n\n\n\n\n\n\n\noperator=\n\n\nassign values to the variable\n\n\n\n\n\n\nget\n\n\nreturns the value of the local variable image",
            "title": "var::image"
        },
        {
            "location": "/api/var/image/#bulkvarimage",
            "text": "Defined in header  <bulk/variable.hpp> .  class   image   bulk::var::image  provides syntactic sugar for dealing with remote images.",
            "title": "bulk::var::image"
        },
        {
            "location": "/api/var/image/#member-functions",
            "text": "Value access     operator=  assign values to the variable    get  returns the value of the local variable image",
            "title": "Member functions"
        },
        {
            "location": "/api/environment/spawn/",
            "text": "bulk::environment::spawn\n\u00b6\n\n\nvoid\n \nspawn\n(\nint\n \nprocessors\n,\n \nstd\n::\nfunction\n<\nvoid\n(\nbulk\n::\nworld\n&\n)\n>\n \nspmd\n);\n\n\n\n\n\n\nStart an SPMD section on a given number of processors.\n\n\nParameters\n\u00b6\n\n\n\n\nprocessors\n - the number of processors to run the SPMD section on.\n\n\nspmd\n - the SPMD function that gets run on each (virtual) processor. A reference to the world of the processor will be passed as the first and only argument.",
            "title": "environment::spawn"
        },
        {
            "location": "/api/environment/spawn/#bulkenvironmentspawn",
            "text": "void   spawn ( int   processors ,   std :: function < void ( bulk :: world & ) >   spmd );   Start an SPMD section on a given number of processors.",
            "title": "bulk::environment::spawn"
        },
        {
            "location": "/api/environment/spawn/#parameters",
            "text": "processors  - the number of processors to run the SPMD section on.  spmd  - the SPMD function that gets run on each (virtual) processor. A reference to the world of the processor will be passed as the first and only argument.",
            "title": "Parameters"
        },
        {
            "location": "/api/environment/available_processors/",
            "text": "bulk::environment::available_processors\n\u00b6\n\n\nint\n \navailable_processors\n()\n \nconst\n;\n\n\n\n\n\n\nReturns the total number of processors available on the system.\n\n\nReturn value\n\u00b6\n\n\n\n\nint\n: The number of available processors.",
            "title": "environment::available_processors"
        },
        {
            "location": "/api/environment/available_processors/#bulkenvironmentavailable_processors",
            "text": "int   available_processors ()   const ;   Returns the total number of processors available on the system.",
            "title": "bulk::environment::available_processors"
        },
        {
            "location": "/api/environment/available_processors/#return-value",
            "text": "int : The number of available processors.",
            "title": "Return value"
        },
        {
            "location": "/api/world/processor_id/",
            "text": "bulk::world::processor_id\n\u00b6\n\n\nint\n \nprocessor_id\n()\n \nconst\n;\n\n\n\n\n\n\nReturns the local processor id\n\n\nReturn value\n\u00b6\n\n\n\n\nint\n: The id of the local processor.",
            "title": "world::processor_id"
        },
        {
            "location": "/api/world/processor_id/#bulkworldprocessor_id",
            "text": "int   processor_id ()   const ;   Returns the local processor id",
            "title": "bulk::world::processor_id"
        },
        {
            "location": "/api/world/processor_id/#return-value",
            "text": "int : The id of the local processor.",
            "title": "Return value"
        },
        {
            "location": "/api/world/active_processors/",
            "text": "bulk::world::active_processors\n\u00b6\n\n\nint\n \nactive_processors\n()\n \nconst\n;\n\n\n\n\n\n\nReturns the total number of active processors in an SPMD section.\n\n\nReturn value\n\u00b6\n\n\n\n\nint\n: The number of active processors.",
            "title": "world::active_processors"
        },
        {
            "location": "/api/world/active_processors/#bulkworldactive_processors",
            "text": "int   active_processors ()   const ;   Returns the total number of active processors in an SPMD section.",
            "title": "bulk::world::active_processors"
        },
        {
            "location": "/api/world/active_processors/#return-value",
            "text": "int : The number of active processors.",
            "title": "Return value"
        },
        {
            "location": "/api/world/next_processor/",
            "text": "bulk::world::next_processor\n\u00b6\n\n\nint\n \nnext_processor\n()\n \nconst\n;\n\n\n\n\n\n\nReturns the id of the next logical processor.\n\n\nReturn value\n\u00b6\n\n\n\n\nint\n: The id of the next processor",
            "title": "world::next_processor"
        },
        {
            "location": "/api/world/next_processor/#bulkworldnext_processor",
            "text": "int   next_processor ()   const ;   Returns the id of the next logical processor.",
            "title": "bulk::world::next_processor"
        },
        {
            "location": "/api/world/next_processor/#return-value",
            "text": "int : The id of the next processor",
            "title": "Return value"
        },
        {
            "location": "/api/world/prev_processor/",
            "text": "bulk::world::prev_processor\n\u00b6\n\n\nint\n \nprev_processor\n()\n \nconst\n;\n\n\n\n\n\n\nReturns the id of the previous logical processor.\n\n\nReturn value\n\u00b6\n\n\n\n\nint\n: The id of the previous processor",
            "title": "world::prev_processor"
        },
        {
            "location": "/api/world/prev_processor/#bulkworldprev_processor",
            "text": "int   prev_processor ()   const ;   Returns the id of the previous logical processor.",
            "title": "bulk::world::prev_processor"
        },
        {
            "location": "/api/world/prev_processor/#return-value",
            "text": "int : The id of the previous processor",
            "title": "Return value"
        },
        {
            "location": "/api/world/sync/",
            "text": "bulk::world::sync\n\u00b6\n\n\nvoid\n \nsync\n()\n \nconst\n;\n\n\n\n\n\n\nPerforms a global barrier synchronization of the active processors, resolving any outstanding communication.\n\n\nComplexity and cost\n\u00b6\n\n\n\n\nCost\n - \nl",
            "title": "world::sync"
        },
        {
            "location": "/api/world/sync/#bulkworldsync",
            "text": "void   sync ()   const ;   Performs a global barrier synchronization of the active processors, resolving any outstanding communication.",
            "title": "bulk::world::sync"
        },
        {
            "location": "/api/world/sync/#complexity-and-cost",
            "text": "Cost  -  l",
            "title": "Complexity and cost"
        },
        {
            "location": "/api/world/barrier/",
            "text": "bulk::world::barrier\n\u00b6\n\n\nvoid\n \nbarrier\n()\n \nconst\n;\n\n\n\n\n\n\nPerforms a global barrier of the active processors.\n\n\nComplexity and cost\n\u00b6\n\n\n\n\nCost\n - \nl\n (approximately)",
            "title": "world::barrier"
        },
        {
            "location": "/api/world/barrier/#bulkworldbarrier",
            "text": "void   barrier ()   const ;   Performs a global barrier of the active processors.",
            "title": "bulk::world::barrier"
        },
        {
            "location": "/api/world/barrier/#complexity-and-cost",
            "text": "Cost  -  l  (approximately)",
            "title": "Complexity and cost"
        },
        {
            "location": "/api/var/constructor/",
            "text": "bulk::var::var\n\u00b6\n\n\nvar\n(\nbulk\n::\nworld\n&\n \nworld\n);\n \n// (1)\n\n\nvar\n(\nbulk\n::\nworld\n&\n \nworld\n,\n \nT\n \nvalue\n);\n \n// (2)\n\n\n\n\n\n\n\n\nConstructs a variable and registers it with \nworld\n. Requires \nT\n to be trivially constructable.\n\n\n\u2026 In addition, set the initial value of the local image to \nvalue\n.\n\n\n\n\nParameters\n\u00b6\n\n\n\n\nworld\n - the world this variable belongs to\n\n\nvalue\n - initial value of the local image\n\n\n\n\nComplexity and cost\n\u00b6\n\n\n\n\nCost\n - \nl\n or free (backend dependent)",
            "title": "var::constructor"
        },
        {
            "location": "/api/var/constructor/#bulkvarvar",
            "text": "var ( bulk :: world &   world );   // (1)  var ( bulk :: world &   world ,   T   value );   // (2)    Constructs a variable and registers it with  world . Requires  T  to be trivially constructable.  \u2026 In addition, set the initial value of the local image to  value .",
            "title": "bulk::var::var"
        },
        {
            "location": "/api/var/constructor/#parameters",
            "text": "world  - the world this variable belongs to  value  - initial value of the local image",
            "title": "Parameters"
        },
        {
            "location": "/api/var/constructor/#complexity-and-cost",
            "text": "Cost  -  l  or free (backend dependent)",
            "title": "Complexity and cost"
        },
        {
            "location": "/api/var/deconstructor/",
            "text": "bulk::var::~var\n\u00b6\n\n\n~\nvar\n();\n\n\n\n\n\n\nDeconstructs a variable and deregisters it with its \nworld\n.\n\n\nComplexity and cost\n\u00b6\n\n\n\n\nCost\n - \nl\n or free, depending on the backend",
            "title": "var::deconstructor"
        },
        {
            "location": "/api/var/deconstructor/#bulkvarvar",
            "text": "~ var ();   Deconstructs a variable and deregisters it with its  world .",
            "title": "bulk::var::~var"
        },
        {
            "location": "/api/var/deconstructor/#complexity-and-cost",
            "text": "Cost  -  l  or free, depending on the backend",
            "title": "Complexity and cost"
        },
        {
            "location": "/api/var/assignment_operator/",
            "text": "bulk::var::operator=\n\u00b6\n\n\nvoid\n \noperator\n=\n(\nvar\n<\nT\n>&&\n \nother\n);\n \n// 1.\n\n\n\n\n\n\n\n\nMove assignment operator. Replaces the target variable \n*this\n with the source variable \nother\n, and invalidates the source.\n\n\n\n\nParameters\n\u00b6\n\n\n\n\nother\n - another variable to move away from\n\n\n\n\nComplexity and cost\n\u00b6\n\n\n\n\nCost\n - \nl\n or free (backend dependent)",
            "title": "var::operator="
        },
        {
            "location": "/api/var/assignment_operator/#bulkvaroperator",
            "text": "void   operator = ( var < T >&&   other );   // 1.    Move assignment operator. Replaces the target variable  *this  with the source variable  other , and invalidates the source.",
            "title": "bulk::var::operator="
        },
        {
            "location": "/api/var/assignment_operator/#parameters",
            "text": "other  - another variable to move away from",
            "title": "Parameters"
        },
        {
            "location": "/api/var/assignment_operator/#complexity-and-cost",
            "text": "Cost  -  l  or free (backend dependent)",
            "title": "Complexity and cost"
        },
        {
            "location": "/api/var/value/",
            "text": "bulk::var::value\n\u00b6\n\n\nT\n&\n \nvalue\n();\n\n\n\n\n\n\nReturns a reference to the value held by the local image of the variable.\n\n\nReturn value\n\u00b6\n\n\n\n\nA reference to the value of the local image",
            "title": "var::value"
        },
        {
            "location": "/api/var/value/#bulkvarvalue",
            "text": "T &   value ();   Returns a reference to the value held by the local image of the variable.",
            "title": "bulk::var::value"
        },
        {
            "location": "/api/var/value/#return-value",
            "text": "A reference to the value of the local image",
            "title": "Return value"
        },
        {
            "location": "/api/var/T_operator/",
            "text": "bulk::var::operator T\n\u00b6\n\n\noperator\n \nT\n&\n();\n\n\noperator\n \nconst\n \nT\n&\n();\n\n\n\n\n\n\nObtain an implicit (const) reference to the value of the local image.\n\n\nExample\n\u00b6\n\n\nThis allows for convenient syntax when working with local images, e.g.:\n\n\nauto\n \nx\n \n=\n \nbulk\n::\nvar\n<\nint\n>\n(\nworld\n,\n \n5\n);\n\n\nauto\n \ny\n \n=\n \nx\n \n+\n \n5\n;\n \n// y is an int with value 10",
            "title": "var::operator T"
        },
        {
            "location": "/api/var/T_operator/#bulkvaroperator-t",
            "text": "operator   T & ();  operator   const   T & ();   Obtain an implicit (const) reference to the value of the local image.",
            "title": "bulk::var::operator T"
        },
        {
            "location": "/api/var/T_operator/#example",
            "text": "This allows for convenient syntax when working with local images, e.g.:  auto   x   =   bulk :: var < int > ( world ,   5 );  auto   y   =   x   +   5 ;   // y is an int with value 10",
            "title": "Example"
        },
        {
            "location": "/api/var/paren_operator/",
            "text": "bulk::var::operator()\n\u00b6\n\n\nimage\n \noperator\n()(\nint\n \nt\n);\n\n\n\n\n\n\nObtain an image object, used to communicate with a remote image.\n\n\nParameters\n\u00b6\n\n\n\n\nt\n - the id of the remote processor",
            "title": "var::operator()"
        },
        {
            "location": "/api/var/paren_operator/#bulkvaroperator",
            "text": "image   operator ()( int   t );   Obtain an image object, used to communicate with a remote image.",
            "title": "bulk::var::operator()"
        },
        {
            "location": "/api/var/paren_operator/#parameters",
            "text": "t  - the id of the remote processor",
            "title": "Parameters"
        },
        {
            "location": "/api/var/broadcast/",
            "text": "bulk::var::broadcast\n\u00b6\n\n\nvoid\n \nbroadcast\n(\nT\n \nx\n);\n\n\n\n\n\n\nBroadcasts a value to all images.\n\n\nFor one variable, this function should be called by a single processor in any given superstep. The broadcasted value is valid starting from the subsequent superstep.\n\n\nParameters\n\u00b6\n\n\n\n\nx\n - the value to broadcast\n\n\n\n\nComplexity and cost\n\u00b6\n\n\n\n\nCost\n - \np * g",
            "title": "var::broadcast"
        },
        {
            "location": "/api/var/broadcast/#bulkvarbroadcast",
            "text": "void   broadcast ( T   x );   Broadcasts a value to all images.  For one variable, this function should be called by a single processor in any given superstep. The broadcasted value is valid starting from the subsequent superstep.",
            "title": "bulk::var::broadcast"
        },
        {
            "location": "/api/var/broadcast/#parameters",
            "text": "x  - the value to broadcast",
            "title": "Parameters"
        },
        {
            "location": "/api/var/broadcast/#complexity-and-cost",
            "text": "Cost  -  p * g",
            "title": "Complexity and cost"
        },
        {
            "location": "/api/var/world/",
            "text": "bulk::var::world\n\u00b6\n\n\nbulk\n::\nworld\n&\n \nworld\n();\n\n\n\n\n\n\nReturns a reference to the world the variable belongs to\n\n\nReturn value\n\u00b6\n\n\n\n\nA reference to the world.",
            "title": "var::world"
        },
        {
            "location": "/api/var/world/#bulkvarworld",
            "text": "bulk :: world &   world ();   Returns a reference to the world the variable belongs to",
            "title": "bulk::var::world"
        },
        {
            "location": "/api/var/world/#return-value",
            "text": "A reference to the world.",
            "title": "Return value"
        },
        {
            "location": "/api/var/image_assignment_operator/",
            "text": "bulk::var::operator=\n\u00b6\n\n\nvoid\n \noperator\n=\n(\nvar\n<\nT\n>&&\n \nother\n);\n \n// 1.\n\n\n\n\n\n\n\n\nMove assignment operator. Replaces the target variable \n*this\n with the source variable \nother\n, and invalidates the source.\n\n\n\n\nParameters\n\u00b6\n\n\n\n\nother\n - another variable to move away from\n\n\n\n\nComplexity and cost\n\u00b6\n\n\n\n\nCost\n - \nl\n or free (backend dependent)",
            "title": "var::image::operator="
        },
        {
            "location": "/api/var/image_assignment_operator/#bulkvaroperator",
            "text": "void   operator = ( var < T >&&   other );   // 1.    Move assignment operator. Replaces the target variable  *this  with the source variable  other , and invalidates the source.",
            "title": "bulk::var::operator="
        },
        {
            "location": "/api/var/image_assignment_operator/#parameters",
            "text": "other  - another variable to move away from",
            "title": "Parameters"
        },
        {
            "location": "/api/var/image_assignment_operator/#complexity-and-cost",
            "text": "Cost  -  l  or free (backend dependent)",
            "title": "Complexity and cost"
        },
        {
            "location": "/api/var/image_get/",
            "text": "",
            "title": "var::image::get="
        },
        {
            "location": "/providers/mpi/",
            "text": "",
            "title": "MPI"
        },
        {
            "location": "/providers/thread/",
            "text": "<thread>\n\u00b6\n\n\nThis backend uses the shared-memory parallelism provided by the standard C++ library \n<thread>\n.\n\n\nTo use it on Linux, link against \nlibpthread\n.",
            "title": "thread"
        },
        {
            "location": "/providers/thread/#thread",
            "text": "This backend uses the shared-memory parallelism provided by the standard C++ library  <thread> .  To use it on Linux, link against  libpthread .",
            "title": "&lt;thread&gt;"
        },
        {
            "location": "/bsp/",
            "text": "BSP Model\n\u00b6\n\n\nThe Bulk Synchronous Parallel (BSP) model was developed by Leslie Valiant in the 1980s. The BSP model is intended as a bridging model between parallel hardware and software. It is an elegant and simple model that has a small and easy to understand interface.\n\n\nThe BSP model is defined on an abstract computer called a BSP computer. This computer has three important requirements.\n\n\n\n\nIt has \n\\(n\\)\n processors capable of computation and communication, i.e. it allows for local memory transactions.\n\n\nIt has a network in place that allows the different processors to send and receive data.\n\n\nIt has a mechanism that allows for the synchronisation of these processors, e.g. by means of a blocking barrier.\n\n\n\n\nA BSP program consists of a number of distinct blocks of computation and communication called \nsupersteps\n. These steps are separated by a barrier synchronisation, and consist of a computation and a communication step.\n\n\nAn important part of a BSP algorithm is the associated cost function. To this end we introduce two important concepts: namely an \n\\(h\\)\n-relation, and a notion of the \nwork\n done by a processor. Furthermore we introduce two parameters that define a BSP computer: \n\\(g\\)\n and \n\\(l\\)\n.\n\n\nAn \n\\(h\\)\n-relation is a superstep in which each processor sends or receives a maximum of \n\\(h\\)\n words of data. We commonly denote with \n\\(p\\)\n the id of a processor such that we can write for the \n\\(h\\)\n-relation:\n\n\n\\[h = \\max_p \\left\\{ \\max \\{ (h_p)_\\text{sent}, (h_p)_\\text{received} \\}~|~\\text{processors } p \\right\\}\\]\nWhere \n\\(h_p\\)\n denotes the number of words received or sent by processor \n\\(p\\)\n. Similarly we define the work \n\\(w\\)\n done in a superstep as the maximum number of flops, floating point operations, performed by all processors. Finally we define the latency \n\\(l\\)\n of a superstep as the fixed constant overhead, used primarily to account for the barrier synchronisation. The values for \n\\(g\\)\n and \n\\(l\\)\n are platform-specific constants that are found emperically. The values for \n\\(w\\)\n and \n\\(h\\)\n are superstep specific and commonly obtained analytically. The total BSP cost associated to a BSP algorithm is:\n\n\n\\[T = \\sum_{\\text{supersteps } i} (w_i + g \\cdot h_i + l)\\]\nThe BSP model has gained significant interest in the last couple of years. Most notably because Google has adopted the model and has developed some technologies based on BSP such as MapReduce and Pregel. The standard for BSP implementations is \nBSPlib\n. Modern implementations of the BSPlib include BSPonMPI, which simulates the BSP model on top of MPI, and MulticoreBSP, which provides a BSP implementation for shared-memory multi-core computers.\n\n\nFor a more detailed introduction on the BSP model, as well as a large number of examples of BSP programs we refer to the \nintroductory textbook on BSP and MPI\n by Rob Bisseling.\n\n\nA large number of algorithms have already been implemented using the BSP model. Some of them with their associated cost function are listed below:\n\n\n\n\n\n\n\n\nProblem\n\n\nBSP Complexity\n\n\n\n\n\n\n\n\n\n\nMatrix multiplication\n\n\n\\(n^3/p + (n^2/p^{2/3}) \\cdot g + l\\)\n\n\n\n\n\n\nSorting\n\n\n\\((n \\log n)/p + (n/p)\\cdot g + l\\)\n\n\n\n\n\n\nFast Fourier Transform\n\n\n\\((n \\log n)/p + (n/p)\\cdot g + l\\)\n\n\n\n\n\n\nLU Decomposition\n\n\n\\(n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l\\)\n\n\n\n\n\n\nCholesky Factorisation\n\n\n\\(n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l\\)\n\n\n\n\n\n\nAlgebraic Path Problem (Shortest Paths)\n\n\n\\(n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l\\)\n\n\n\n\n\n\nTriangular Solver\n\n\n\\(n^2/p + n\\cdot g + p\\cdot l\\)\n\n\n\n\n\n\nString Edit Problem\n\n\n\\(n^2/p + n\\cdot g + p\\cdot l\\)\n\n\n\n\n\n\nDense Matrix-Vector Multiplication\n\n\n\\(n^2/p + (n/p^{1/2})\\cdot g+l\\)\n\n\n\n\n\n\nSparse Matrix-Vector Multiplication (2D grid)\n\n\n\\(n/p + (n/p)^{1/2}\\cdot g+l\\)\n\n\n\n\n\n\nSparse Matrix-Vector Multiplication (3D grid)\n\n\n\\(n/p + (n/p)^{2/3}\\cdot g+l\\)\n\n\n\n\n\n\nSparse Matrix-Vector Multiplication (random)\n\n\n\\(n/p + (n/p)\\cdot g+l\\)\n\n\n\n\n\n\nList Ranking\n\n\n\\(n/p + (n/p)\\cdot g+(\\log p)\\cdot l\\)\n\n\n\n\n\n\n\n\n(From: McColl 1998 \u201cFoundations of Time-Critical Scalable Computing\u201d)",
            "title": "BSP model"
        },
        {
            "location": "/bsp/#bsp-model",
            "text": "The Bulk Synchronous Parallel (BSP) model was developed by Leslie Valiant in the 1980s. The BSP model is intended as a bridging model between parallel hardware and software. It is an elegant and simple model that has a small and easy to understand interface.  The BSP model is defined on an abstract computer called a BSP computer. This computer has three important requirements.   It has  \\(n\\)  processors capable of computation and communication, i.e. it allows for local memory transactions.  It has a network in place that allows the different processors to send and receive data.  It has a mechanism that allows for the synchronisation of these processors, e.g. by means of a blocking barrier.   A BSP program consists of a number of distinct blocks of computation and communication called  supersteps . These steps are separated by a barrier synchronisation, and consist of a computation and a communication step.  An important part of a BSP algorithm is the associated cost function. To this end we introduce two important concepts: namely an  \\(h\\) -relation, and a notion of the  work  done by a processor. Furthermore we introduce two parameters that define a BSP computer:  \\(g\\)  and  \\(l\\) .  An  \\(h\\) -relation is a superstep in which each processor sends or receives a maximum of  \\(h\\)  words of data. We commonly denote with  \\(p\\)  the id of a processor such that we can write for the  \\(h\\) -relation:  \\[h = \\max_p \\left\\{ \\max \\{ (h_p)_\\text{sent}, (h_p)_\\text{received} \\}~|~\\text{processors } p \\right\\}\\] Where  \\(h_p\\)  denotes the number of words received or sent by processor  \\(p\\) . Similarly we define the work  \\(w\\)  done in a superstep as the maximum number of flops, floating point operations, performed by all processors. Finally we define the latency  \\(l\\)  of a superstep as the fixed constant overhead, used primarily to account for the barrier synchronisation. The values for  \\(g\\)  and  \\(l\\)  are platform-specific constants that are found emperically. The values for  \\(w\\)  and  \\(h\\)  are superstep specific and commonly obtained analytically. The total BSP cost associated to a BSP algorithm is:  \\[T = \\sum_{\\text{supersteps } i} (w_i + g \\cdot h_i + l)\\] The BSP model has gained significant interest in the last couple of years. Most notably because Google has adopted the model and has developed some technologies based on BSP such as MapReduce and Pregel. The standard for BSP implementations is  BSPlib . Modern implementations of the BSPlib include BSPonMPI, which simulates the BSP model on top of MPI, and MulticoreBSP, which provides a BSP implementation for shared-memory multi-core computers.  For a more detailed introduction on the BSP model, as well as a large number of examples of BSP programs we refer to the  introductory textbook on BSP and MPI  by Rob Bisseling.  A large number of algorithms have already been implemented using the BSP model. Some of them with their associated cost function are listed below:     Problem  BSP Complexity      Matrix multiplication  \\(n^3/p + (n^2/p^{2/3}) \\cdot g + l\\)    Sorting  \\((n \\log n)/p + (n/p)\\cdot g + l\\)    Fast Fourier Transform  \\((n \\log n)/p + (n/p)\\cdot g + l\\)    LU Decomposition  \\(n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l\\)    Cholesky Factorisation  \\(n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l\\)    Algebraic Path Problem (Shortest Paths)  \\(n^3/p + (n^2/p^{1/2})\\cdot g + p^{1/2}\\cdot l\\)    Triangular Solver  \\(n^2/p + n\\cdot g + p\\cdot l\\)    String Edit Problem  \\(n^2/p + n\\cdot g + p\\cdot l\\)    Dense Matrix-Vector Multiplication  \\(n^2/p + (n/p^{1/2})\\cdot g+l\\)    Sparse Matrix-Vector Multiplication (2D grid)  \\(n/p + (n/p)^{1/2}\\cdot g+l\\)    Sparse Matrix-Vector Multiplication (3D grid)  \\(n/p + (n/p)^{2/3}\\cdot g+l\\)    Sparse Matrix-Vector Multiplication (random)  \\(n/p + (n/p)\\cdot g+l\\)    List Ranking  \\(n/p + (n/p)\\cdot g+(\\log p)\\cdot l\\)     (From: McColl 1998 \u201cFoundations of Time-Critical Scalable Computing\u201d)",
            "title": "BSP Model"
        },
        {
            "location": "/CHANGELOG/",
            "text": "Changelog\n\u00b6\n\n\n0.1.0\n\u00b6\n\n\n2017-01-01\n\u00b6\n\n\n\n\nInitial release",
            "title": "Release Notes"
        },
        {
            "location": "/CHANGELOG/#changelog",
            "text": "",
            "title": "Changelog"
        },
        {
            "location": "/CHANGELOG/#010",
            "text": "",
            "title": "0.1.0"
        },
        {
            "location": "/CHANGELOG/#2017-01-01",
            "text": "Initial release",
            "title": "2017-01-01"
        }
    ]
}